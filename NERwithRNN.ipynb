{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsnRZ4WcrBny"
   },
   "source": [
    "# <center>Deep Learning Project</center>\n",
    "<br>\n",
    "<b>Name : </b>Daniel Sabba <br> \n",
    "<b>Project Name : </b>Named Entity Recognition using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jBfLt2ponq8c"
   },
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKCnK9dwunoD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D,Flatten,GRU\n",
    "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IH6JxcytunoN"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xriXu2M9rBn3"
   },
   "source": [
    "My dataset contains a total of 3482 sentences, which is constructed from 59883 words.<br>\n",
    "the dataset has 18752 unique words and 101 unique chars, there are 17 different tags, and 1 more tag for padding - total 18.\n",
    "<br>\n",
    "data set providers https://www.cs.bgu.ac.il/~elhadad/nlpproj/naama/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJgM8wQVunoP"
   },
   "outputs": [],
   "source": [
    "with open(r\"trainSet\",encoding = \"utf8\") as fp:\n",
    "    dict_list = fp.readlines();\n",
    "\n",
    "i = 0\n",
    "start = 0\n",
    "sentences = []\n",
    "for elem in dict_list:\n",
    "    if(elem == \"\\n\" and \"DOCSTART\" not in elem ):\n",
    "        sentences.append(\" \".join(dict_list[start:i]))\n",
    "        start = i\n",
    "    i+=1\n",
    "    \n",
    "sentences.remove(\"--DOCSTART-- O\\n\")\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = sentences[i].replace(\"\\n\",\"\")\n",
    "    while(sentences[i].startswith(\" \")):\n",
    "        sentences[i] = sentences[i][1:]\n",
    "    while(sentences[i].endswith(\" \")):\n",
    "        sentences[i] = sentences[i][:-1]\n",
    "    while(sentences[i].endswith(\". O\")):\n",
    "        sentences[i] = sentences[i][:-3]\n",
    "    while(sentences[i].endswith(\" \")):\n",
    "        sentences[i] = sentences[i][:-1]\n",
    "        \n",
    "all_tags = []\n",
    "clean_sent = []\n",
    "clean_tags = []\n",
    "df = {}\n",
    "n = 0\n",
    "for sent in sentences:\n",
    "    i = 0\n",
    "    temp_tags = []\n",
    "    temp_sent = []\n",
    "    for word in sent.split(\" \"):\n",
    "        if(i%2 == 0):\n",
    "            temp_sent.append(word)\n",
    "        else:\n",
    "            temp_tags.append(word)\n",
    "            all_tags.append(word)\n",
    "            all_tags = list(set(all_tags))\n",
    "        i+=1\n",
    "    clean_sent.append(temp_sent)\n",
    "    clean_tags.append(temp_tags)\n",
    "\n",
    "all_tags.append(\"PADDING\")    \n",
    "tags_dict = {}\n",
    "for i in range(0,len(all_tags)):\n",
    "    tags_dict.update({all_tags[i]:i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fxOOJAXyunoc"
   },
   "outputs": [],
   "source": [
    "n_tags = len(all_tags)\n",
    "words = []\n",
    "for sent in clean_sent:\n",
    "    for word in sent:\n",
    "        if(word not in words):\n",
    "            words.append(word)\n",
    "n_words = len(words)\n",
    "\n",
    "chars = []\n",
    "for sent in clean_sent:\n",
    "    for word in sent:\n",
    "        for char in word:\n",
    "            if(char not in chars):\n",
    "                chars.append(char)\n",
    "chars = sorted(chars)\n",
    "n_chars = len(chars)\n",
    "\n",
    "    # Building dictionaries to help build the corpus\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "word2idx[\"PADDING\"] = 0\n",
    "\n",
    "char2idx = {c: i + 1 for i, c in enumerate(chars)}\n",
    "char2idx[\"PADDING\"] = 0\n",
    "\n",
    "tag2idx = {t: i+1 for i, t in enumerate(all_tags)}\n",
    "tag2idx[\"PADDING\"] = 0\n",
    "    # Building the word corpus using the words dictionarie\n",
    "X_word = [[word2idx[w] for w in s] for s in clean_sent]\n",
    "X_word = np.array(X_word)\n",
    "\n",
    "max_len = 75\n",
    "\n",
    "# Padding the sentences vectors with zeros, so all of my sentences will have the same length\n",
    "X_word_padded = pad_sequences(maxlen=max_len, sequences=X_word, value=word2idx[\"PADDING\"], padding='post', truncating='post')\n",
    "\n",
    "max_len_char = 10\n",
    "\n",
    "    # Building my charecter vectors, each word will become a vector of size max_len_char.\n",
    "    # Using the char2idx dictionarie\n",
    "X_char = []\n",
    "for sentence in clean_sent:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PADDING\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))\n",
    "    \n",
    "X_char = np.array(X_char)\n",
    "\n",
    "    # Building the corresponding label data.\n",
    "y = [[tag2idx[w] for w in s] for s in clean_tags]\n",
    "y = np.array(y)\n",
    "\n",
    "    # Padding the labels with zeros, so it will match the length of the new padded sentences\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, value=tag2idx[\"PADDING\"], padding='post', truncating='post')\n",
    "y2 = y.reshape(y.shape[0],y.shape[1],1)\n",
    "\n",
    "    # Splitting the data into train and test.\n",
    "X_word_tr, X_word_te, y_tr, y_te = train_test_split(X_word_padded, y, test_size=0.1, random_state=2018)\n",
    "X_char_tr, X_char_te, _, _ = train_test_split(X_char, y, test_size=0.1, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wB4ckZALuno3"
   },
   "outputs": [],
   "source": [
    "flat_list = []\n",
    "for sublist in clean_sent:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "\n",
    "flat_list2 = []\n",
    "for sublist in clean_tags:\n",
    "    for item in sublist:\n",
    "        flat_list2.append(item)\n",
    "\n",
    "temp = {\"Words\" : flat_list[:10],\"Tags\":flat_list2[:10]}\n",
    "      \n",
    "df = pd.DataFrame(temp)\n",
    "\n",
    "total_tags = 0\n",
    "count_padding = 0\n",
    "count_other = 0\n",
    "for sent in y_te:\n",
    "    for tag in sent:\n",
    "        total_tags+=1\n",
    "        if(tag == 0):\n",
    "            count_padding +=1\n",
    "        if(tag == tag2idx[\"O\"]):\n",
    "            count_other+=1\n",
    "           \n",
    "        \n",
    "def plot_hist(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "        \n",
    "    \n",
    "def get_tags(pred):\n",
    "    pred_tags = []\n",
    "    for sent in pred:\n",
    "        ans = []\n",
    "        for word in sent:\n",
    "            ans.append(word.argmax())\n",
    "        pred_tags.append(ans)\n",
    "    return pred_tags\n",
    "\n",
    "def get_hits(y_te,pred_tags):\n",
    "    hits = 0\n",
    "    count_pad = 0\n",
    "    count_o = 0\n",
    "    for real_tag,pred_tag in zip(y_te,pred_tags):\n",
    "        for y,yhat in zip(real_tag,pred_tag):\n",
    "            try:\n",
    "                if(y == yhat and yhat != 0 and y != tag2idx[\"O\"]):\n",
    "                    hits +=1\n",
    "                if(yhat == tag2idx[\"PADDING\"]):\n",
    "                    count_pad +=1\n",
    "                if(yhat == tag2idx[\"O\"]):\n",
    "                    count_o +=1\n",
    "            except:\n",
    "                try:\n",
    "                    if(y == yhat[0] and yhat[0] != 0 and y != tag2idx[\"O\"]):\n",
    "                        hits +=1\n",
    "                    if(yhat[0] == tag2idx[\"PADDING\"]):\n",
    "                        count_pad +=1\n",
    "                    if(yhat[0] == tag2idx[\"O\"]):\n",
    "                        count_o +=1\n",
    "                except:\n",
    "                    if(y == yhat and yhat != 0 and y != tag2idx[\"O\"]):\n",
    "                        hits +=1\n",
    "                    if(yhat == tag2idx[\"PAD\"]):\n",
    "                        count_pad +=1\n",
    "                    if(yhat == tag2idx[\"O\"]):\n",
    "                        count_o +=1\n",
    "                    \n",
    "    return hits,count_pad,count_o\n",
    "\n",
    "def print_scores(hits,count_pad,count_o):\n",
    "    print(\"Total tags :\", total_tags)\n",
    "    print(\"# of 'P' :\", count_padding)\n",
    "    print(\"# of 'O' :\", count_other)\n",
    "    print(\"Total tags left without O,P :\", total_tags - count_other - count_padding)\n",
    "    print(\"# of hits without 'PAD' and 'O' :\", hits)\n",
    "    print(\"# of predicted - 'O' :\", count_o)\n",
    "    print(\"# of predicted - 'PAD' :\", count_pad)\n",
    "    print(\"Accuracy rate : \", hits/(total_tags - count_other - count_padding))\n",
    "    \n",
    "def from_catagorical(y_te):\n",
    "    new_y_te = []\n",
    "    for sent in y_te:\n",
    "        newsent = []\n",
    "        for word in sent:\n",
    "            newsent.append(word.argmax())\n",
    "        new_y_te.append(newsent)\n",
    "    return new_y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEloc6wPjs5a"
   },
   "source": [
    "# My dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "9kOW_nepuno_",
    "outputId": "e78c8987-03b9-422b-f186-aefd52a24910",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>נראה</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>שאביטל</td>\n",
       "      <td>I_PERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>אברג'יל</td>\n",
       "      <td>I_PERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>לשעבר</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>אוז</td>\n",
       "      <td>I_PERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>)</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>אוהבת</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>לא</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Words    Tags\n",
       "0     נראה       O\n",
       "1   שאביטל  I_PERS\n",
       "2  אברג'יל  I_PERS\n",
       "3        (       O\n",
       "4    לשעבר       O\n",
       "5      אוז  I_PERS\n",
       "6        )       O\n",
       "7        ,       O\n",
       "8    אוהבת       O\n",
       "9       לא       O"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "EwoIdww1js5f",
    "outputId": "cd1fc09e-1800-436e-91b5-ed025b9cd7d2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B_DATE': 6,\n",
       " 'B_LOC': 12,\n",
       " 'B_MISC__AFF': 1,\n",
       " 'B_MISC__ENT': 0,\n",
       " 'B_ORG': 4,\n",
       " 'B_PERS': 11,\n",
       " 'B_TIME': 9,\n",
       " 'I_DATE': 2,\n",
       " 'I_LOC': 15,\n",
       " 'I_MISC_EVENT': 8,\n",
       " 'I_MISC__AFF': 16,\n",
       " 'I_MISC__ENT': 13,\n",
       " 'I_MONEY': 3,\n",
       " 'I_ORG': 5,\n",
       " 'I_PERCENT': 7,\n",
       " 'I_PERS': 10,\n",
       " 'I_TIME': 14,\n",
       " 'O': 17,\n",
       " 'PADDING': 18}"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "1EUIOf89js5j",
    "outputId": "49cb5f84-6ad7-4a14-eedb-280219e022d6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 18 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "w = Counter(flat_list2)\n",
    "plt.bar(w.keys(), w.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyaOk8tZjs5l"
   },
   "source": [
    "Here we can see the distribution of the tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGQo32rBunqf"
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGTXIO3Sjs5p"
   },
   "source": [
    "## Model 1: Simple NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJf6Fp9vjs5p"
   },
   "source": [
    "### Layers explanation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XHdkfCFmTFF"
   },
   "source": [
    "#### Input layer \n",
    "The input layer is used to instantiate a Keras tensor - (n-dimentions metrice)\n",
    "A Keras tensor is a TensorFlow symbolic tensor object, which we augment with certain attributes that allow us to build a Keras model just by knowing the inputs and outputs of the model.<br>\n",
    "input used in this model is a corpus constructed from the word vectors.<br>\n",
    "https://keras.io/api/layers/core_layers/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bitArennmpGb"
   },
   "source": [
    "#### Dense layer\n",
    "Dense layer is the regular deeply connected neural network layer. It is most common and frequently used layer. Dense layer does the below operation on the input and return the output.<br>\n",
    "when using a dense layer with a \"softmax\" or \"sigmoid\" activation, it becomes a \"Decoder\".<br>\n",
    "the decoder helpes us translate a vector into the output that matches it.<br>\n",
    "https://www.quora.com/In-Keras-what-is-a-dense-and-a-dropout-layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-p6dfn9mtb4"
   },
   "source": [
    "#### Dropout layer and Regularizers\n",
    "\n",
    "The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.<br>\n",
    "\n",
    "Regularizers allow you to apply penalties on layer parameters or layer activity during optimization. These penalties are summed into the loss function that the network optimizes.<br>\n",
    "https://keras.io/api/layers/regularization_layers/dropout/<br>\n",
    "https://keras.io/api/layers/regularizers/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIcRU1Rxjs5q"
   },
   "outputs": [],
   "source": [
    "word_input = Input(shape = (X_word_tr.shape[1],))\n",
    "\n",
    "layer1 = Dense(8,activation = \"relu\",kernel_regularizer=\"l2\")(word_input)\n",
    "layer2 = Dense(16,activation = \"relu\",kernel_regularizer=\"l2\")(layer1)\n",
    "dropout3 = Dropout(0.4)(layer2)\n",
    "layer4 = Dense(32,activation = \"relu\",kernel_regularizer=\"l2\")(dropout3)\n",
    "layer5 = Dense(16,activation = \"relu\",kernel_regularizer=\"l2\")(layer4)\n",
    "dropout6 = Dropout(0.4)(layer5)\n",
    "out = Dense(max_len,activation = \"softmax\")(dropout6)\n",
    "\n",
    "model = Model(word_input,out)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "GMyU-uZDjs5t",
    "outputId": "eedd304f-9aa4-4be2-f14d-5260f2b76f3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 75)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 608       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 75)                1275      \n",
      "=================================================================\n",
      "Total params: 3,099\n",
      "Trainable params: 3,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "d3pa24o8js5w",
    "outputId": "14dc4b64-bc90-4c45-8f47-65a2fe029e31",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 16058257802002432.0000 - acc: 0.2123 - val_loss: 17371935826509824.0000 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 16121695542706176.0000 - acc: 0.2154 - val_loss: 17836160587923456.0000 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 17185193869705216.0000 - acc: 0.1982 - val_loss: 18289594244005888.0000 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 18156469585182720.0000 - acc: 0.2059 - val_loss: 18762710661464064.0000 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 17340820935933952.0000 - acc: 0.1957 - val_loss: 19248074178166784.0000 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 18685218714025984.0000 - acc: 0.1976 - val_loss: 19729782677700608.0000 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 18960721538711552.0000 - acc: 0.2154 - val_loss: 20236204419055616.0000 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 19054480674783232.0000 - acc: 0.2065 - val_loss: 20755764465369088.0000 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 20245264652566528.0000 - acc: 0.2081 - val_loss: 21281446987563008.0000 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 20407287998840832.0000 - acc: 0.2017 - val_loss: 21798318384349184.0000 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 20108246605889536.0000 - acc: 0.2135 - val_loss: 22342928827416576.0000 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 20747924002570240.0000 - acc: 0.2142 - val_loss: 22897602378858496.0000 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 22399817816735744.0000 - acc: 0.2033 - val_loss: 23455284554891264.0000 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 23342623267749888.0000 - acc: 0.2231 - val_loss: 24021679072083968.0000 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 21931393651048448.0000 - acc: 0.2103 - val_loss: 24604394465001472.0000 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 22857869636403200.0000 - acc: 0.2071 - val_loss: 25227014399066112.0000 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 23897344063832064.0000 - acc: 0.2033 - val_loss: 25807071207227392.0000 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 24548379501527040.0000 - acc: 0.2132 - val_loss: 26425827818209280.0000 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 24913428099366912.0000 - acc: 0.2091 - val_loss: 27039275849613312.0000 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 24884774225051648.0000 - acc: 0.2142 - val_loss: 27687732159447040.0000 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 25119406140948480.0000 - acc: 0.2129 - val_loss: 28344166371033088.0000 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 26698803054641152.0000 - acc: 0.2107 - val_loss: 28988400728014848.0000 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 27865747816448000.0000 - acc: 0.2008 - val_loss: 29652181481160704.0000 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 28145899943231488.0000 - acc: 0.2024 - val_loss: 30332772736303104.0000 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 28798026302619648.0000 - acc: 0.2132 - val_loss: 30998039548133376.0000 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 29289974004187136.0000 - acc: 0.2103 - val_loss: 31693253019435008.0000 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 30110703599747072.0000 - acc: 0.2170 - val_loss: 32421718127542272.0000 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 30555990776610816.0000 - acc: 0.2199 - val_loss: 33137377790656512.0000 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 32006948840800256.0000 - acc: 0.2046 - val_loss: 33861006765588480.0000 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 31194399010455552.0000 - acc: 0.2177 - val_loss: 34625575368785920.0000 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 32805533584982016.0000 - acc: 0.2269 - val_loss: 35365712050520064.0000 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 34182888794619904.0000 - acc: 0.2100 - val_loss: 36162009724616704.0000 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 34277506924150784.0000 - acc: 0.2158 - val_loss: 36948847733243904.0000 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 34862133577515008.0000 - acc: 0.2011 - val_loss: 37764036820992000.0000 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 35565262673543168.0000 - acc: 0.2081 - val_loss: 38572143507668992.0000 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 36736646284050432.0000 - acc: 0.2199 - val_loss: 39395407133933568.0000 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 37406854455754752.0000 - acc: 0.2196 - val_loss: 40235953708597248.0000 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 37812260713791488.0000 - acc: 0.2087 - val_loss: 41053646762278912.0000 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 38975595555586048.0000 - acc: 0.2228 - val_loss: 41940583278706688.0000 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 39408549733859328.0000 - acc: 0.2164 - val_loss: 42835452599730176.0000 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 41052684689604608.0000 - acc: 0.2164 - val_loss: 43699935027134464.0000 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 41558812225699840.0000 - acc: 0.2253 - val_loss: 44587760601792512.0000 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 41329254813663232.0000 - acc: 0.2142 - val_loss: 45517483582423040.0000 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 41683074219507712.0000 - acc: 0.2011 - val_loss: 46476360801058816.0000 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 43781852938371072.0000 - acc: 0.2040 - val_loss: 47409060194025472.0000 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 43084702436818944.0000 - acc: 0.2132 - val_loss: 48368134981156864.0000 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 45412699265302528.0000 - acc: 0.2225 - val_loss: 49339849857040384.0000 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 46638066319753216.0000 - acc: 0.2129 - val_loss: 50318861882359808.0000 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 47894455922982912.0000 - acc: 0.2116 - val_loss: 51298045706371072.0000 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 48252849468997632.0000 - acc: 0.2177 - val_loss: 52283105045643264.0000 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 48516307057901568.0000 - acc: 0.2097 - val_loss: 53325111356293120.0000 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 51623840450609152.0000 - acc: 0.2129 - val_loss: 54402997823733760.0000 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 49750865342365696.0000 - acc: 0.2212 - val_loss: 55477267928711168.0000 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 53185413250023424.0000 - acc: 0.2301 - val_loss: 56571574056124416.0000 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 52060088868798464.0000 - acc: 0.2145 - val_loss: 57708211381207040.0000 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 51606072170905600.0000 - acc: 0.2154 - val_loss: 58784182293233664.0000 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 54803297365655552.0000 - acc: 0.2231 - val_loss: 59932450389753856.0000 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 55949667086630912.0000 - acc: 0.2154 - val_loss: 61050971542781952.0000 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 57120973387726848.0000 - acc: 0.2266 - val_loss: 62217978581614592.0000 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 57388579915038720.0000 - acc: 0.2330 - val_loss: 63385251908419584.0000 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 57416699065925632.0000 - acc: 0.2174 - val_loss: 64558886081789952.0000 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 62231529203433472.0000 - acc: 0.2142 - val_loss: 65737721460555776.0000 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 60150119332315136.0000 - acc: 0.2234 - val_loss: 66938117575147520.0000 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 64263456756334592.0000 - acc: 0.2113 - val_loss: 68168638590353408.0000 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 65348172221775872.0000 - acc: 0.2186 - val_loss: 69427566519255040.0000 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 65608958341021696.0000 - acc: 0.2257 - val_loss: 70692515992305664.0000 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 65675040707837952.0000 - acc: 0.2327 - val_loss: 72033864343617536.0000 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 66273961012363264.0000 - acc: 0.2333 - val_loss: 73330063998713856.0000 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 68293982915919872.0000 - acc: 0.2413 - val_loss: 74662869660073984.0000 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 69678680372150272.0000 - acc: 0.2177 - val_loss: 75990718929174528.0000 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 69116872880029696.0000 - acc: 0.2250 - val_loss: 77429859390849024.0000 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 71227235125690368.0000 - acc: 0.2260 - val_loss: 78790779908128768.0000 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 78249760057720832.0000 - acc: 0.2308 - val_loss: 80181378649423872.0000 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 79599496480161792.0000 - acc: 0.2180 - val_loss: 81570079015174144.0000 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 75686454855991296.0000 - acc: 0.2372 - val_loss: 83034920561147904.0000 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 75096575457624064.0000 - acc: 0.2394 - val_loss: 84505122226307072.0000 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 79305866746003456.0000 - acc: 0.2362 - val_loss: 85995458698149888.0000 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 80281846524411904.0000 - acc: 0.2298 - val_loss: 87461459885293568.0000 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 83918695981645824.0000 - acc: 0.2314 - val_loss: 88968555319525376.0000 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 81630268686860288.0000 - acc: 0.2314 - val_loss: 90537360843866112.0000 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 82782118786105344.0000 - acc: 0.2375 - val_loss: 92150352991748096.0000 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 81119966442553344.0000 - acc: 0.2260 - val_loss: 93759814676512768.0000 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 85478301686038528.0000 - acc: 0.2257 - val_loss: 95332167843840000.0000 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 86030746149453824.0000 - acc: 0.2464 - val_loss: 96955416373624832.0000 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 91737082648592384.0000 - acc: 0.2320 - val_loss: 98580159552028672.0000 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 95284072800059392.0000 - acc: 0.2333 - val_loss: 100210537727524864.0000 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 91444543836127232.0000 - acc: 0.2222 - val_loss: 101877337225691136.0000 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 93595283069337600.0000 - acc: 0.2065 - val_loss: 103604292035805184.0000 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 94025441223901184.0000 - acc: 0.2368 - val_loss: 105290341577392128.0000 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 95210302441783296.0000 - acc: 0.2298 - val_loss: 107088567074816000.0000 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 99642786000666624.0000 - acc: 0.2397 - val_loss: 108856770750840832.0000 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 104500101954666496.0000 - acc: 0.2346 - val_loss: 110593354877632512.0000 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 104486194850562048.0000 - acc: 0.2356 - val_loss: 112437459215712256.0000 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 107648218493353984.0000 - acc: 0.2397 - val_loss: 114254419360481280.0000 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 109397172125958144.0000 - acc: 0.2196 - val_loss: 116046339845914624.0000 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 112207446537142272.0000 - acc: 0.2346 - val_loss: 117949482804445184.0000 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 107957834095788032.0000 - acc: 0.2384 - val_loss: 119813902337835008.0000 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 110839731381600256.0000 - acc: 0.2289 - val_loss: 121656529207164928.0000 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 114522614298312704.0000 - acc: 0.2343 - val_loss: 123690909186392064.0000 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 118082214473760768.0000 - acc: 0.2381 - val_loss: 125594335612764160.0000 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 118406956951011328.0000 - acc: 0.2324 - val_loss: 127570785073102848.0000 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 122700953584402432.0000 - acc: 0.2295 - val_loss: 129550103571595264.0000 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 122220467003064320.0000 - acc: 0.2336 - val_loss: 131600460829163520.0000 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 126137296788389888.0000 - acc: 0.2455 - val_loss: 133621723978268672.0000 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 123218823561084928.0000 - acc: 0.2269 - val_loss: 135713519080308736.0000 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 124994448940597248.0000 - acc: 0.2292 - val_loss: 137821901346045952.0000 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 125024144344481792.0000 - acc: 0.2269 - val_loss: 139938718927552512.0000 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 125150622541414400.0000 - acc: 0.2356 - val_loss: 142129744953999360.0000 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 128783743967035392.0000 - acc: 0.2403 - val_loss: 144365241071828992.0000 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 133626379722817536.0000 - acc: 0.2340 - val_loss: 146574589428760576.0000 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 131335323908046848.0000 - acc: 0.2343 - val_loss: 148809621690122240.0000 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 143216603608121344.0000 - acc: 0.2317 - val_loss: 151000364248727552.0000 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 147050196927250432.0000 - acc: 0.2336 - val_loss: 153215381962489856.0000 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 141229511218823168.0000 - acc: 0.2359 - val_loss: 155492161305968640.0000 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 142468360175616000.0000 - acc: 0.2301 - val_loss: 157809313342029824.0000 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 147932795526709248.0000 - acc: 0.2397 - val_loss: 160147630976925696.0000 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 147978545518346240.0000 - acc: 0.2573 - val_loss: 162615192767692800.0000 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 147220105833480192.0000 - acc: 0.2336 - val_loss: 165036935847346176.0000 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 150849954494021632.0000 - acc: 0.2474 - val_loss: 167521419809259520.0000 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 162937280955154432.0000 - acc: 0.2451 - val_loss: 169928405381283840.0000 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 162468115907608576.0000 - acc: 0.2320 - val_loss: 172519919928213504.0000 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 161385887228231680.0000 - acc: 0.2636 - val_loss: 174988649950085120.0000 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 160917701433229312.0000 - acc: 0.2448 - val_loss: 177550769740840960.0000 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 162262215175438336.0000 - acc: 0.2518 - val_loss: 180029017410240512.0000 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 160412527379873792.0000 - acc: 0.2646 - val_loss: 182721635487318016.0000 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 173413925960810496.0000 - acc: 0.2419 - val_loss: 185440916721369088.0000 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 179995963341930496.0000 - acc: 0.2483 - val_loss: 187960121198903296.0000 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 176772710645366784.0000 - acc: 0.2506 - val_loss: 190677701625905152.0000 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 182326945172684800.0000 - acc: 0.2375 - val_loss: 193437458631753728.0000 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 179505357817643008.0000 - acc: 0.2327 - val_loss: 196121727292407808.0000 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 183711539549700096.0000 - acc: 0.2423 - val_loss: 198848292790992896.0000 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 185148910484848640.0000 - acc: 0.2295 - val_loss: 201634455255777280.0000 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 181225784277467136.0000 - acc: 0.2400 - val_loss: 204589908151500800.0000 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 182599074300559360.0000 - acc: 0.2330 - val_loss: 207476658750357504.0000 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 198221296285253632.0000 - acc: 0.2356 - val_loss: 210427919758000128.0000 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 197344006265372672.0000 - acc: 0.2292 - val_loss: 213363736063246336.0000 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 203821590041853952.0000 - acc: 0.2509 - val_loss: 216321439521832960.0000 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 193794473493266432.0000 - acc: 0.2269 - val_loss: 219287303418281984.0000 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 206514156579323904.0000 - acc: 0.2356 - val_loss: 222296546484420608.0000 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 201372256092291072.0000 - acc: 0.2372 - val_loss: 225473757131571200.0000 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 212022074179321856.0000 - acc: 0.2553 - val_loss: 228416015887761408.0000 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 209753781691219968.0000 - acc: 0.2461 - val_loss: 231564209735860224.0000 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 214905509063426048.0000 - acc: 0.2496 - val_loss: 234653322013835264.0000 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 215981570169765888.0000 - acc: 0.2620 - val_loss: 237961082486915072.0000 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 227862738200690688.0000 - acc: 0.2515 - val_loss: 241172944930209792.0000 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 225357552496410624.0000 - acc: 0.2384 - val_loss: 244506354947981312.0000 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 228239149134512128.0000 - acc: 0.2518 - val_loss: 247741100977029120.0000 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 221760345587318784.0000 - acc: 0.2391 - val_loss: 251117941704097792.0000 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 234022837994651648.0000 - acc: 0.2493 - val_loss: 254504901374115840.0000 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 242589493863907328.0000 - acc: 0.2397 - val_loss: 257695855916613632.0000 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 233510843533230080.0000 - acc: 0.2378 - val_loss: 261143391805374464.0000 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 244424475691450368.0000 - acc: 0.2448 - val_loss: 264521057166163968.0000 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 238988696362156032.0000 - acc: 0.2455 - val_loss: 268107715635576832.0000 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 253584060385853440.0000 - acc: 0.2317 - val_loss: 271717584108257280.0000 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 248138265192824832.0000 - acc: 0.2560 - val_loss: 275180547519545344.0000 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 253844455663075328.0000 - acc: 0.2576 - val_loss: 278695256696815616.0000 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 257312968172109824.0000 - acc: 0.2614 - val_loss: 282443371576819712.0000 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 248934534949634048.0000 - acc: 0.2534 - val_loss: 286108026652327936.0000 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 267064416539770880.0000 - acc: 0.2483 - val_loss: 289785463550509056.0000 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 263213651941392384.0000 - acc: 0.2458 - val_loss: 293564553734651904.0000 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 271689391942926336.0000 - acc: 0.2397 - val_loss: 297423461591023616.0000 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 270231989280309248.0000 - acc: 0.2340 - val_loss: 301261684884897792.0000 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 269772548038721536.0000 - acc: 0.2461 - val_loss: 305053041495638016.0000 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 282602560244678656.0000 - acc: 0.2579 - val_loss: 309017639907229696.0000 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 287505179513716736.0000 - acc: 0.2534 - val_loss: 312912934726533120.0000 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 278741126947536896.0000 - acc: 0.2522 - val_loss: 317003324140290048.0000 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 290174518868049920.0000 - acc: 0.2461 - val_loss: 320986167572955136.0000 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 295424893049110528.0000 - acc: 0.2407 - val_loss: 324965197074661376.0000 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 312158566670663680.0000 - acc: 0.2486 - val_loss: 329055586488418304.0000 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 309433633259651072.0000 - acc: 0.2455 - val_loss: 333072239903637504.0000 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 309273242000949248.0000 - acc: 0.2442 - val_loss: 337212244779597824.0000 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 315953737212362752.0000 - acc: 0.2703 - val_loss: 341491578394640384.0000 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 321574028336693248.0000 - acc: 0.2624 - val_loss: 345704666434109440.0000 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 337187127810850816.0000 - acc: 0.2582 - val_loss: 350123225709019136.0000 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 319959429871042560.0000 - acc: 0.2528 - val_loss: 354300132943986688.0000 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 328801668021878784.0000 - acc: 0.2550 - val_loss: 358653752313380864.0000 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 339307879582400512.0000 - acc: 0.2643 - val_loss: 363036371301957632.0000 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 338527604283801600.0000 - acc: 0.2739 - val_loss: 367442320552886272.0000 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 327414084347625472.0000 - acc: 0.2739 - val_loss: 372048690157715456.0000 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 334668524628738048.0000 - acc: 0.2493 - val_loss: 376442854018383872.0000 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 343435171355164672.0000 - acc: 0.2589 - val_loss: 380991258744586240.0000 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 361501487429320704.0000 - acc: 0.2620 - val_loss: 385787809501282304.0000 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 355760662342795264.0000 - acc: 0.2592 - val_loss: 390458431816859648.0000 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 358929214335877120.0000 - acc: 0.2662 - val_loss: 395189836509609984.0000 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 344621269523628032.0000 - acc: 0.2528 - val_loss: 400036140167462912.0000 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 366036698015989760.0000 - acc: 0.2617 - val_loss: 404803519506284544.0000 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 369309188217634816.0000 - acc: 0.2528 - val_loss: 409747507900317696.0000 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 384414725636620288.0000 - acc: 0.2563 - val_loss: 414625834834329600.0000 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 392280356943822848.0000 - acc: 0.2525 - val_loss: 419657062604079104.0000 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 399107602597806080.0000 - acc: 0.2585 - val_loss: 424663620081680384.0000 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 392063478275244032.0000 - acc: 0.2550 - val_loss: 429677152586170368.0000 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 406351357000286208.0000 - acc: 0.2595 - val_loss: 434746931982368768.0000 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 402208431546564608.0000 - acc: 0.2525 - val_loss: 439910513464311808.0000 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 407403177311207424.0000 - acc: 0.2569 - val_loss: 445179098306707456.0000 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 412883624300380160.0000 - acc: 0.2614 - val_loss: 450397552290824192.0000 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 416483494089195520.0000 - acc: 0.2774 - val_loss: 455503271973355520.0000 - val_acc: 0.9026\n",
      "Epoch 197/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 409615703943938048.0000 - acc: 0.2582 - val_loss: 460864215792484352.0000 - val_acc: 0.9026\n",
      "Epoch 198/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 416322793592848384.0000 - acc: 0.2758 - val_loss: 466310543561457664.0000 - val_acc: 0.9026\n",
      "Epoch 199/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 432302030439055360.0000 - acc: 0.2659 - val_loss: 471503605698920448.0000 - val_acc: 0.9026\n",
      "Epoch 200/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 436458802867339264.0000 - acc: 0.2601 - val_loss: 477114104297816064.0000 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 433368591077736448.0000 - acc: 0.2694 - val_loss: 482860152064573440.0000 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 438002242314829824.0000 - acc: 0.2477 - val_loss: 488330909607526400.0000 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 430987048891973632.0000 - acc: 0.2668 - val_loss: 494211888066854912.0000 - val_acc: 0.9026\n",
      "Epoch 204/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 447716530625445888.0000 - acc: 0.2589 - val_loss: 499885780383039488.0000 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 455308520976285696.0000 - acc: 0.2541 - val_loss: 505806444340183040.0000 - val_acc: 0.9026\n",
      "Epoch 206/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 452857675198234624.0000 - acc: 0.2771 - val_loss: 511466489681805312.0000 - val_acc: 0.9026\n",
      "Epoch 207/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 489418154808705024.0000 - acc: 0.2745 - val_loss: 517151342754529280.0000 - val_acc: 0.9026\n",
      "Epoch 208/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 466996398299021312.0000 - acc: 0.2646 - val_loss: 523075477045248000.0000 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 485822133310586880.0000 - acc: 0.2627 - val_loss: 528941474658648064.0000 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 497532035225616384.0000 - acc: 0.2681 - val_loss: 534925738491510784.0000 - val_acc: 0.9026\n",
      "Epoch 211/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 513735400645197824.0000 - acc: 0.2636 - val_loss: 540819876730634240.0000 - val_acc: 0.9026\n",
      "Epoch 212/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 477154133393014784.0000 - acc: 0.2681 - val_loss: 547153579102699520.0000 - val_acc: 0.9026\n",
      "Epoch 213/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 515356561820876800.0000 - acc: 0.2691 - val_loss: 553127775532220416.0000 - val_acc: 0.9026\n",
      "Epoch 214/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 497838043055521792.0000 - acc: 0.2582 - val_loss: 559334037634678784.0000 - val_acc: 0.9026\n",
      "Epoch 215/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 504043033847660544.0000 - acc: 0.2688 - val_loss: 565710277362843648.0000 - val_acc: 0.9026\n",
      "Epoch 216/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 502455476496105472.0000 - acc: 0.2614 - val_loss: 572093560837373952.0000 - val_acc: 0.9026\n",
      "Epoch 217/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 507634313701883904.0000 - acc: 0.2742 - val_loss: 578460076759580672.0000 - val_acc: 0.9026\n",
      "Epoch 218/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 549343531387322368.0000 - acc: 0.2735 - val_loss: 584986159306768384.0000 - val_acc: 0.9026\n",
      "Epoch 219/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 530532399264563200.0000 - acc: 0.2643 - val_loss: 591479874980413440.0000 - val_acc: 0.9026\n",
      "Epoch 220/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 540313826503950336.0000 - acc: 0.2630 - val_loss: 598104295098810368.0000 - val_acc: 0.9026\n",
      "Epoch 221/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 563449303499014144.0000 - acc: 0.2640 - val_loss: 604759226664878080.0000 - val_acc: 0.9026\n",
      "Epoch 222/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 553623827075039232.0000 - acc: 0.2659 - val_loss: 611266480075440128.0000 - val_acc: 0.9026\n",
      "Epoch 223/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 555408746763780096.0000 - acc: 0.2608 - val_loss: 617981816061558784.0000 - val_acc: 0.9026\n",
      "Epoch 224/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 559618879865749504.0000 - acc: 0.2611 - val_loss: 624873073908121600.0000 - val_acc: 0.9026\n",
      "Epoch 225/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 575670581400174592.0000 - acc: 0.2694 - val_loss: 631556936373895168.0000 - val_acc: 0.9026\n",
      "Epoch 226/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 566989559141761024.0000 - acc: 0.2656 - val_loss: 638570377450094592.0000 - val_acc: 0.9026\n",
      "Epoch 227/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 566386580093140992.0000 - acc: 0.2640 - val_loss: 645487267661479936.0000 - val_acc: 0.9026\n",
      "Epoch 228/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 612335755133452288.0000 - acc: 0.2726 - val_loss: 652548400054534144.0000 - val_acc: 0.9026\n",
      "Epoch 229/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 614847520727629824.0000 - acc: 0.2672 - val_loss: 659545898212130816.0000 - val_acc: 0.9026\n",
      "Epoch 230/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 597716098774728704.0000 - acc: 0.2630 - val_loss: 666620499622625280.0000 - val_acc: 0.9026\n",
      "Epoch 231/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 637168843722063872.0000 - acc: 0.2818 - val_loss: 673755642892124160.0000 - val_acc: 0.9026\n",
      "Epoch 232/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 623214460617621504.0000 - acc: 0.2672 - val_loss: 680893672379645952.0000 - val_acc: 0.9026\n",
      "Epoch 233/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 617635332459855872.0000 - acc: 0.2793 - val_loss: 688182609838080000.0000 - val_acc: 0.9026\n",
      "Epoch 234/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 647721612728074240.0000 - acc: 0.2499 - val_loss: 695586240103186432.0000 - val_acc: 0.9026\n",
      "Epoch 235/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 657017296346152960.0000 - acc: 0.2866 - val_loss: 702879438169178112.0000 - val_acc: 0.9026\n",
      "Epoch 236/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 645502248507408384.0000 - acc: 0.2735 - val_loss: 710270561489518592.0000 - val_acc: 0.9026\n",
      "Epoch 237/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 660629260762873856.0000 - acc: 0.2825 - val_loss: 717787578891239424.0000 - val_acc: 0.9026\n",
      "Epoch 238/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 674482351358607360.0000 - acc: 0.2742 - val_loss: 725317790432493568.0000 - val_acc: 0.9026\n",
      "Epoch 239/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 643480452782358528.0000 - acc: 0.2700 - val_loss: 733055122476630016.0000 - val_acc: 0.9026\n",
      "Epoch 240/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 677502160044294144.0000 - acc: 0.2620 - val_loss: 741082107115208704.0000 - val_acc: 0.9026\n",
      "Epoch 241/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 671900491898159104.0000 - acc: 0.2841 - val_loss: 748795181184057344.0000 - val_acc: 0.9026\n",
      "Epoch 242/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 665056169454206976.0000 - acc: 0.2688 - val_loss: 756734204892413952.0000 - val_acc: 0.9026\n",
      "Epoch 243/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 716355602435014656.0000 - acc: 0.2793 - val_loss: 764364471991795712.0000 - val_acc: 0.9026\n",
      "Epoch 244/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 704452770589048832.0000 - acc: 0.2652 - val_loss: 772412622229209088.0000 - val_acc: 0.9026\n",
      "Epoch 245/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 713334213201362944.0000 - acc: 0.2796 - val_loss: 780405384568373248.0000 - val_acc: 0.9026\n",
      "Epoch 246/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 736431791405006848.0000 - acc: 0.2633 - val_loss: 788441371458404352.0000 - val_acc: 0.9026\n",
      "Epoch 247/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 723780260860002304.0000 - acc: 0.2777 - val_loss: 796550819469066240.0000 - val_acc: 0.9026\n",
      "Epoch 248/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 747367121738006528.0000 - acc: 0.2783 - val_loss: 804549354244276224.0000 - val_acc: 0.9026\n",
      "Epoch 249/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 757782108193161216.0000 - acc: 0.2806 - val_loss: 813076685392969728.0000 - val_acc: 0.9026\n",
      "Epoch 250/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 741624166347702272.0000 - acc: 0.2853 - val_loss: 821645179508228096.0000 - val_acc: 0.9026\n",
      "Epoch 251/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 781612098579857408.0000 - acc: 0.2742 - val_loss: 830117878672916480.0000 - val_acc: 0.9026\n",
      "Epoch 252/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 762560379569045504.0000 - acc: 0.2838 - val_loss: 838235710459740160.0000 - val_acc: 0.9026\n",
      "Epoch 253/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 782129212642295808.0000 - acc: 0.2681 - val_loss: 846694871887511552.0000 - val_acc: 0.9026\n",
      "Epoch 254/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 765257137994596352.0000 - acc: 0.2742 - val_loss: 855268176366141440.0000 - val_acc: 0.9026\n",
      "Epoch 255/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 784530065001021440.0000 - acc: 0.2758 - val_loss: 864061314450849792.0000 - val_acc: 0.9026\n",
      "Epoch 256/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 789244427263541248.0000 - acc: 0.2767 - val_loss: 872748418382954496.0000 - val_acc: 0.9026\n",
      "Epoch 257/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 849163825247682560.0000 - acc: 0.2818 - val_loss: 881756579710369792.0000 - val_acc: 0.9026\n",
      "Epoch 258/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 793292829077012480.0000 - acc: 0.2936 - val_loss: 890685301322678272.0000 - val_acc: 0.9026\n",
      "Epoch 259/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 842151208805203968.0000 - acc: 0.2780 - val_loss: 899917350705299456.0000 - val_acc: 0.9026\n",
      "Epoch 260/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 860540265901850624.0000 - acc: 0.2901 - val_loss: 908561917281304576.0000 - val_acc: 0.9026\n",
      "Epoch 261/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 829518988433162240.0000 - acc: 0.2901 - val_loss: 917491463527333888.0000 - val_acc: 0.9026\n",
      "Epoch 262/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 865753050529136640.0000 - acc: 0.2895 - val_loss: 926717053279141888.0000 - val_acc: 0.9026\n",
      "Epoch 263/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 864969717213822976.0000 - acc: 0.2790 - val_loss: 935924226211184640.0000 - val_acc: 0.9026\n",
      "Epoch 264/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 872552636593733632.0000 - acc: 0.2745 - val_loss: 945440705508016128.0000 - val_acc: 0.9026\n",
      "Epoch 265/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 891481279021711360.0000 - acc: 0.2761 - val_loss: 954544455627571200.0000 - val_acc: 0.9026\n",
      "Epoch 266/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 857399717095538688.0000 - acc: 0.2786 - val_loss: 964078939427307520.0000 - val_acc: 0.9026\n",
      "Epoch 267/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 888707417343262720.0000 - acc: 0.2825 - val_loss: 973701315437789184.0000 - val_acc: 0.9026\n",
      "Epoch 268/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 872461926884442112.0000 - acc: 0.2697 - val_loss: 983348774057279488.0000 - val_acc: 0.9026\n",
      "Epoch 269/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 901201923883925504.0000 - acc: 0.2822 - val_loss: 993066670140424192.0000 - val_acc: 0.9026\n",
      "Epoch 270/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 893333681236606976.0000 - acc: 0.2764 - val_loss: 1003096071611613184.0000 - val_acc: 0.9026\n",
      "Epoch 271/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 897585080384356352.0000 - acc: 0.2761 - val_loss: 1013439452372008960.0000 - val_acc: 0.9026\n",
      "Epoch 272/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 904933941226504192.0000 - acc: 0.2786 - val_loss: 1023578323969638400.0000 - val_acc: 0.9026\n",
      "Epoch 273/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 936285140903002112.0000 - acc: 0.2774 - val_loss: 1033423900840558592.0000 - val_acc: 0.9026\n",
      "Epoch 274/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 947318740087734272.0000 - acc: 0.2908 - val_loss: 1043434473175121920.0000 - val_acc: 0.9026\n",
      "Epoch 275/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 978850190951710720.0000 - acc: 0.2879 - val_loss: 1053459751477706752.0000 - val_acc: 0.9026\n",
      "Epoch 276/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 952598388765884416.0000 - acc: 0.2633 - val_loss: 1063547358345691136.0000 - val_acc: 0.9026\n",
      "Epoch 277/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 968110023932641280.0000 - acc: 0.2863 - val_loss: 1073962963276136448.0000 - val_acc: 0.9026\n",
      "Epoch 278/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1012796925264527360.0000 - acc: 0.2841 - val_loss: 1083966801101979648.0000 - val_acc: 0.9026\n",
      "Epoch 279/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 978991959232217088.0000 - acc: 0.2882 - val_loss: 1094990916998922240.0000 - val_acc: 0.9026\n",
      "Epoch 280/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 975752042062544896.0000 - acc: 0.2751 - val_loss: 1105712323600842752.0000 - val_acc: 0.9026\n",
      "Epoch 281/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 996155198302846976.0000 - acc: 0.2834 - val_loss: 1116580858602455040.0000 - val_acc: 0.9026\n",
      "Epoch 282/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1015086177193033728.0000 - acc: 0.2726 - val_loss: 1127223718842466304.0000 - val_acc: 0.9026\n",
      "Epoch 283/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1073359262673010688.0000 - acc: 0.2771 - val_loss: 1137907261012705280.0000 - val_acc: 0.9026\n",
      "Epoch 284/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 985866793123840000.0000 - acc: 0.2761 - val_loss: 1148928834289008640.0000 - val_acc: 0.9026\n",
      "Epoch 285/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 997884867532292096.0000 - acc: 0.2783 - val_loss: 1160254834847252480.0000 - val_acc: 0.9026\n",
      "Epoch 286/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1055062014797283328.0000 - acc: 0.2847 - val_loss: 1171125706311073792.0000 - val_acc: 0.9026\n",
      "Epoch 287/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1067439011032727552.0000 - acc: 0.2678 - val_loss: 1182211119981264896.0000 - val_acc: 0.9026\n",
      "Epoch 288/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1123633882097254400.0000 - acc: 0.2783 - val_loss: 1193349585087496192.0000 - val_acc: 0.9026\n",
      "Epoch 289/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1086375968517390336.0000 - acc: 0.2863 - val_loss: 1204436922903035904.0000 - val_acc: 0.9026\n",
      "Epoch 290/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1064063166738071552.0000 - acc: 0.2949 - val_loss: 1215778660221452288.0000 - val_acc: 0.9026\n",
      "Epoch 291/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1114354072678301696.0000 - acc: 0.2972 - val_loss: 1227322157923565568.0000 - val_acc: 0.9026\n",
      "Epoch 292/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1114275732474822656.0000 - acc: 0.2857 - val_loss: 1238601223079198720.0000 - val_acc: 0.9026\n",
      "Epoch 293/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1099143360100171776.0000 - acc: 0.2994 - val_loss: 1250280510467342336.0000 - val_acc: 0.9026\n",
      "Epoch 294/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1172676292584144896.0000 - acc: 0.2949 - val_loss: 1261667877518311424.0000 - val_acc: 0.9026\n",
      "Epoch 295/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1175187164825124864.0000 - acc: 0.2853 - val_loss: 1273509892627365888.0000 - val_acc: 0.9026\n",
      "Epoch 296/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1145876933607686144.0000 - acc: 0.2863 - val_loss: 1285305728248053760.0000 - val_acc: 0.9026\n",
      "Epoch 297/300\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1195846438555222016.0000 - acc: 0.2936 - val_loss: 1297056209014095872.0000 - val_acc: 0.9026\n",
      "Epoch 298/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1238245943384473600.0000 - acc: 0.2914 - val_loss: 1309159220695793664.0000 - val_acc: 0.9026\n",
      "Epoch 299/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1209305697829781504.0000 - acc: 0.2917 - val_loss: 1321222512519938048.0000 - val_acc: 0.9026\n",
      "Epoch 300/300\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1225817888577814528.0000 - acc: 0.2812 - val_loss: 1333461726204526592.0000 - val_acc: 0.9026\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_word_tr,y_tr,epochs = 300,validation_data = (X_word_te,y_te),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "C9MVYlgijs5y",
    "outputId": "8ac800ee-8e75-46e4-b01f-00110db4e357",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MT7pb8jnjs50"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_word_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "beF0LAlFjs53"
   },
   "outputs": [],
   "source": [
    "pred_tags = get_tags(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nah6bFg8rBoX"
   },
   "outputs": [],
   "source": [
    "hits,count_pad,count_o = get_hits(y_te,pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Z_rxP8D7js55",
    "outputId": "be2d7964-f7fd-43b9-d5c5-adb41f3a245b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tags : 26175\n",
      "# of 'P' : 19946\n",
      "# of 'O' : 5403\n",
      "Total tags left without O,P : 826\n",
      "# of hits without 'PAD' and 'O' : 0\n",
      "# of predicted - 'O' : 0\n",
      "# of predicted - 'PAD' : 26175\n",
      "Accuracy rate :  0.0\n"
     ]
    }
   ],
   "source": [
    "print_scores(hits,count_pad,count_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qaJymwLcjs5-"
   },
   "source": [
    "most of the tags are PADDINGS, so in order to get a small loss, the NN learned to give all the words the tag \"PAD\"(0).\n",
    "we can go deeper with the net, adding some dropouts and use different initializers, but the best practice for sequenced data is undoubtedly RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jJL0X09unqg"
   },
   "source": [
    "## Model 2: Simple LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VkAEY2PCjs5_"
   },
   "source": [
    "In this model, I have tryed a simple RNN, which is built from a input layer, embedding layer, an LSTM layer and a dense layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgS3Ip0Wjs5_"
   },
   "source": [
    "### Layers explanation :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMIXjrJynbiE"
   },
   "source": [
    "#### Embedding layer \n",
    "the Embedding layer turns positive integers (indexes) into dense vectors of fixed size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KX27_8gZneR8"
   },
   "source": [
    "#### LSTM layer \n",
    "Long Short-Term Memory layer - Hochreiter 1997.\n",
    "A special kind of RNN, capable of learning long-term dependencies.\n",
    "LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n",
    "\n",
    "There are several architectures of LSTM units. A common architecture is composed of a cell (the memory part of the LSTM unit) and three \"regulators\", usually called gates, of the flow of information inside the LSTM unit: an input gate, an output gate and a forget gate. Some variations of the LSTM unit do not have one or more of these gates or maybe have other gates. For example, gated recurrent units (GRUs) do not have an output gate.\n",
    "\n",
    "The compact forms of the equations for the forward pass of an LSTM unit with a forget gate are:\n",
    "\n",
    "<math>\n",
    "\\begin{align}\n",
    "f_t &= \\sigma_g(W_{f} x_t + U_{f} h_{t-1} + b_f) \\\\\n",
    "i_t &= \\sigma_g(W_{i} x_t + U_{i} h_{t-1} + b_i) \\\\\n",
    "o_t &= \\sigma_g(W_{o} x_t + U_{o} h_{t-1} + b_o) \\\\\n",
    "\\tilde{c}_t &= \\sigma_c(W_{c} x_t + U_{c} h_{t-1} + b_c) \\\\\n",
    "c_t &= f_t \\circ c_{t-1} + i_t \\circ \\tilde{c}_t \\\\\n",
    "h_t &= o_t \\circ \\sigma_h(c_t)\n",
    "\\end{align}\n",
    "</math>\n",
    "https://en.wikipedia.org/wiki/Long_short-term_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ff5jUXzzunqh"
   },
   "outputs": [],
   "source": [
    "word_input = Input(shape = (X_word_tr.shape[1],))\n",
    "emb_word = Embedding(input_dim = n_words + 1,output_dim=16,mask_zero = True,input_length = max_len)(word_input)\n",
    "\n",
    "lstm1 = LSTM(units=8, return_sequences=True)(emb_word)\n",
    "\n",
    "out = Dense(n_tags,activation = 'softmax')(lstm1)\n",
    "\n",
    "model = Model(word_input,out)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "7mOh5nmsunql",
    "outputId": "1b9d8ad6-ed9f-4738-f0ee-33294b83985b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 75)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 75, 16)            300048    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 75, 8)             800       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 75, 19)            171       \n",
      "=================================================================\n",
      "Total params: 301,019\n",
      "Trainable params: 301,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lMdzIb_Sunqn",
    "outputId": "80451c3d-943f-453b-ad54-dff6a4ec1879",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.6678 - acc: 0.6219 - val_loss: 0.6899 - val_acc: 0.8671\n",
      "Epoch 2/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.6554 - acc: 0.8589 - val_loss: 0.6741 - val_acc: 0.8671\n",
      "Epoch 3/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6364 - acc: 0.8589 - val_loss: 0.6476 - val_acc: 0.8671\n",
      "Epoch 4/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6017 - acc: 0.8589 - val_loss: 0.5951 - val_acc: 0.8671\n",
      "Epoch 5/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5359 - acc: 0.8589 - val_loss: 0.5097 - val_acc: 0.8671\n",
      "Epoch 6/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4535 - acc: 0.8589 - val_loss: 0.4271 - val_acc: 0.8671\n",
      "Epoch 7/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3819 - acc: 0.8589 - val_loss: 0.3616 - val_acc: 0.8671\n",
      "Epoch 8/250\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.3264 - acc: 0.8589 - val_loss: 0.3131 - val_acc: 0.8671\n",
      "Epoch 9/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2855 - acc: 0.8589 - val_loss: 0.2781 - val_acc: 0.8671\n",
      "Epoch 10/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2563 - acc: 0.8589 - val_loss: 0.2532 - val_acc: 0.8671\n",
      "Epoch 11/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2356 - acc: 0.8589 - val_loss: 0.2356 - val_acc: 0.8671\n",
      "Epoch 12/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2207 - acc: 0.8589 - val_loss: 0.2229 - val_acc: 0.8671\n",
      "Epoch 13/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2098 - acc: 0.8589 - val_loss: 0.2134 - val_acc: 0.8671\n",
      "Epoch 14/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2014 - acc: 0.8589 - val_loss: 0.2060 - val_acc: 0.8671\n",
      "Epoch 15/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1948 - acc: 0.8589 - val_loss: 0.2002 - val_acc: 0.8671\n",
      "Epoch 16/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1894 - acc: 0.8589 - val_loss: 0.1954 - val_acc: 0.8671\n",
      "Epoch 17/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1849 - acc: 0.8589 - val_loss: 0.1914 - val_acc: 0.8671\n",
      "Epoch 18/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1811 - acc: 0.8589 - val_loss: 0.1880 - val_acc: 0.8673\n",
      "Epoch 19/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1777 - acc: 0.8589 - val_loss: 0.1850 - val_acc: 0.8673\n",
      "Epoch 20/250\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1747 - acc: 0.8589 - val_loss: 0.1824 - val_acc: 0.8673\n",
      "Epoch 21/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1719 - acc: 0.8589 - val_loss: 0.1799 - val_acc: 0.8673\n",
      "Epoch 22/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1693 - acc: 0.8589 - val_loss: 0.1777 - val_acc: 0.8673\n",
      "Epoch 23/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1668 - acc: 0.8589 - val_loss: 0.1756 - val_acc: 0.8673\n",
      "Epoch 24/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1644 - acc: 0.8589 - val_loss: 0.1735 - val_acc: 0.8673\n",
      "Epoch 25/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1620 - acc: 0.8589 - val_loss: 0.1715 - val_acc: 0.8673\n",
      "Epoch 26/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1596 - acc: 0.8589 - val_loss: 0.1696 - val_acc: 0.8671\n",
      "Epoch 27/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1572 - acc: 0.8590 - val_loss: 0.1676 - val_acc: 0.8671\n",
      "Epoch 28/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1548 - acc: 0.8591 - val_loss: 0.1656 - val_acc: 0.8671\n",
      "Epoch 29/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1523 - acc: 0.8592 - val_loss: 0.1636 - val_acc: 0.8670\n",
      "Epoch 30/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1497 - acc: 0.8592 - val_loss: 0.1616 - val_acc: 0.8670\n",
      "Epoch 31/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1472 - acc: 0.8592 - val_loss: 0.1596 - val_acc: 0.8670\n",
      "Epoch 32/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1446 - acc: 0.8593 - val_loss: 0.1576 - val_acc: 0.8668\n",
      "Epoch 33/250\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1420 - acc: 0.8594 - val_loss: 0.1556 - val_acc: 0.8668\n",
      "Epoch 34/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1394 - acc: 0.8594 - val_loss: 0.1537 - val_acc: 0.8668\n",
      "Epoch 35/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1369 - acc: 0.8594 - val_loss: 0.1518 - val_acc: 0.8668\n",
      "Epoch 36/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1345 - acc: 0.8594 - val_loss: 0.1500 - val_acc: 0.8670\n",
      "Epoch 37/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1321 - acc: 0.8595 - val_loss: 0.1483 - val_acc: 0.8671\n",
      "Epoch 38/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1298 - acc: 0.8596 - val_loss: 0.1466 - val_acc: 0.8668\n",
      "Epoch 39/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1277 - acc: 0.8596 - val_loss: 0.1451 - val_acc: 0.8666\n",
      "Epoch 40/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1256 - acc: 0.8597 - val_loss: 0.1436 - val_acc: 0.8666\n",
      "Epoch 41/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1237 - acc: 0.8598 - val_loss: 0.1423 - val_acc: 0.8665\n",
      "Epoch 42/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1219 - acc: 0.8599 - val_loss: 0.1409 - val_acc: 0.8663\n",
      "Epoch 43/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1202 - acc: 0.8600 - val_loss: 0.1397 - val_acc: 0.8663\n",
      "Epoch 44/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1186 - acc: 0.8604 - val_loss: 0.1386 - val_acc: 0.8666\n",
      "Epoch 45/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1171 - acc: 0.8607 - val_loss: 0.1376 - val_acc: 0.8668\n",
      "Epoch 46/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1157 - acc: 0.8609 - val_loss: 0.1366 - val_acc: 0.8681\n",
      "Epoch 47/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1144 - acc: 0.8611 - val_loss: 0.1356 - val_acc: 0.8687\n",
      "Epoch 48/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1132 - acc: 0.8613 - val_loss: 0.1347 - val_acc: 0.8689\n",
      "Epoch 49/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1120 - acc: 0.8614 - val_loss: 0.1339 - val_acc: 0.8692\n",
      "Epoch 50/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1109 - acc: 0.8614 - val_loss: 0.1331 - val_acc: 0.8692\n",
      "Epoch 51/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1099 - acc: 0.8614 - val_loss: 0.1324 - val_acc: 0.8690\n",
      "Epoch 52/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1089 - acc: 0.8614 - val_loss: 0.1317 - val_acc: 0.8689\n",
      "Epoch 53/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1080 - acc: 0.8614 - val_loss: 0.1311 - val_acc: 0.8687\n",
      "Epoch 54/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1071 - acc: 0.8612 - val_loss: 0.1305 - val_acc: 0.8689\n",
      "Epoch 55/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1063 - acc: 0.8613 - val_loss: 0.1300 - val_acc: 0.8684\n",
      "Epoch 56/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1055 - acc: 0.8614 - val_loss: 0.1294 - val_acc: 0.8679\n",
      "Epoch 57/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1048 - acc: 0.8614 - val_loss: 0.1289 - val_acc: 0.8671\n",
      "Epoch 58/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1041 - acc: 0.8615 - val_loss: 0.1284 - val_acc: 0.8671\n",
      "Epoch 59/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1034 - acc: 0.8616 - val_loss: 0.1280 - val_acc: 0.8662\n",
      "Epoch 60/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1027 - acc: 0.8618 - val_loss: 0.1276 - val_acc: 0.8660\n",
      "Epoch 61/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1021 - acc: 0.8620 - val_loss: 0.1272 - val_acc: 0.8655\n",
      "Epoch 62/250\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1015 - acc: 0.8620 - val_loss: 0.1268 - val_acc: 0.8652\n",
      "Epoch 63/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1009 - acc: 0.8621 - val_loss: 0.1264 - val_acc: 0.8652\n",
      "Epoch 64/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1004 - acc: 0.8621 - val_loss: 0.1260 - val_acc: 0.8647\n",
      "Epoch 65/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0998 - acc: 0.8621 - val_loss: 0.1257 - val_acc: 0.8645\n",
      "Epoch 66/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0993 - acc: 0.8623 - val_loss: 0.1253 - val_acc: 0.8647\n",
      "Epoch 67/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0988 - acc: 0.8625 - val_loss: 0.1250 - val_acc: 0.8644\n",
      "Epoch 68/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0984 - acc: 0.8626 - val_loss: 0.1247 - val_acc: 0.8645\n",
      "Epoch 69/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0979 - acc: 0.8628 - val_loss: 0.1244 - val_acc: 0.8645\n",
      "Epoch 70/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0974 - acc: 0.8631 - val_loss: 0.1240 - val_acc: 0.8645\n",
      "Epoch 71/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0970 - acc: 0.8634 - val_loss: 0.1237 - val_acc: 0.8650\n",
      "Epoch 72/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0966 - acc: 0.8638 - val_loss: 0.1235 - val_acc: 0.8652\n",
      "Epoch 73/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0961 - acc: 0.8642 - val_loss: 0.1232 - val_acc: 0.8652\n",
      "Epoch 74/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0957 - acc: 0.8645 - val_loss: 0.1229 - val_acc: 0.8652\n",
      "Epoch 75/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0953 - acc: 0.8648 - val_loss: 0.1227 - val_acc: 0.8655\n",
      "Epoch 76/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0949 - acc: 0.8653 - val_loss: 0.1224 - val_acc: 0.8657\n",
      "Epoch 77/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0946 - acc: 0.8660 - val_loss: 0.1222 - val_acc: 0.8649\n",
      "Epoch 78/250\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0942 - acc: 0.8664 - val_loss: 0.1219 - val_acc: 0.8652\n",
      "Epoch 79/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0938 - acc: 0.8668 - val_loss: 0.1217 - val_acc: 0.8647\n",
      "Epoch 80/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0935 - acc: 0.8673 - val_loss: 0.1214 - val_acc: 0.8650\n",
      "Epoch 81/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0931 - acc: 0.8679 - val_loss: 0.1212 - val_acc: 0.8650\n",
      "Epoch 82/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0928 - acc: 0.8683 - val_loss: 0.1210 - val_acc: 0.8650\n",
      "Epoch 83/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0924 - acc: 0.8689 - val_loss: 0.1207 - val_acc: 0.8650\n",
      "Epoch 84/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0921 - acc: 0.8695 - val_loss: 0.1205 - val_acc: 0.8654\n",
      "Epoch 85/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0917 - acc: 0.8699 - val_loss: 0.1202 - val_acc: 0.8655\n",
      "Epoch 86/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0914 - acc: 0.8706 - val_loss: 0.1200 - val_acc: 0.8660\n",
      "Epoch 87/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0910 - acc: 0.8712 - val_loss: 0.1198 - val_acc: 0.8663\n",
      "Epoch 88/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0907 - acc: 0.8718 - val_loss: 0.1196 - val_acc: 0.8666\n",
      "Epoch 89/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0904 - acc: 0.8724 - val_loss: 0.1193 - val_acc: 0.8670\n",
      "Epoch 90/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0901 - acc: 0.8732 - val_loss: 0.1191 - val_acc: 0.8676\n",
      "Epoch 91/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0897 - acc: 0.8740 - val_loss: 0.1189 - val_acc: 0.8682\n",
      "Epoch 92/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0894 - acc: 0.8748 - val_loss: 0.1187 - val_acc: 0.8686\n",
      "Epoch 93/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0891 - acc: 0.8759 - val_loss: 0.1185 - val_acc: 0.8695\n",
      "Epoch 94/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0888 - acc: 0.8772 - val_loss: 0.1183 - val_acc: 0.8695\n",
      "Epoch 95/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0884 - acc: 0.8783 - val_loss: 0.1181 - val_acc: 0.8695\n",
      "Epoch 96/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0881 - acc: 0.8795 - val_loss: 0.1178 - val_acc: 0.8702\n",
      "Epoch 97/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0878 - acc: 0.8804 - val_loss: 0.1176 - val_acc: 0.8705\n",
      "Epoch 98/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0875 - acc: 0.8812 - val_loss: 0.1174 - val_acc: 0.8716\n",
      "Epoch 99/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0871 - acc: 0.8821 - val_loss: 0.1172 - val_acc: 0.8724\n",
      "Epoch 100/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0868 - acc: 0.8831 - val_loss: 0.1170 - val_acc: 0.8726\n",
      "Epoch 101/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0865 - acc: 0.8840 - val_loss: 0.1168 - val_acc: 0.8735\n",
      "Epoch 102/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0861 - acc: 0.8847 - val_loss: 0.1166 - val_acc: 0.8743\n",
      "Epoch 103/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0858 - acc: 0.8857 - val_loss: 0.1164 - val_acc: 0.8747\n",
      "Epoch 104/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0854 - acc: 0.8865 - val_loss: 0.1162 - val_acc: 0.8763\n",
      "Epoch 105/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0851 - acc: 0.8879 - val_loss: 0.1159 - val_acc: 0.8775\n",
      "Epoch 106/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0847 - acc: 0.8895 - val_loss: 0.1156 - val_acc: 0.8782\n",
      "Epoch 107/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0843 - acc: 0.8911 - val_loss: 0.1154 - val_acc: 0.8787\n",
      "Epoch 108/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0839 - acc: 0.8928 - val_loss: 0.1152 - val_acc: 0.8788\n",
      "Epoch 109/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0835 - acc: 0.8946 - val_loss: 0.1149 - val_acc: 0.8796\n",
      "Epoch 110/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0831 - acc: 0.8964 - val_loss: 0.1146 - val_acc: 0.8803\n",
      "Epoch 111/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0826 - acc: 0.8986 - val_loss: 0.1143 - val_acc: 0.8811\n",
      "Epoch 112/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0821 - acc: 0.9008 - val_loss: 0.1140 - val_acc: 0.8824\n",
      "Epoch 113/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0816 - acc: 0.9028 - val_loss: 0.1137 - val_acc: 0.8832\n",
      "Epoch 114/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0811 - acc: 0.9042 - val_loss: 0.1133 - val_acc: 0.8846\n",
      "Epoch 115/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0806 - acc: 0.9054 - val_loss: 0.1130 - val_acc: 0.8849\n",
      "Epoch 116/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0800 - acc: 0.9067 - val_loss: 0.1127 - val_acc: 0.8853\n",
      "Epoch 117/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0794 - acc: 0.9084 - val_loss: 0.1122 - val_acc: 0.8870\n",
      "Epoch 118/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0788 - acc: 0.9103 - val_loss: 0.1119 - val_acc: 0.8889\n",
      "Epoch 119/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0781 - acc: 0.9125 - val_loss: 0.1115 - val_acc: 0.8899\n",
      "Epoch 120/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0775 - acc: 0.9140 - val_loss: 0.1111 - val_acc: 0.8912\n",
      "Epoch 121/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0768 - acc: 0.9148 - val_loss: 0.1107 - val_acc: 0.8917\n",
      "Epoch 122/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0761 - acc: 0.9162 - val_loss: 0.1103 - val_acc: 0.8926\n",
      "Epoch 123/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0755 - acc: 0.9175 - val_loss: 0.1099 - val_acc: 0.8934\n",
      "Epoch 124/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0748 - acc: 0.9186 - val_loss: 0.1095 - val_acc: 0.8946\n",
      "Epoch 125/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0741 - acc: 0.9200 - val_loss: 0.1092 - val_acc: 0.8950\n",
      "Epoch 126/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0734 - acc: 0.9214 - val_loss: 0.1088 - val_acc: 0.8958\n",
      "Epoch 127/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0727 - acc: 0.9224 - val_loss: 0.1085 - val_acc: 0.8958\n",
      "Epoch 128/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0720 - acc: 0.9233 - val_loss: 0.1081 - val_acc: 0.8963\n",
      "Epoch 129/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0713 - acc: 0.9245 - val_loss: 0.1078 - val_acc: 0.8966\n",
      "Epoch 130/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0707 - acc: 0.9258 - val_loss: 0.1075 - val_acc: 0.8974\n",
      "Epoch 131/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0700 - acc: 0.9268 - val_loss: 0.1072 - val_acc: 0.8978\n",
      "Epoch 132/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0694 - acc: 0.9276 - val_loss: 0.1069 - val_acc: 0.8983\n",
      "Epoch 133/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0688 - acc: 0.9285 - val_loss: 0.1067 - val_acc: 0.8991\n",
      "Epoch 134/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0681 - acc: 0.9294 - val_loss: 0.1064 - val_acc: 0.8992\n",
      "Epoch 135/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0675 - acc: 0.9300 - val_loss: 0.1062 - val_acc: 0.8997\n",
      "Epoch 136/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0669 - acc: 0.9306 - val_loss: 0.1059 - val_acc: 0.8997\n",
      "Epoch 137/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0664 - acc: 0.9310 - val_loss: 0.1057 - val_acc: 0.8999\n",
      "Epoch 138/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0658 - acc: 0.9313 - val_loss: 0.1055 - val_acc: 0.9000\n",
      "Epoch 139/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0652 - acc: 0.9318 - val_loss: 0.1052 - val_acc: 0.9007\n",
      "Epoch 140/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0647 - acc: 0.9323 - val_loss: 0.1050 - val_acc: 0.9005\n",
      "Epoch 141/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0641 - acc: 0.9327 - val_loss: 0.1048 - val_acc: 0.9010\n",
      "Epoch 142/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0636 - acc: 0.9330 - val_loss: 0.1046 - val_acc: 0.9011\n",
      "Epoch 143/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0631 - acc: 0.9332 - val_loss: 0.1045 - val_acc: 0.9015\n",
      "Epoch 144/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0626 - acc: 0.9337 - val_loss: 0.1042 - val_acc: 0.9015\n",
      "Epoch 145/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0620 - acc: 0.9338 - val_loss: 0.1039 - val_acc: 0.9019\n",
      "Epoch 146/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0615 - acc: 0.9340 - val_loss: 0.1038 - val_acc: 0.9019\n",
      "Epoch 147/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0610 - acc: 0.9343 - val_loss: 0.1035 - val_acc: 0.9015\n",
      "Epoch 148/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0605 - acc: 0.9346 - val_loss: 0.1033 - val_acc: 0.9018\n",
      "Epoch 149/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0600 - acc: 0.9350 - val_loss: 0.1031 - val_acc: 0.9010\n",
      "Epoch 150/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0595 - acc: 0.9354 - val_loss: 0.1028 - val_acc: 0.9018\n",
      "Epoch 151/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0590 - acc: 0.9357 - val_loss: 0.1025 - val_acc: 0.9021\n",
      "Epoch 152/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0585 - acc: 0.9360 - val_loss: 0.1024 - val_acc: 0.9019\n",
      "Epoch 153/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0580 - acc: 0.9363 - val_loss: 0.1021 - val_acc: 0.9023\n",
      "Epoch 154/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0574 - acc: 0.9367 - val_loss: 0.1019 - val_acc: 0.9021\n",
      "Epoch 155/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0569 - acc: 0.9370 - val_loss: 0.1017 - val_acc: 0.9018\n",
      "Epoch 156/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0564 - acc: 0.9372 - val_loss: 0.1014 - val_acc: 0.9023\n",
      "Epoch 157/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0559 - acc: 0.9376 - val_loss: 0.1012 - val_acc: 0.9024\n",
      "Epoch 158/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0553 - acc: 0.9379 - val_loss: 0.1009 - val_acc: 0.9023\n",
      "Epoch 159/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0548 - acc: 0.9382 - val_loss: 0.1007 - val_acc: 0.9023\n",
      "Epoch 160/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0543 - acc: 0.9385 - val_loss: 0.1004 - val_acc: 0.9023\n",
      "Epoch 161/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0538 - acc: 0.9387 - val_loss: 0.1002 - val_acc: 0.9024\n",
      "Epoch 162/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0533 - acc: 0.9388 - val_loss: 0.0999 - val_acc: 0.9024\n",
      "Epoch 163/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0528 - acc: 0.9390 - val_loss: 0.0998 - val_acc: 0.9027\n",
      "Epoch 164/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0523 - acc: 0.9392 - val_loss: 0.0994 - val_acc: 0.9024\n",
      "Epoch 165/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0518 - acc: 0.9394 - val_loss: 0.0993 - val_acc: 0.9023\n",
      "Epoch 166/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0513 - acc: 0.9395 - val_loss: 0.0990 - val_acc: 0.9024\n",
      "Epoch 167/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0508 - acc: 0.9396 - val_loss: 0.0988 - val_acc: 0.9019\n",
      "Epoch 168/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0503 - acc: 0.9398 - val_loss: 0.0985 - val_acc: 0.9023\n",
      "Epoch 169/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0498 - acc: 0.9401 - val_loss: 0.0983 - val_acc: 0.9018\n",
      "Epoch 170/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0493 - acc: 0.9403 - val_loss: 0.0982 - val_acc: 0.9013\n",
      "Epoch 171/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0488 - acc: 0.9408 - val_loss: 0.0978 - val_acc: 0.9018\n",
      "Epoch 172/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0483 - acc: 0.9410 - val_loss: 0.0976 - val_acc: 0.9019\n",
      "Epoch 173/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0479 - acc: 0.9413 - val_loss: 0.0974 - val_acc: 0.9018\n",
      "Epoch 174/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0474 - acc: 0.9414 - val_loss: 0.0972 - val_acc: 0.9021\n",
      "Epoch 175/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0470 - acc: 0.9415 - val_loss: 0.0969 - val_acc: 0.9016\n",
      "Epoch 176/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0465 - acc: 0.9417 - val_loss: 0.0969 - val_acc: 0.9021\n",
      "Epoch 177/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0461 - acc: 0.9419 - val_loss: 0.0966 - val_acc: 0.9019\n",
      "Epoch 178/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0457 - acc: 0.9420 - val_loss: 0.0965 - val_acc: 0.9023\n",
      "Epoch 179/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0453 - acc: 0.9422 - val_loss: 0.0962 - val_acc: 0.9021\n",
      "Epoch 180/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0449 - acc: 0.9425 - val_loss: 0.0960 - val_acc: 0.9023\n",
      "Epoch 181/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0444 - acc: 0.9427 - val_loss: 0.0957 - val_acc: 0.9026\n",
      "Epoch 182/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0440 - acc: 0.9428 - val_loss: 0.0955 - val_acc: 0.9031\n",
      "Epoch 183/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0436 - acc: 0.9437 - val_loss: 0.0953 - val_acc: 0.9037\n",
      "Epoch 184/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0432 - acc: 0.9448 - val_loss: 0.0951 - val_acc: 0.9050\n",
      "Epoch 185/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0429 - acc: 0.9456 - val_loss: 0.0949 - val_acc: 0.9060\n",
      "Epoch 186/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0425 - acc: 0.9467 - val_loss: 0.0946 - val_acc: 0.9071\n",
      "Epoch 187/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0421 - acc: 0.9481 - val_loss: 0.0942 - val_acc: 0.9069\n",
      "Epoch 188/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0417 - acc: 0.9493 - val_loss: 0.0941 - val_acc: 0.9084\n",
      "Epoch 189/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0413 - acc: 0.9507 - val_loss: 0.0938 - val_acc: 0.9088\n",
      "Epoch 190/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0410 - acc: 0.9518 - val_loss: 0.0935 - val_acc: 0.9092\n",
      "Epoch 191/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0406 - acc: 0.9527 - val_loss: 0.0932 - val_acc: 0.9095\n",
      "Epoch 192/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0403 - acc: 0.9533 - val_loss: 0.0930 - val_acc: 0.9103\n",
      "Epoch 193/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0399 - acc: 0.9539 - val_loss: 0.0928 - val_acc: 0.9103\n",
      "Epoch 194/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0396 - acc: 0.9545 - val_loss: 0.0926 - val_acc: 0.9111\n",
      "Epoch 195/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0392 - acc: 0.9549 - val_loss: 0.0923 - val_acc: 0.9119\n",
      "Epoch 196/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0389 - acc: 0.9554 - val_loss: 0.0921 - val_acc: 0.9119\n",
      "Epoch 197/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0385 - acc: 0.9556 - val_loss: 0.0919 - val_acc: 0.9124\n",
      "Epoch 198/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0382 - acc: 0.9557 - val_loss: 0.0916 - val_acc: 0.9133\n",
      "Epoch 199/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0378 - acc: 0.9560 - val_loss: 0.0913 - val_acc: 0.9132\n",
      "Epoch 200/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0375 - acc: 0.9563 - val_loss: 0.0910 - val_acc: 0.9133\n",
      "Epoch 201/250\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0371 - acc: 0.9564 - val_loss: 0.0907 - val_acc: 0.9137\n",
      "Epoch 202/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0368 - acc: 0.9567 - val_loss: 0.0905 - val_acc: 0.9138\n",
      "Epoch 203/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0364 - acc: 0.9568 - val_loss: 0.0903 - val_acc: 0.9137\n",
      "Epoch 204/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0361 - acc: 0.9569 - val_loss: 0.0902 - val_acc: 0.9140\n",
      "Epoch 205/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0358 - acc: 0.9571 - val_loss: 0.0899 - val_acc: 0.9141\n",
      "Epoch 206/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0354 - acc: 0.9572 - val_loss: 0.0898 - val_acc: 0.9141\n",
      "Epoch 207/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0351 - acc: 0.9574 - val_loss: 0.0896 - val_acc: 0.9143\n",
      "Epoch 208/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0348 - acc: 0.9575 - val_loss: 0.0895 - val_acc: 0.9148\n",
      "Epoch 209/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0344 - acc: 0.9574 - val_loss: 0.0893 - val_acc: 0.9151\n",
      "Epoch 210/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0341 - acc: 0.9576 - val_loss: 0.0892 - val_acc: 0.9156\n",
      "Epoch 211/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0338 - acc: 0.9580 - val_loss: 0.0891 - val_acc: 0.9145\n",
      "Epoch 212/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0335 - acc: 0.9585 - val_loss: 0.0891 - val_acc: 0.9148\n",
      "Epoch 213/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0332 - acc: 0.9594 - val_loss: 0.0891 - val_acc: 0.9153\n",
      "Epoch 214/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0328 - acc: 0.9605 - val_loss: 0.0890 - val_acc: 0.9149\n",
      "Epoch 215/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0325 - acc: 0.9612 - val_loss: 0.0889 - val_acc: 0.9159\n",
      "Epoch 216/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0322 - acc: 0.9620 - val_loss: 0.0889 - val_acc: 0.9164\n",
      "Epoch 217/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0318 - acc: 0.9633 - val_loss: 0.0889 - val_acc: 0.9180\n",
      "Epoch 218/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0315 - acc: 0.9644 - val_loss: 0.0889 - val_acc: 0.9180\n",
      "Epoch 219/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0312 - acc: 0.9660 - val_loss: 0.0887 - val_acc: 0.9183\n",
      "Epoch 220/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0309 - acc: 0.9668 - val_loss: 0.0887 - val_acc: 0.9190\n",
      "Epoch 221/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0305 - acc: 0.9671 - val_loss: 0.0887 - val_acc: 0.9186\n",
      "Epoch 222/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0302 - acc: 0.9673 - val_loss: 0.0887 - val_acc: 0.9190\n",
      "Epoch 223/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0299 - acc: 0.9675 - val_loss: 0.0887 - val_acc: 0.9186\n",
      "Epoch 224/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0296 - acc: 0.9676 - val_loss: 0.0887 - val_acc: 0.9185\n",
      "Epoch 225/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0293 - acc: 0.9679 - val_loss: 0.0887 - val_acc: 0.9183\n",
      "Epoch 226/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0289 - acc: 0.9679 - val_loss: 0.0887 - val_acc: 0.9178\n",
      "Epoch 227/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0286 - acc: 0.9681 - val_loss: 0.0888 - val_acc: 0.9170\n",
      "Epoch 228/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0283 - acc: 0.9682 - val_loss: 0.0888 - val_acc: 0.9173\n",
      "Epoch 229/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0280 - acc: 0.9683 - val_loss: 0.0889 - val_acc: 0.9161\n",
      "Epoch 230/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0277 - acc: 0.9684 - val_loss: 0.0889 - val_acc: 0.9165\n",
      "Epoch 231/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0274 - acc: 0.9686 - val_loss: 0.0889 - val_acc: 0.9169\n",
      "Epoch 232/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0271 - acc: 0.9687 - val_loss: 0.0890 - val_acc: 0.9167\n",
      "Epoch 233/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0268 - acc: 0.9689 - val_loss: 0.0892 - val_acc: 0.9165\n",
      "Epoch 234/250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0265 - acc: 0.9691 - val_loss: 0.0893 - val_acc: 0.9165\n",
      "Epoch 235/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0262 - acc: 0.9693 - val_loss: 0.0894 - val_acc: 0.9164\n",
      "Epoch 236/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0259 - acc: 0.9695 - val_loss: 0.0894 - val_acc: 0.9157\n",
      "Epoch 237/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0256 - acc: 0.9696 - val_loss: 0.0896 - val_acc: 0.9159\n",
      "Epoch 238/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0254 - acc: 0.9696 - val_loss: 0.0896 - val_acc: 0.9164\n",
      "Epoch 239/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0251 - acc: 0.9698 - val_loss: 0.0897 - val_acc: 0.9161\n",
      "Epoch 240/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0248 - acc: 0.9699 - val_loss: 0.0899 - val_acc: 0.9159\n",
      "Epoch 241/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0246 - acc: 0.9701 - val_loss: 0.0900 - val_acc: 0.9154\n",
      "Epoch 242/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0243 - acc: 0.9703 - val_loss: 0.0900 - val_acc: 0.9161\n",
      "Epoch 243/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0241 - acc: 0.9704 - val_loss: 0.0903 - val_acc: 0.9151\n",
      "Epoch 244/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0238 - acc: 0.9706 - val_loss: 0.0904 - val_acc: 0.9149\n",
      "Epoch 245/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0236 - acc: 0.9708 - val_loss: 0.0907 - val_acc: 0.9149\n",
      "Epoch 246/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0234 - acc: 0.9709 - val_loss: 0.0909 - val_acc: 0.9143\n",
      "Epoch 247/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0231 - acc: 0.9711 - val_loss: 0.0910 - val_acc: 0.9143\n",
      "Epoch 248/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0229 - acc: 0.9716 - val_loss: 0.0912 - val_acc: 0.9140\n",
      "Epoch 249/250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0227 - acc: 0.9715 - val_loss: 0.0913 - val_acc: 0.9141\n",
      "Epoch 250/250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0225 - acc: 0.9718 - val_loss: 0.0916 - val_acc: 0.9130\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_word_tr,y_tr,validation_data = (X_word_te,y_te),epochs = 250,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "Hw6rYenKunqp",
    "outputId": "ebbcea1f-e15f-4ae5-cce6-eaa2092b843f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5ycZX338c9vZ8/HJLub8zkkEBBIIJwEFUQE0RqtvjQUrVoq1Yqt0vZ5oPVRHmyr7atnS6moqegjRB+pNj6moi0nlVM2GggJBDYJSXYTkj1ks+fDzPyeP67Z7GRml8wmu9ndO9/36zWvmbkPs9fFhO/c85vrvi9zd0REJLryJroBIiIyvhT0IiIRp6AXEYk4Bb2ISMQp6EVEIi5/ohuQqaamxhcvXjzRzRARmVK2bNnS7O61w62bdEG/ePFi6urqJroZIiJTipntHWmdSjciIhGnoBcRiTgFvYhIxCnoRUQiTkEvIhJxCnoRkYhT0IuIRNykG0cvIhJ17k7PQIIDbT3sfK2TeDJJU0cfJYUxbr5s0Zj/PQW9iMhJcnc6++Icau+jvXeArr44XX0JuvvjdPXFaeseoKWrnyPd/bR29dPSOfS4L57Mer3VC6cp6EVExkM8kaSlq59D7b00d/bR3Z+gpz9BZ1+coz0Dx27tPXHa05639fTTO5Ad2OnKi/KZUVbIjLJCZlcVc+7cSqrLCpleVkhteRHnzKmgKD9GdVkh00oLxqV/CnoROaN09sX5wa8beeTFQxxq76Ops4+Wzj6SrzPZXkVRPpUlBVSWFFBVks+i6lKqSgqoKilgZmURMyuKmVZaQFlRPqWFMcoK8yktilFVUkBRfuz0dW4ECnoROSO4O5u2vcb//tF2Dnf0say2jMXVZVwwv4qZFUXMrCxmVmUxNeWFlBflU1wQo7won4rifPJjU3vcioJeRCJvf2s3/+s/XuCxnU2cO6eSf7n5Ii5eNB0zm+imnRYKehGJrOcb2njgmX38cGsjeWb8r3edy0euWDTlj9BHS0EvIpHS2Rdn49YDPPDsXl5obKekIMbaC+fxh29bztxpJRPdvAmhoBeRSc3d6R1I0t0fp6M3jIJp7w2jXjp648TM6I0neLW5m22NbWxrPErvQJJzZldw99rzeM/qeVQWj89olqlCQS8iE+pozwD1hzs50NZDZ1+cvS3d7G3poqWrn8Ptvexr7X7dETGDigvyeMPcKm66dCHvumAuFy2cdsbU4E8kp6A3sxuAfwRiwNfd/csZ6xcB64FaoBX4kLs3pNYlgG2pTfe5+7vHqO0iMsW4Oy8f6uTRnYf5xSvN7DzUQVNH33HbFMSMBdNLqa0o4ry5VbzzgjmUFxVQUpBHRXEY0liZGtpYUZxP0p3ighjTSwuJ5SnYh3PCoDezGHAPcB3QAGw2s43uviNts78BvuXu95vZW4EvAR9Oretx91Vj3G4RmUKaOvq474ld/Pj5gxw42gvAObMreMuKWs6aWc5ZteUsrC6lvCifWZXFCuwxlssR/aVAvbvvBjCzDcBaID3ozwVuTz1+FPjhWDZSRKamo90D3PfzXaz/xav0xRO89ZxZfPra5Vxz9kxmVxVPdPPOGLkE/Txgf9rzBuCyjG2eA36TUN55L1BhZtXu3gIUm1kdEAe+7O76EBCJuK6+ON988lW++vgu2nvjvOuCOXz2uhUsqy2f6Kadkcbqx9g/Bv7ZzD4KPAE0AonUukXu3mhmS4FHzGybu+9K39nMbgVuBVi4cOEYNUlEJsKT9c38yfefp7Gth7etnMnt153NuXMrJ7pZZ7Rcgr4RWJD2fH5q2THufoBwRI+ZlQPvc/e21LrG1P1uM3sMWA3sytj/PuA+gDVr1uTw+7qITCbJpPPozsN84xd7eHJXC0tqyvi/n7iCSxbPmOimCbkF/WZguZktIQT8OuC30jcwsxqg1d2TwJ2EETiY2XSg2937UttcCfz1GLZfRCZIfzxJS1cfP37+IN96ai/7WruZVVnE5965kpsvW0RJ4cRfzEuCEwa9u8fN7DbgYcLwyvXuvt3M7gbq3H0jcDXwJTNzQunmU6ndVwJfNbMkYTarL2eM1hGRSSKeSHKke4Aj3eG66a1d/bR29dHS1U9zZx/NHan7zj5aOvvp6Isf2/eSxdP5HzeczfXnzabgDLu8wFRg7pOrUrJmzRqvq6ub6GaIRMbg5BitXf1hEoy0+9bUbXdzF1v3t5EY4cykaaUF1JYXUVNeRE1FETXlhcwoLWRaWSEXLZzGeXOrTnOvJJOZbXH3NcOt05mxIlPc0e4BXm3p4tWWLva2dPNqSxeH2nuPzWZ0pGuA/sTwk2MU5udRXVbInKpifvdNS5g3rSRMklFayIzyMFnG9NJCHaVPcQp6kSmgdyDB3pZudjd1Un+4k11NnexJXSqgrXvguG3nVhUzZ1oJC2aUcuH8aSGwSwuPzXKUfistjOkyAWcABb3IJODutPfGOdTey8Gjvexv7R4K9OYuGtt6SK+yzptWwpKaMt55/hwWV5exqLqUxTVlLJxRSnGBfgSV4ynoRU4jd2d/aw/bDxxlx8F2Go70sL+1mxcPttPVnzhu29LCGMtqy7l40XTef/F8ltaWs7SmjKW1ZZQW6n9dyZ3+tYiME3en/nAnzzccZfuB9mPh3tEbRqvE8ow5VcXMqSrm/RfPZ/70UmZVFTO7sph500uYU1lMnq75ImNAQS8yhhJJ57Gdh/nRcwf4RX0LzZ3hyozFBXmsnFPJuy+cy3lzqzhvbiVnz65QmUVOCwW9yBho7uzje3X7eeCZfTQc6aG6rJCrltdw5bIaLlo0jSU15boio0wYBb3IKag/3MFXHqln07aDDCScy5fO4M53rOTt583SkESZNBT0Iieh4Ug3X318Nw8+u4+Sghg3X7aID12+kLNmVkx000SyKOhFRqH+cAf3Prab/9jaiBl84JIF/NF1K6guL5ropomMSEEvkoPu/jh//ZOd3P/UqxTl5/HbVyzm429ewpyqkolumsgJKehFXoe78/NXmvncD19gX2s3H758EZ9523IdwU9F/V3Q1wGdh2D/s/DaNiifBV2HIb8YKudCxRwoq4U5F0JpdC6xrKAXGcErhzq460fb+WV9C4uqS/nurZdz2dLqiW6WjFa8D7Z+B37ypxDvGVpePA1626BkBiTj0Nd+/H4L3whV86CoEi7/fehqgsPbIZmEooqhW3El1K6EgmIY6IGjDVA1Hwomz7c9Bb1IhqPdA9z7+C6+/vPdlBXl84XfOJebLl2oMe+TRbwPupqhuxk6m6DpRXjtBcgvgtUfho4DcGhHCNqDz8FLP4ZEHyy9Blb+BpRWw+zzoXoZJAYgVhBet7c9HO23N8K+Z2D7D0Jodx6Cum+8fpsKyqCsGtoPhA8NgMr54W90NYdvDRd8EKoWhHbVrID5ayAvH07DtYZ0mWKRlN6BBH/7051866m99MWTvP/i+dz5jnNUpjld2vbBS5tCYPd3hSDvaoKultTjZuhuyT7yhlBy6WlLO2I3wMPR+IXrYOnVsOIdkHcSQ15bd8PLD8OMpTDrPMgvCW3o6wi37mbY8/PwuGoeVJ8VPiBa6sOtoDQc+b/8E/CMq4haLBz9J/ph4RVwzZ9CzfLRtxFdpljkhFq7+rn568/w4sF23n/xfD525WJdY308uUNDHbzw/RDmbfug8Vfgadf7ySuAshoorQlHy9MWpT2vGXpcfRaU10LHIXj15+EounYlxHvDh8apllBmLIXLP3n8srKMEt65a0/8OgO94QNsoCv0vfmV8MHUth8sL3zzOLwDfv/pMT/KV9DLGe9Qey8f+7fN7G7q5N8+egnXnDNzopsUPZ1N0LwzhNlr20J5pHV3ODqunAvlM+FNt8Oqm0M4F5aFo/HRBF7FLDj//UPPC4rHvh+noqA41aZqmLYwe31nU/jvMg6lHAW9nNGe29/Grd+uo6M3zlc/fDFXn62QHzMvbQq17de2hTo3QKwQ5qwKR+FX3R6OhIsrJ7adk0V5bbiNAwW9nJESSeeBZ/byxR+/yMyKIh765BtZOUeBc0ri/fDcg/D0vWE0S8dBmL4Yll0Ls98ANWfDvIsiNWxxqlDQyxnn1/uOcNfG7TzXcJQ3La/hHz64Sj+4nopkEp7/Ljzy59DeEI7Yl14DM88JwxIHR7XIhMkp6M3sBuAfgRjwdXf/csb6RcB6oBZoBT7k7g2pdR8BPpfa9M/d/f4xarvIqPT0J/jCxhf4Xl0DMyuK+IcPrmLtqrmTZyq9RDz8GBkrzK7T9raHHxctLxwpl9aEunZ3S/hRr78z1LbzSwAPozgS/eHHv7Z9UFieGttdCsmB8GNlTyuUzTz+h8VEHPJiMNANyUQYLdLVDPmF4X6gJwR3+4Hwuvuegt2PhyGN8y6Gd/9jOIKfLP9NBcgh6M0sBtwDXAc0AJvNbKO770jb7G+Ab7n7/Wb2VuBLwIfNbAbwBWAN4MCW1L5HxrojIq+npz/BLfdv5qndLdz65qX8wbXLKS86zV9oOw6FenWsAA6/GH54624Ngdt+AA5tDyFcWh0CuL8TFl0J+5+GI69mv57Fjh+lcrJmLIOK2XDoBeg9Gj5oEv1hXcl06Hmd/11Lq2Hxm8L49PN+8+SGL8q4y+Vf+qVAvbvvBjCzDcBaID3ozwVuTz1+FPhh6vH1wM/cvTW178+AG4AHT73pIrnp7o9zyzfreGZPC3/3gQt57+r54/OHkknY+8sQ5m17w0k8/R1hWF3vUeh87fjtY0WhXl1aHYYKXv5JKK4Ko1F6jgAWRqksuAQu/mg4KccTYcx4d3P4cCiZHsZ2F1WGE4niPeGoP1YYbvnFMG1BOLJvPxDuAZpeCn+3vRH2bw4n9Lzh/eFbwkBP+AYAoR8zzw1/t2RGGA2TGIDKOVA5Lwx5VLhPerkE/Txgf9rzBuCyjG2eA36TUN55L1BhZtUj7Dsv8w+Y2a3ArQALFw4z7EjkJHX3x/mdb27m2T2t/N0HVvGe1Vn//E7eQC8c3Bqum9LwbDibsutwWFdQGs6+LJ8dhtQVVcKMJbDgsnDmZM2KENinq8RRMj2UbgYtu+b0/F2ZFMbqu+sfA/9sZh8FngAagZy/U7r7fcB9EM6MHaM2yRmupbOPT/yfLWzZe4S//+Aq1q46hZCP98OeJ6D+v0L9+tALcPD5UGqBMLpk6dWw4npY9tZwHRUd6cokkUvQNwIL0p7PTy07xt0PEI7oMbNy4H3u3mZmjcDVGfs+dgrtFcnJiwfb+d3762ju7OOfblrNuy6YO/oXcQ/h/vS9sPvR1JmWJaF8UXs2XPEpWHApzL8klDxEJqlcgn4zsNzMlhACfh3wW+kbmFkN0OruSeBOwggcgIeBvzSz6annb0+tFxk3P3ruAP/zoeepKM7ne793BRcumDa6F+g5Ajt/Ak/dA4e2hREuF38MlrwJznpbGN0iMoWcMOjdPW5mtxFCOwasd/ftZnY3UOfuGwlH7V8yMyeUbj6V2rfVzL5I+LAAuHvwh1mRsdYfT/KXm17km0++ysWLpnPvzRcxs3IUp8E318NP/yxcfAqg9hx491fg/A9MvtPpRUZBV6+USNjV1Mnt393Kcw1H+Z0rl3DnjefkPjl3dyv8+HbY/sMw2uSy3wt19kVv1HhwmTJ09UqJrP54ku88s5e/+slLFBfE+JebL+LG8+fk/gItu+CBD4STf676DFz2yXBxLJEIUdDLlLSvpZsHnt3H97fsp7mzn6vPruWv3ncBs3Ip1bTsCpfEbXkFnv1aWPbbG2HRFePbaJEJoqCXKSOeSPLfLx3mO8/s44mXm8gzuHblLG6+bCFvWVF74ksZdByCp++BJ7+SmgDCYO4qeN83wjXMRSJKQS+T3oG2HjZs3s93N+/jUHsfsyuL+czblvPBSxYwpyqHSSU6D8NjX4It94czPFd/OAyNnL5EP7LKGUFBL5PWC41HuefReh7e/hoOvGVFLX/+nkVcc3Yt+Sf6obWnDV78EbzwEOx5HDC45Ba45ONQu+J0NF9k0lDQy6SzZe8R/vmRV3h0ZxMVxfn83luW8VuXLmTBjNKRdzr8UhgWueeJcK2Z7uZQnpm+OExwceFNUHPWaeuDyGSioJdJ47Wjvdz9/7azadtrTC8t4E+uP5sPX7GIyuLXuZ55bzv89HPwq28BHsa+r7g+TE+34nqYe5GGSMoZT0EvE8rd2bL3CA/9qoGHfhWurHH7dSu45aollI10GWF32PtkOHp//rthaOQVn4I3fjpcbldEjqOgl9MumXR2HGznZzsO8YNfN7KvtZuSghjvu2gev3/1WcOXaLpbw/VmjuwN4d70EmAwcyV8bBMsvPy090NkqlDQy7hzd/a2dPPLXc08Wd/Ck7uaOdI9gBm8cVk1f3Dtcm54w+zsiUD6u6BpJ9Sth+c2DF0pct7FsPYeOO+94QJjIvK6FPRThXuYlah1d5iRqLsV+trDKfulM8KkEPnFYeKJWW+AGUsntDZ9uKOXp3a18Mv6Zn5Z30JjWw8AsyuLueacmVy5rIarlteEE5ySSWh7FZ7cAI1bwgv0d0FDXQj3WGGYeOPCm8I13TW5tMioRCfoB3rhxY2pJ6mASw+6Y49t5MfHtsvcfzT7cPx2lhcmocgvBjxc1zzRHwK5tx1KpoWZespqoaAkbDf4+u4h0Pc8Bv/9RTiy5/g+W17qxJ9hlNbAWdeGa6SXzAiPx2mSZndnX2s32xqPsmXvEX5Z38zLhzoBqCzO54pl1XziLUt541k1LK0pwxL90LoHdj0eRsrsejTMxISFyTpiBZCXD5d/IlwCeP6lYUYjETkp0Qn6/k74949PdCvGRn5JCP2BnvCBAOEo/d1fgdkXDB3BF5aFbQaP8ON9YWLng1vDbEc7/zPUswHKZ4VZjWYsDWE6Y0n4O7POCx82I+nrDN8iBtviSfo7W2g5sIeDzW38e+e57Dt0hD19ZXR6CfPz27l4XhW3XDWN1QuqWFbaTaz1V9BSDz+pD/dH9w99QFXMhfPfB3NXh7lHdYaqyJiLztUrE/Ewv+Wx/vjxjyH1fKTHo92H3PZJJkJADmTO5VkUppfrbYOjjWHc90DPUKAO9ISj+6r5YSz4WddBbJSfywO9YU7Qlnp47kFoPwjNO7Mney6qCtPbWV4Ylpjoh3gvnkxAdzM20reG0SisCCFefdbQbebK8EGj4Y8ip+zMuHplLP+MORpMJp2OvjidfXGSyfCBYgYFsTzKi/LpHUjQ3Z+gZyBBV98MevIupuu8VXT3xznS2QedBynrPkAs3sWM9pco6m2i3/OIDwxQ1nGYjniMo/EY/QmjiWm8mFxID0VMq6xg3oxyZtXOYvbCs1hZW8jCI0+HafPaG0JZqnJO+MAYVFoN1cvDDEwKdJEJEZ2gnwLcnYGE059I0jeQSN0n0+4T9A0k6Us9P9zRyyuHOnm1pYsj3f0c7RmgvSdOR+8AyVP+IlYKlFJcMIuSghilhfmUFcWoqSmipjzcqssLWTSthLfNKmdZbTnFBbHsl1m4+FQbIiLjLHJB/6+P7+IXrzQD4EP1FdIrVH6s+jLC+vQXPG65v+62iaTTlTrS7osnSSSdZNKJJ52EOwOJJKOtlFUU57O0poza8iLOqi2nqqSAypICqkoKqCjOJ8/sWBv640m6+uIUF8QoKYxRVphPaWEsdcunpDDG9NICyoryyc8zYnl24is+isiUF7mg/84ze+nqS7CkZmh8dXqU2bHBMekjco5/aGQMsmHoyXADeQbXm8GcqmLKi/IpKsgjZkYsL49YHuTlGUWxPArz8yjKj6XuR3oe7qvLiphVWaQwFpFTErmgTybhmrNn8rcfuHCimyIiMinkNKmmmd1gZjvNrN7M7hhm/UIze9TMfm1mz5vZjanli82sx8y2pm7/OtYdyOTu5OkAWETkmBMe0ZtZDLgHuA5oADab2UZ335G22eeA77n7vWZ2LrAJWJxat8vdV41ts0eWcCempBcROSaXI/pLgXp33+3u/cAGYG3GNg5Uph5XAQfGromjk3RU0xYRSZNL0M8D9qc9b0gtS3cX8CEzayAczX86bd2SVEnncTN703B/wMxuNbM6M6tramrKvfXDSCZVuhERSZdTjT4HNwHfdPf5wI3At80sDzgILHT31cDtwANmVpm5s7vf5+5r3H1NbW3tKTUkqdKNiMhxcgn6RmBB2vP5qWXpbgG+B+DuTwHFQI2797l7S2r5FmAXMK4TdiYd8lS6ERE5Jpeg3wwsN7MlZlYIrAM2ZmyzD7gWwMxWEoK+ycxqUz/mYmZLgeXA7rFq/HCSSdeZ9iIiaU446sbd42Z2G/AwEAPWu/t2M7sbqHP3jcAfAV8zs88Sfpj9qLu7mb0ZuNvMBoAk8Al3bx233pAq3SjpRUSOyemEKXffRPiRNX3Z59Me7wCuHGa/h4CHTrGNo5L0cBaqiIgEY/Vj7KSRcJVuRETSRS7oXaUbEZHjRC7oNepGROR4kQv6hE6YEhE5TqSCfnBaRP0YKyIyJFJBPzjrkko3IiJDIhX0iVTS64BeRGRIpII+qdKNiEiWSAW9q3QjIpIlUkGfcJVuREQyRSroj5VudEQvInJMpILek+FeQS8iMiRSQa/SjYhItkgF/WDpRjNMiYgMiWTQa3JwEZEh0Qp61ehFRLJEK+iPlW4muCEiIpNIpCJRpRsRkWzRCnqVbkREsuQU9GZ2g5ntNLN6M7tjmPULzexRM/u1mT1vZjemrbsztd9OM7t+LBufSaUbEZFsJ5wc3MxiwD3AdUADsNnMNqYmBB/0OeB77n6vmZ1LmEh8cerxOuA8YC7wX2a2wt0TY90R0JmxIiLDyeXY91Kg3t13u3s/sAFYm7GNA5Wpx1XAgdTjtcAGd+9z9z1Afer1xoVq9CIi2XIJ+nnA/rTnDall6e4CPmRmDYSj+U+PYl/M7FYzqzOzuqamphybnm1w4hFNDi4iMmSsqtk3Ad909/nAjcC3zSzn13b3+9x9jbuvqa2tPelGJHUJBBGRLCes0QONwIK05/NTy9LdAtwA4O5PmVkxUJPjvmPm2AxTSnoRkWNyOereDCw3syVmVkj4cXVjxjb7gGsBzGwlUAw0pbZbZ2ZFZrYEWA48O1aNz6SJR0REsp3wiN7d42Z2G/AwEAPWu/t2M7sbqHP3jcAfAV8zs88Sfpj9qLs7sN3MvgfsAOLAp8ZrxA2odCMiMpxcSje4+ybCj6zpyz6f9ngHcOUI+/4F8Ben0MacqXQjIpItUqcWJVW6ERHJEqmgd5VuRESyRCroB0s3GkcvIjIkUkE/WLrRmbEiIkMiFfQq3YiIZItU0Cc0Z6yISJZIBb1KNyIi2SIW9CrdiIhkilbQJ1W6ERHJFK2g1wlTIiJZIhb0gxOPTHBDREQmkWgFvUo3IiJZohX0Kt2IiGSJWNBr1I2ISKaIBr2SXkRkkIJeRCTiohX0yXCvoBcRGRKpoB+81k1epHolInJqIhWJrtKNiEiWnILezG4ws51mVm9mdwyz/u/NbGvq9rKZtaWtS6St2ziWjc+k4ZUiItlOODm4mcWAe4DrgAZgs5ltTE0IDoC7fzZt+08Dq9NeosfdV41dk0c2NDn46fhrIiJTQy6ReClQ7+673b0f2ACsfZ3tbwIeHIvGjZZKNyIi2XIJ+nnA/rTnDallWcxsEbAEeCRtcbGZ1ZnZ02b2npNuaQ6OHdEr6EVEjjlh6WaU1gHfd/dE2rJF7t5oZkuBR8xsm7vvSt/JzG4FbgVYuHDhSf/xwRq9JgcXERmSyxF9I7Ag7fn81LLhrCOjbOPujan73cBjHF+/H9zmPndf4+5ramtrc2jS8I5dvVI1ehGRY3KJxM3AcjNbYmaFhDDPGj1jZucA04Gn0pZNN7Oi1OMa4EpgR+a+Y0VnxoqIZDth6cbd42Z2G/AwEAPWu/t2M7sbqHP3wdBfB2zwwV9Eg5XAV80sSfhQ+XL6aJ2xptKNiEi2nGr07r4J2JSx7PMZz+8aZr8ngfNPoX2joolHRESyRaqandSoGxGRLNEK+sHSjS5ILyJyTMSCXhOPiIhkilbQJwdr9Ep6EZFB0Qp6V9lGRCRTxILeVbYREckQqaBPuKtsIyKSIVJB766TpUREMkUq6JNJlW5ERDJFKugT7jpZSkQkQ6SC3h3ydEgvInKcSAW9Rt2IiGSLVNAnkirdiIhkilTQJ1W6ERHJEqmgd5VuRESyRCroVboREckWqaBPuq5FLyKSKVJB7+7kRapHIiKnLlKxqBOmRESyRSrok7rWjYhIlpyC3sxuMLOdZlZvZncMs/7vzWxr6vaymbWlrfuImb2Sun1kLBufKemuicFFRDLkn2gDM4sB9wDXAQ3AZjPb6O47Brdx98+mbf9pYHXq8QzgC8AawIEtqX2PjGkvUpIadSMikiWXI/pLgXp33+3u/cAGYO3rbH8T8GDq8fXAz9y9NRXuPwNuOJUGv56ku2aYEhHJkEvQzwP2pz1vSC3LYmaLgCXAI6PZ18xuNbM6M6tramrKpd3DSrrmixURyTTWP8auA77v7onR7OTu97n7GndfU1tbe9J/XNejFxHJlkvQNwIL0p7PTy0bzjqGyjaj3feUqXQjIpItl6DfDCw3syVmVkgI842ZG5nZOcB04Km0xQ8Dbzez6WY2HXh7atm4UOlGRCTbCUfduHvczG4jBHQMWO/u283sbqDO3QdDfx2wwd09bd9WM/si4cMC4G53bx3bLgzR9ehFRLKdMOgB3H0TsClj2ecznt81wr7rgfUn2b5RSbrrhCkRkQzROjM2qYuaiYhkilTQJ3RmrIhIlkgFvWvUjYhIlkgFva5HLyKSLVJBn0iqdCMikilSQa/SjYhItkgFvUo3IiLZIhX0CV3rRkQkS6SCPqmpBEVEskQq6F2lGxGRLJEK+oQ7eZHqkYjIqYtULKp0IyKSLVJBr9KNiEi2SAW9Rt2IiGSLVNAn3clT0ouIHCdSQa/SjYhItkgFfSKpiUdERDJFKuiTGl4pIpIlUrGYdNfk4CIiGXIKejO7wcx2mlm9md0xwjYfMLMdZrbdzB5IW54ws62p28bh9h0rSUelGxGRDCecHNzMYsA9wHVAA7DZzP4z1ukAAAXFSURBVDa6+460bZYDdwJXuvsRM5uZ9hI97r5qjNs9rHDC1On4SyIiU0cuR/SXAvXuvtvd+4ENwNqMbT4O3OPuRwDc/fDYNjM3YeIRJb2ISLpcgn4esD/teUNqWboVwAoz+6WZPW1mN6StKzazutTy9wz3B8zs1tQ2dU1NTaPqQDp3NPGIiEiGE5ZuRvE6y4GrgfnAE2Z2vru3AYvcvdHMlgKPmNk2d9+VvrO73wfcB7BmzRo/2UaodCMiki2XI/pGYEHa8/mpZekagI3uPuDue4CXCcGPuzem7ncDjwGrT7HNIwqXQFDSi4ikyyXoNwPLzWyJmRUC64DM0TM/JBzNY2Y1hFLObjObbmZFacuvBHYwTtzRJRBERDKcsHTj7nEzuw14GIgB6919u5ndDdS5+8bUureb2Q4gAfyJu7eY2RuBr5pZkvCh8uX00TpjTaUbEZFsOdXo3X0TsClj2efTHjtwe+qWvs2TwPmn3szcJHQ9ehGRLJE5M9bddVEzEZFhRCjow72CXkTkeJEJ+kQq6VWjFxE5XmSCPjkY9Ep6EZHjRCboVboRERleZII+kVTpRkRkOJEJ+sHSja51IyJyvAgFfbjX1StFRI4XnaBX6UZEZFjRCXqVbkREhhWZoC/Iz+Od589hUXXZRDdFRGRSGavr0U+4yuIC7rn5ooluhojIpBOZI3oRERmegl5EJOIU9CIiEaegFxGJOAW9iEjEKehFRCJOQS8iEnEKehGRiDMfvJD7JGFmTcDeU3iJGqB5jJozVajPZwb1+cxwsn1e5O61w62YdEF/qsyszt3XTHQ7Tif1+cygPp8ZxqPPKt2IiEScgl5EJOKiGPT3TXQDJoD6fGZQn88MY97nyNXoRUTkeFE8ohcRkTQKehGRiItM0JvZDWa208zqzeyOiW7PeDGzV81sm5ltNbO61LIZZvYzM3sldT99ott5qsxsvZkdNrMX0pYN208L/in13j9vZlNyBpoR+nyXmTWm3u+tZnZj2ro7U33eaWbXT0yrT56ZLTCzR81sh5ltN7M/TC2P+vs8Ur/H77129yl/A2LALmApUAg8B5w70e0ap76+CtRkLPtr4I7U4zuAv5rodo5BP98MXAS8cKJ+AjcC/wkYcDnwzES3fwz7fBfwx8Nse27q33kRsCT17z820X0YZX/nABelHlcAL6f6FfX3eaR+j9t7HZUj+kuBenff7e79wAZg7QS36XRaC9yfenw/8J4JbMuYcPcngNaMxSP1cy3wLQ+eBqaZ2ZzT09KxM0KfR7IW2ODufe6+B6gn/H8wZbj7QXf/VepxB/AiMI/ov88j9Xskp/xeRyXo5wH705438Pr/4aYyB35qZlvM7NbUslnufjD1+DVg1sQ0bdyN1M+ov/+3pUoV69PKcpHqs5ktBlYDz3AGvc8Z/YZxeq+jEvRnkqvc/SLgHcCnzOzN6Ss9fNeL/JjZM6WfwL3AMmAVcBD424ltztgzs3LgIeAz7t6evi7K7/Mw/R639zoqQd8ILEh7Pj+1LHLcvTF1fxj4AeEr3KHBr7Cp+8MT18JxNVI/I/v+u/shd0+4exL4GkNf2SPRZzMrIITdd9z931OLI/8+D9fv8XyvoxL0m4HlZrbEzAqBdcDGCW7TmDOzMjOrGHwMvB14gdDXj6Q2+wjwHxPTwnE3Uj83Ar+dGpVxOXA07av/lJZRg34v4f2G0Od1ZlZkZkuA5cCzp7t9p8LMDPgG8KK7/13aqki/zyP1e1zf64n+BXoMf8m+kfDr9S7gzya6PePUx6WEX9+fA7YP9hOoBv4beAX4L2DGRLd1DPr6IOHr6wChJnnLSP0kjMK4J/XebwPWTHT7x7DP30716fnU//Bz0rb/s1SfdwLvmOj2n0R/ryKUZZ4HtqZuN54B7/NI/R6391qXQBARibiolG5ERGQECnoRkYhT0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMT9f49cWMoIOxKxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "415504tMunqs"
   },
   "outputs": [],
   "source": [
    "pred2 = model.predict(X_word_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIBxgP4uunqu"
   },
   "outputs": [],
   "source": [
    "pred_tags = get_tags(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6msyMqLtojV"
   },
   "outputs": [],
   "source": [
    "hits ,count_pad ,count_o = get_hits(y_te,pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "YAGfMYbKunq2",
    "outputId": "753ab8c8-a44f-41cb-974a-0f75dc8da87a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tags : 26175\n",
      "# of 'P' : 19946\n",
      "# of 'O' : 5403\n",
      "Total tags left without O,P : 826\n",
      "# of hits without 'PAD' and 'O' : 478\n",
      "# of predicted - 'O' : 5419\n",
      "# of predicted - 'PAD' : 0\n",
      "Accuracy rate :  0.5786924939467313\n"
     ]
    }
   ],
   "source": [
    "print_scores(hits,count_pad,count_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OP6g8A9unq9"
   },
   "source": [
    "## Model 3: Complex LSTM network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuH9VngGjs6T"
   },
   "source": [
    "In this model, i've joined the char vectors for each of the sentences, concatenating them to the sentece vector that is constructed with word vectors, making a one big vector for each sentence to feed the netword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yH1RlqzFofPE"
   },
   "source": [
    "###Layers Explanation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UlkKK9cUjs6T"
   },
   "source": [
    "#### TimeDistributed layer \n",
    "This wrapper allows us to apply a layer to every temporal slice of an input.\n",
    "use TimeDistributed to apply a type of a layer e.g. Conv2D layer to each of the 10 timesteps, independently.\n",
    "\n",
    "https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
    "\n",
    "https://keras.io/api/layers/recurrent_layers/time_distributed/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqM28sXwpSsU"
   },
   "source": [
    "#### Bidirectional LSTM \n",
    "which is a combination of two LSTMs — one runs forward from “right to left” and one runs backward from “left to right”.\n",
    "\n",
    "https://towardsdatascience.com/named-entity-recognition-ner-meeting-industrys-requirement-by-applying-state-of-the-art-deep-698d2b3b4ede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nh08yWacpKLI"
   },
   "source": [
    "#### SpatialDropout1D\n",
    " This version performs the same function as Dropout, however it drops entire 1D feature maps instead of individual elements\n",
    "\n",
    "https://www.rdocumentation.org/packages/keras/versions/2.0.6/topics/layer_spatial_dropout_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zdqwHsx_unq-",
    "outputId": "67ba16ec-b2e8-4a34-e913-9bdf20725bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "word_input = Input(shape = (X_word_tr.shape[1],))\n",
    "emb_word = Embedding(input_dim = n_words + 1,output_dim=16,mask_zero = True,input_length = max_len)(word_input)\n",
    "\n",
    "char_input = Input(shape = (X_char_tr.shape[1],X_char_tr.shape[2],))\n",
    "emb_char = Embedding(input_dim = n_chars + 1,output_dim = 16,mask_zero = True,input_length = (X_char_tr.shape[1],X_char_tr.shape[2],))(char_input)\n",
    "\n",
    "#flatten = Flatten(emb_word)\n",
    "\n",
    "lstm_word = LSTM(units=8, return_sequences=True,activation = 'tanh',recurrent_activation= 'sigmoid',\n",
    "                 recurrent_dropout= 0,unroll = False,use_bias = True)(emb_word)\n",
    "\n",
    "\n",
    "char_enc = TimeDistributed(LSTM(units=20, return_sequences=False,activation = 'tanh',recurrent_activation= 'sigmoid',\n",
    "                 recurrent_dropout= 0.5,unroll = False,use_bias = True))(emb_char)\n",
    "\n",
    "x = concatenate([lstm_word, char_enc])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "main_lstm = Bidirectional(LSTM(units=50, return_sequences=True,activation = 'tanh',recurrent_activation= 'sigmoid',\n",
    "                 recurrent_dropout= 0,unroll = False,use_bias = True))(x)\n",
    "\n",
    "out = Dense(n_tags,input_dim = (max_len,),activation = \"softmax\")(main_lstm)\n",
    "\n",
    "model = Model([word_input, char_input], out)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "c8NAQe-zunrB",
    "outputId": "0bcd6cd5-6d7e-4818-da40-df7b522f3954",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 75, 10)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 75, 16)       300048      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 75, 10, 16)   1632        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 75, 8)        800         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 75, 20)       2960        embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 75, 28)       0           lstm_2[0][0]                     \n",
      "                                                                 time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 75, 28)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 75, 100)      31600       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 75, 19)       1919        bidirectional[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 338,959\n",
      "Trainable params: 338,959\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E2tYCrakunrE",
    "outputId": "d04330ba-8c1c-4c0c-e31c-e2c602616008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "13/13 [==============================] - 5s 358ms/step - loss: 0.6484 - acc: 0.7916 - val_loss: 0.6096 - val_acc: 0.8671\n",
      "Epoch 2/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.4181 - acc: 0.8589 - val_loss: 0.2264 - val_acc: 0.8671\n",
      "Epoch 3/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.2280 - acc: 0.8589 - val_loss: 0.2102 - val_acc: 0.8671\n",
      "Epoch 4/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.1960 - acc: 0.8589 - val_loss: 0.1819 - val_acc: 0.8671\n",
      "Epoch 5/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.1802 - acc: 0.8589 - val_loss: 0.1752 - val_acc: 0.8671\n",
      "Epoch 6/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.1727 - acc: 0.8589 - val_loss: 0.1686 - val_acc: 0.8671\n",
      "Epoch 7/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.1678 - acc: 0.8589 - val_loss: 0.1651 - val_acc: 0.8671\n",
      "Epoch 8/250\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.1645 - acc: 0.8589 - val_loss: 0.1624 - val_acc: 0.8671\n",
      "Epoch 9/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.1619 - acc: 0.8589 - val_loss: 0.1593 - val_acc: 0.8671\n",
      "Epoch 10/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.1595 - acc: 0.8589 - val_loss: 0.1569 - val_acc: 0.8671\n",
      "Epoch 11/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.1573 - acc: 0.8589 - val_loss: 0.1548 - val_acc: 0.8671\n",
      "Epoch 12/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.1556 - acc: 0.8589 - val_loss: 0.1532 - val_acc: 0.8671\n",
      "Epoch 13/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.1539 - acc: 0.8589 - val_loss: 0.1518 - val_acc: 0.8671\n",
      "Epoch 14/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.1519 - acc: 0.8589 - val_loss: 0.1499 - val_acc: 0.8671\n",
      "Epoch 15/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.1494 - acc: 0.8589 - val_loss: 0.1476 - val_acc: 0.8671\n",
      "Epoch 16/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.1459 - acc: 0.8589 - val_loss: 0.1451 - val_acc: 0.8671\n",
      "Epoch 17/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.1416 - acc: 0.8589 - val_loss: 0.1419 - val_acc: 0.8671\n",
      "Epoch 18/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.1364 - acc: 0.8589 - val_loss: 0.1386 - val_acc: 0.8671\n",
      "Epoch 19/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.1310 - acc: 0.8589 - val_loss: 0.1353 - val_acc: 0.8671\n",
      "Epoch 20/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.1256 - acc: 0.8589 - val_loss: 0.1320 - val_acc: 0.8671\n",
      "Epoch 21/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.1202 - acc: 0.8589 - val_loss: 0.1288 - val_acc: 0.8670\n",
      "Epoch 22/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.1150 - acc: 0.8589 - val_loss: 0.1252 - val_acc: 0.8668\n",
      "Epoch 23/250\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.1096 - acc: 0.8591 - val_loss: 0.1219 - val_acc: 0.8666\n",
      "Epoch 24/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.1047 - acc: 0.8599 - val_loss: 0.1191 - val_acc: 0.8670\n",
      "Epoch 25/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0995 - acc: 0.8608 - val_loss: 0.1167 - val_acc: 0.8682\n",
      "Epoch 26/250\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 0.0944 - acc: 0.8625 - val_loss: 0.1144 - val_acc: 0.8697\n",
      "Epoch 27/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0895 - acc: 0.8659 - val_loss: 0.1117 - val_acc: 0.8732\n",
      "Epoch 28/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0855 - acc: 0.8694 - val_loss: 0.1101 - val_acc: 0.8751\n",
      "Epoch 29/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0813 - acc: 0.8750 - val_loss: 0.1104 - val_acc: 0.8777\n",
      "Epoch 30/250\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.0783 - acc: 0.8794 - val_loss: 0.1090 - val_acc: 0.8804\n",
      "Epoch 31/250\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.0756 - acc: 0.8845 - val_loss: 0.1096 - val_acc: 0.8814\n",
      "Epoch 32/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0734 - acc: 0.8877 - val_loss: 0.1094 - val_acc: 0.8819\n",
      "Epoch 33/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0712 - acc: 0.8913 - val_loss: 0.1091 - val_acc: 0.8822\n",
      "Epoch 34/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0691 - acc: 0.8953 - val_loss: 0.1090 - val_acc: 0.8825\n",
      "Epoch 35/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0678 - acc: 0.8978 - val_loss: 0.1101 - val_acc: 0.8841\n",
      "Epoch 36/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0664 - acc: 0.8999 - val_loss: 0.1099 - val_acc: 0.8833\n",
      "Epoch 37/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0653 - acc: 0.9025 - val_loss: 0.1104 - val_acc: 0.8857\n",
      "Epoch 38/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0641 - acc: 0.9043 - val_loss: 0.1099 - val_acc: 0.8844\n",
      "Epoch 39/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0632 - acc: 0.9062 - val_loss: 0.1120 - val_acc: 0.8835\n",
      "Epoch 40/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0622 - acc: 0.9085 - val_loss: 0.1110 - val_acc: 0.8844\n",
      "Epoch 41/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0615 - acc: 0.9096 - val_loss: 0.1108 - val_acc: 0.8840\n",
      "Epoch 42/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0603 - acc: 0.9125 - val_loss: 0.1116 - val_acc: 0.8848\n",
      "Epoch 43/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0591 - acc: 0.9145 - val_loss: 0.1123 - val_acc: 0.8844\n",
      "Epoch 44/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0585 - acc: 0.9162 - val_loss: 0.1135 - val_acc: 0.8867\n",
      "Epoch 45/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0577 - acc: 0.9175 - val_loss: 0.1140 - val_acc: 0.8856\n",
      "Epoch 46/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0567 - acc: 0.9190 - val_loss: 0.1134 - val_acc: 0.8835\n",
      "Epoch 47/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0563 - acc: 0.9205 - val_loss: 0.1136 - val_acc: 0.8830\n",
      "Epoch 48/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0553 - acc: 0.9219 - val_loss: 0.1145 - val_acc: 0.8819\n",
      "Epoch 49/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0543 - acc: 0.9232 - val_loss: 0.1157 - val_acc: 0.8816\n",
      "Epoch 50/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0534 - acc: 0.9251 - val_loss: 0.1170 - val_acc: 0.8825\n",
      "Epoch 51/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0526 - acc: 0.9267 - val_loss: 0.1182 - val_acc: 0.8835\n",
      "Epoch 52/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0519 - acc: 0.9279 - val_loss: 0.1176 - val_acc: 0.8832\n",
      "Epoch 53/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0512 - acc: 0.9291 - val_loss: 0.1180 - val_acc: 0.8832\n",
      "Epoch 54/250\n",
      "13/13 [==============================] - 1s 91ms/step - loss: 0.0505 - acc: 0.9299 - val_loss: 0.1192 - val_acc: 0.8830\n",
      "Epoch 55/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0501 - acc: 0.9309 - val_loss: 0.1196 - val_acc: 0.8806\n",
      "Epoch 56/250\n",
      "13/13 [==============================] - 1s 91ms/step - loss: 0.0491 - acc: 0.9328 - val_loss: 0.1210 - val_acc: 0.8822\n",
      "Epoch 57/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0485 - acc: 0.9340 - val_loss: 0.1223 - val_acc: 0.8828\n",
      "Epoch 58/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0478 - acc: 0.9354 - val_loss: 0.1225 - val_acc: 0.8811\n",
      "Epoch 59/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0469 - acc: 0.9365 - val_loss: 0.1239 - val_acc: 0.8801\n",
      "Epoch 60/250\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.0464 - acc: 0.9372 - val_loss: 0.1254 - val_acc: 0.8832\n",
      "Epoch 61/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0458 - acc: 0.9378 - val_loss: 0.1243 - val_acc: 0.8814\n",
      "Epoch 62/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0449 - acc: 0.9397 - val_loss: 0.1262 - val_acc: 0.8808\n",
      "Epoch 63/250\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.0447 - acc: 0.9403 - val_loss: 0.1264 - val_acc: 0.8832\n",
      "Epoch 64/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0441 - acc: 0.9406 - val_loss: 0.1282 - val_acc: 0.8827\n",
      "Epoch 65/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0433 - acc: 0.9426 - val_loss: 0.1280 - val_acc: 0.8814\n",
      "Epoch 66/250\n",
      "13/13 [==============================] - 1s 89ms/step - loss: 0.0425 - acc: 0.9432 - val_loss: 0.1283 - val_acc: 0.8806\n",
      "Epoch 67/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0422 - acc: 0.9434 - val_loss: 0.1304 - val_acc: 0.8838\n",
      "Epoch 68/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0415 - acc: 0.9442 - val_loss: 0.1301 - val_acc: 0.8809\n",
      "Epoch 69/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0410 - acc: 0.9461 - val_loss: 0.1307 - val_acc: 0.8828\n",
      "Epoch 70/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0403 - acc: 0.9469 - val_loss: 0.1323 - val_acc: 0.8849\n",
      "Epoch 71/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0395 - acc: 0.9468 - val_loss: 0.1334 - val_acc: 0.8843\n",
      "Epoch 72/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0390 - acc: 0.9476 - val_loss: 0.1332 - val_acc: 0.8841\n",
      "Epoch 73/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0387 - acc: 0.9487 - val_loss: 0.1346 - val_acc: 0.8838\n",
      "Epoch 74/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0380 - acc: 0.9496 - val_loss: 0.1356 - val_acc: 0.8835\n",
      "Epoch 75/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0372 - acc: 0.9505 - val_loss: 0.1363 - val_acc: 0.8848\n",
      "Epoch 76/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0370 - acc: 0.9509 - val_loss: 0.1366 - val_acc: 0.8849\n",
      "Epoch 77/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0363 - acc: 0.9521 - val_loss: 0.1380 - val_acc: 0.8859\n",
      "Epoch 78/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0362 - acc: 0.9516 - val_loss: 0.1377 - val_acc: 0.8830\n",
      "Epoch 79/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0355 - acc: 0.9531 - val_loss: 0.1392 - val_acc: 0.8830\n",
      "Epoch 80/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0349 - acc: 0.9532 - val_loss: 0.1399 - val_acc: 0.8856\n",
      "Epoch 81/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0345 - acc: 0.9546 - val_loss: 0.1407 - val_acc: 0.8835\n",
      "Epoch 82/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0336 - acc: 0.9552 - val_loss: 0.1415 - val_acc: 0.8833\n",
      "Epoch 83/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0335 - acc: 0.9565 - val_loss: 0.1430 - val_acc: 0.8838\n",
      "Epoch 84/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0327 - acc: 0.9570 - val_loss: 0.1431 - val_acc: 0.8824\n",
      "Epoch 85/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0324 - acc: 0.9577 - val_loss: 0.1445 - val_acc: 0.8840\n",
      "Epoch 86/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0316 - acc: 0.9589 - val_loss: 0.1441 - val_acc: 0.8856\n",
      "Epoch 87/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0310 - acc: 0.9590 - val_loss: 0.1445 - val_acc: 0.8846\n",
      "Epoch 88/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0307 - acc: 0.9603 - val_loss: 0.1459 - val_acc: 0.8825\n",
      "Epoch 89/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0305 - acc: 0.9605 - val_loss: 0.1467 - val_acc: 0.8832\n",
      "Epoch 90/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0303 - acc: 0.9597 - val_loss: 0.1463 - val_acc: 0.8849\n",
      "Epoch 91/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0294 - acc: 0.9616 - val_loss: 0.1472 - val_acc: 0.8841\n",
      "Epoch 92/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0291 - acc: 0.9621 - val_loss: 0.1485 - val_acc: 0.8844\n",
      "Epoch 93/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0290 - acc: 0.9623 - val_loss: 0.1479 - val_acc: 0.8859\n",
      "Epoch 94/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0280 - acc: 0.9625 - val_loss: 0.1487 - val_acc: 0.8840\n",
      "Epoch 95/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0275 - acc: 0.9648 - val_loss: 0.1505 - val_acc: 0.8817\n",
      "Epoch 96/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0272 - acc: 0.9649 - val_loss: 0.1504 - val_acc: 0.8853\n",
      "Epoch 97/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0266 - acc: 0.9665 - val_loss: 0.1504 - val_acc: 0.8843\n",
      "Epoch 98/250\n",
      "13/13 [==============================] - 1s 91ms/step - loss: 0.0265 - acc: 0.9661 - val_loss: 0.1502 - val_acc: 0.8848\n",
      "Epoch 99/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0258 - acc: 0.9675 - val_loss: 0.1524 - val_acc: 0.8853\n",
      "Epoch 100/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0256 - acc: 0.9673 - val_loss: 0.1510 - val_acc: 0.8857\n",
      "Epoch 101/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0248 - acc: 0.9687 - val_loss: 0.1521 - val_acc: 0.8856\n",
      "Epoch 102/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0247 - acc: 0.9694 - val_loss: 0.1522 - val_acc: 0.8867\n",
      "Epoch 103/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0237 - acc: 0.9711 - val_loss: 0.1526 - val_acc: 0.8870\n",
      "Epoch 104/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0232 - acc: 0.9718 - val_loss: 0.1529 - val_acc: 0.8891\n",
      "Epoch 105/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0231 - acc: 0.9715 - val_loss: 0.1538 - val_acc: 0.8889\n",
      "Epoch 106/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0229 - acc: 0.9723 - val_loss: 0.1542 - val_acc: 0.8877\n",
      "Epoch 107/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0221 - acc: 0.9736 - val_loss: 0.1547 - val_acc: 0.8881\n",
      "Epoch 108/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0218 - acc: 0.9737 - val_loss: 0.1543 - val_acc: 0.8893\n",
      "Epoch 109/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0214 - acc: 0.9737 - val_loss: 0.1564 - val_acc: 0.8873\n",
      "Epoch 110/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0212 - acc: 0.9740 - val_loss: 0.1555 - val_acc: 0.8912\n",
      "Epoch 111/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0206 - acc: 0.9754 - val_loss: 0.1567 - val_acc: 0.8910\n",
      "Epoch 112/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0202 - acc: 0.9755 - val_loss: 0.1559 - val_acc: 0.8910\n",
      "Epoch 113/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0193 - acc: 0.9773 - val_loss: 0.1544 - val_acc: 0.8931\n",
      "Epoch 114/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0191 - acc: 0.9776 - val_loss: 0.1556 - val_acc: 0.8909\n",
      "Epoch 115/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0188 - acc: 0.9780 - val_loss: 0.1572 - val_acc: 0.8901\n",
      "Epoch 116/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0186 - acc: 0.9786 - val_loss: 0.1590 - val_acc: 0.8883\n",
      "Epoch 117/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0179 - acc: 0.9788 - val_loss: 0.1595 - val_acc: 0.8889\n",
      "Epoch 118/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0178 - acc: 0.9787 - val_loss: 0.1599 - val_acc: 0.8902\n",
      "Epoch 119/250\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.0176 - acc: 0.9796 - val_loss: 0.1598 - val_acc: 0.8915\n",
      "Epoch 120/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0174 - acc: 0.9798 - val_loss: 0.1598 - val_acc: 0.8936\n",
      "Epoch 121/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0171 - acc: 0.9803 - val_loss: 0.1612 - val_acc: 0.8917\n",
      "Epoch 122/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0165 - acc: 0.9811 - val_loss: 0.1620 - val_acc: 0.8918\n",
      "Epoch 123/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0164 - acc: 0.9810 - val_loss: 0.1623 - val_acc: 0.8933\n",
      "Epoch 124/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0163 - acc: 0.9808 - val_loss: 0.1628 - val_acc: 0.8917\n",
      "Epoch 125/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0160 - acc: 0.9817 - val_loss: 0.1627 - val_acc: 0.8907\n",
      "Epoch 126/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0155 - acc: 0.9812 - val_loss: 0.1647 - val_acc: 0.8907\n",
      "Epoch 127/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0152 - acc: 0.9825 - val_loss: 0.1639 - val_acc: 0.8893\n",
      "Epoch 128/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0154 - acc: 0.9822 - val_loss: 0.1647 - val_acc: 0.8899\n",
      "Epoch 129/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0149 - acc: 0.9830 - val_loss: 0.1640 - val_acc: 0.8904\n",
      "Epoch 130/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0147 - acc: 0.9826 - val_loss: 0.1641 - val_acc: 0.8915\n",
      "Epoch 131/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0144 - acc: 0.9834 - val_loss: 0.1647 - val_acc: 0.8904\n",
      "Epoch 132/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0139 - acc: 0.9837 - val_loss: 0.1666 - val_acc: 0.8877\n",
      "Epoch 133/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0142 - acc: 0.9836 - val_loss: 0.1665 - val_acc: 0.8907\n",
      "Epoch 134/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0134 - acc: 0.9849 - val_loss: 0.1673 - val_acc: 0.8886\n",
      "Epoch 135/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0131 - acc: 0.9855 - val_loss: 0.1672 - val_acc: 0.8897\n",
      "Epoch 136/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0135 - acc: 0.9847 - val_loss: 0.1655 - val_acc: 0.8915\n",
      "Epoch 137/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0131 - acc: 0.9849 - val_loss: 0.1679 - val_acc: 0.8891\n",
      "Epoch 138/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0126 - acc: 0.9852 - val_loss: 0.1682 - val_acc: 0.8912\n",
      "Epoch 139/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0125 - acc: 0.9855 - val_loss: 0.1694 - val_acc: 0.8894\n",
      "Epoch 140/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0122 - acc: 0.9859 - val_loss: 0.1696 - val_acc: 0.8913\n",
      "Epoch 141/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0123 - acc: 0.9858 - val_loss: 0.1702 - val_acc: 0.8913\n",
      "Epoch 142/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0117 - acc: 0.9864 - val_loss: 0.1704 - val_acc: 0.8901\n",
      "Epoch 143/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0119 - acc: 0.9866 - val_loss: 0.1710 - val_acc: 0.8894\n",
      "Epoch 144/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0119 - acc: 0.9857 - val_loss: 0.1722 - val_acc: 0.8912\n",
      "Epoch 145/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0115 - acc: 0.9869 - val_loss: 0.1728 - val_acc: 0.8896\n",
      "Epoch 146/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0116 - acc: 0.9866 - val_loss: 0.1736 - val_acc: 0.8901\n",
      "Epoch 147/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0113 - acc: 0.9866 - val_loss: 0.1741 - val_acc: 0.8897\n",
      "Epoch 148/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0112 - acc: 0.9867 - val_loss: 0.1742 - val_acc: 0.8902\n",
      "Epoch 149/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0112 - acc: 0.9863 - val_loss: 0.1741 - val_acc: 0.8881\n",
      "Epoch 150/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0109 - acc: 0.9872 - val_loss: 0.1743 - val_acc: 0.8891\n",
      "Epoch 151/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0107 - acc: 0.9872 - val_loss: 0.1740 - val_acc: 0.8893\n",
      "Epoch 152/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0105 - acc: 0.9878 - val_loss: 0.1745 - val_acc: 0.8901\n",
      "Epoch 153/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0104 - acc: 0.9884 - val_loss: 0.1750 - val_acc: 0.8904\n",
      "Epoch 154/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0099 - acc: 0.9881 - val_loss: 0.1742 - val_acc: 0.8901\n",
      "Epoch 155/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0101 - acc: 0.9881 - val_loss: 0.1761 - val_acc: 0.8917\n",
      "Epoch 156/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0105 - acc: 0.9875 - val_loss: 0.1754 - val_acc: 0.8933\n",
      "Epoch 157/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0098 - acc: 0.9879 - val_loss: 0.1766 - val_acc: 0.8909\n",
      "Epoch 158/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0096 - acc: 0.9887 - val_loss: 0.1764 - val_acc: 0.8910\n",
      "Epoch 159/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0095 - acc: 0.9884 - val_loss: 0.1772 - val_acc: 0.8910\n",
      "Epoch 160/250\n",
      "13/13 [==============================] - 1s 89ms/step - loss: 0.0097 - acc: 0.9885 - val_loss: 0.1786 - val_acc: 0.8893\n",
      "Epoch 161/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0094 - acc: 0.9890 - val_loss: 0.1790 - val_acc: 0.8889\n",
      "Epoch 162/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0091 - acc: 0.9895 - val_loss: 0.1796 - val_acc: 0.8888\n",
      "Epoch 163/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0090 - acc: 0.9892 - val_loss: 0.1790 - val_acc: 0.8897\n",
      "Epoch 164/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0091 - acc: 0.9890 - val_loss: 0.1786 - val_acc: 0.8917\n",
      "Epoch 165/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0088 - acc: 0.9897 - val_loss: 0.1790 - val_acc: 0.8896\n",
      "Epoch 166/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0088 - acc: 0.9896 - val_loss: 0.1793 - val_acc: 0.8894\n",
      "Epoch 167/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0086 - acc: 0.9900 - val_loss: 0.1805 - val_acc: 0.8867\n",
      "Epoch 168/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0084 - acc: 0.9899 - val_loss: 0.1795 - val_acc: 0.8901\n",
      "Epoch 169/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0083 - acc: 0.9904 - val_loss: 0.1803 - val_acc: 0.8915\n",
      "Epoch 170/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0085 - acc: 0.9902 - val_loss: 0.1808 - val_acc: 0.8915\n",
      "Epoch 171/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0085 - acc: 0.9896 - val_loss: 0.1817 - val_acc: 0.8912\n",
      "Epoch 172/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0083 - acc: 0.9906 - val_loss: 0.1828 - val_acc: 0.8907\n",
      "Epoch 173/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0079 - acc: 0.9905 - val_loss: 0.1833 - val_acc: 0.8886\n",
      "Epoch 174/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0080 - acc: 0.9910 - val_loss: 0.1825 - val_acc: 0.8896\n",
      "Epoch 175/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0078 - acc: 0.9906 - val_loss: 0.1827 - val_acc: 0.8933\n",
      "Epoch 176/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0077 - acc: 0.9909 - val_loss: 0.1847 - val_acc: 0.8905\n",
      "Epoch 177/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0076 - acc: 0.9913 - val_loss: 0.1841 - val_acc: 0.8905\n",
      "Epoch 178/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0073 - acc: 0.9915 - val_loss: 0.1840 - val_acc: 0.8902\n",
      "Epoch 179/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0074 - acc: 0.9912 - val_loss: 0.1854 - val_acc: 0.8883\n",
      "Epoch 180/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0074 - acc: 0.9916 - val_loss: 0.1847 - val_acc: 0.8904\n",
      "Epoch 181/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0073 - acc: 0.9912 - val_loss: 0.1841 - val_acc: 0.8905\n",
      "Epoch 182/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0071 - acc: 0.9922 - val_loss: 0.1860 - val_acc: 0.8918\n",
      "Epoch 183/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0070 - acc: 0.9919 - val_loss: 0.1863 - val_acc: 0.8885\n",
      "Epoch 184/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0071 - acc: 0.9918 - val_loss: 0.1862 - val_acc: 0.8907\n",
      "Epoch 185/250\n",
      "13/13 [==============================] - 1s 89ms/step - loss: 0.0068 - acc: 0.9923 - val_loss: 0.1868 - val_acc: 0.8913\n",
      "Epoch 186/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0066 - acc: 0.9928 - val_loss: 0.1879 - val_acc: 0.8912\n",
      "Epoch 187/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0066 - acc: 0.9925 - val_loss: 0.1884 - val_acc: 0.8889\n",
      "Epoch 188/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0068 - acc: 0.9923 - val_loss: 0.1892 - val_acc: 0.8905\n",
      "Epoch 189/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0065 - acc: 0.9929 - val_loss: 0.1905 - val_acc: 0.8888\n",
      "Epoch 190/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0065 - acc: 0.9928 - val_loss: 0.1897 - val_acc: 0.8897\n",
      "Epoch 191/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0065 - acc: 0.9926 - val_loss: 0.1902 - val_acc: 0.8883\n",
      "Epoch 192/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0062 - acc: 0.9928 - val_loss: 0.1905 - val_acc: 0.8870\n",
      "Epoch 193/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0063 - acc: 0.9930 - val_loss: 0.1893 - val_acc: 0.8894\n",
      "Epoch 194/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0062 - acc: 0.9930 - val_loss: 0.1894 - val_acc: 0.8894\n",
      "Epoch 195/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0063 - acc: 0.9925 - val_loss: 0.1902 - val_acc: 0.8888\n",
      "Epoch 196/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0059 - acc: 0.9934 - val_loss: 0.1909 - val_acc: 0.8896\n",
      "Epoch 197/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0061 - acc: 0.9928 - val_loss: 0.1905 - val_acc: 0.8886\n",
      "Epoch 198/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0058 - acc: 0.9935 - val_loss: 0.1911 - val_acc: 0.8886\n",
      "Epoch 199/250\n",
      "13/13 [==============================] - 1s 89ms/step - loss: 0.0059 - acc: 0.9932 - val_loss: 0.1908 - val_acc: 0.8904\n",
      "Epoch 200/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0060 - acc: 0.9929 - val_loss: 0.1885 - val_acc: 0.8902\n",
      "Epoch 201/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0056 - acc: 0.9940 - val_loss: 0.1903 - val_acc: 0.8910\n",
      "Epoch 202/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0057 - acc: 0.9933 - val_loss: 0.1904 - val_acc: 0.8894\n",
      "Epoch 203/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0054 - acc: 0.9935 - val_loss: 0.1932 - val_acc: 0.8864\n",
      "Epoch 204/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0057 - acc: 0.9933 - val_loss: 0.1917 - val_acc: 0.8896\n",
      "Epoch 205/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0053 - acc: 0.9942 - val_loss: 0.1926 - val_acc: 0.8870\n",
      "Epoch 206/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0054 - acc: 0.9938 - val_loss: 0.1935 - val_acc: 0.8885\n",
      "Epoch 207/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0055 - acc: 0.9938 - val_loss: 0.1914 - val_acc: 0.8891\n",
      "Epoch 208/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0055 - acc: 0.9941 - val_loss: 0.1930 - val_acc: 0.8878\n",
      "Epoch 209/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0050 - acc: 0.9944 - val_loss: 0.1926 - val_acc: 0.8885\n",
      "Epoch 210/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0052 - acc: 0.9943 - val_loss: 0.1935 - val_acc: 0.8878\n",
      "Epoch 211/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0049 - acc: 0.9946 - val_loss: 0.1936 - val_acc: 0.8878\n",
      "Epoch 212/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0048 - acc: 0.9945 - val_loss: 0.1950 - val_acc: 0.8869\n",
      "Epoch 213/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0051 - acc: 0.9942 - val_loss: 0.1951 - val_acc: 0.8867\n",
      "Epoch 214/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0051 - acc: 0.9944 - val_loss: 0.1946 - val_acc: 0.8905\n",
      "Epoch 215/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0048 - acc: 0.9946 - val_loss: 0.1942 - val_acc: 0.8893\n",
      "Epoch 216/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0052 - acc: 0.9942 - val_loss: 0.1944 - val_acc: 0.8888\n",
      "Epoch 217/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0048 - acc: 0.9946 - val_loss: 0.1940 - val_acc: 0.8891\n",
      "Epoch 218/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0047 - acc: 0.9947 - val_loss: 0.1946 - val_acc: 0.8881\n",
      "Epoch 219/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0049 - acc: 0.9941 - val_loss: 0.1940 - val_acc: 0.8880\n",
      "Epoch 220/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0045 - acc: 0.9951 - val_loss: 0.1946 - val_acc: 0.8904\n",
      "Epoch 221/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0044 - acc: 0.9952 - val_loss: 0.1960 - val_acc: 0.8880\n",
      "Epoch 222/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0042 - acc: 0.9953 - val_loss: 0.1964 - val_acc: 0.8885\n",
      "Epoch 223/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0046 - acc: 0.9947 - val_loss: 0.1967 - val_acc: 0.8856\n",
      "Epoch 224/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0044 - acc: 0.9954 - val_loss: 0.1953 - val_acc: 0.8894\n",
      "Epoch 225/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0043 - acc: 0.9953 - val_loss: 0.1967 - val_acc: 0.8878\n",
      "Epoch 226/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0047 - acc: 0.9948 - val_loss: 0.1974 - val_acc: 0.8877\n",
      "Epoch 227/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0041 - acc: 0.9954 - val_loss: 0.1983 - val_acc: 0.8862\n",
      "Epoch 228/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0042 - acc: 0.9954 - val_loss: 0.1981 - val_acc: 0.8878\n",
      "Epoch 229/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0041 - acc: 0.9958 - val_loss: 0.1964 - val_acc: 0.8912\n",
      "Epoch 230/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0039 - acc: 0.9959 - val_loss: 0.1975 - val_acc: 0.8894\n",
      "Epoch 231/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0040 - acc: 0.9957 - val_loss: 0.1979 - val_acc: 0.8885\n",
      "Epoch 232/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0043 - acc: 0.9951 - val_loss: 0.1999 - val_acc: 0.8853\n",
      "Epoch 233/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0041 - acc: 0.9954 - val_loss: 0.1983 - val_acc: 0.8880\n",
      "Epoch 234/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0043 - acc: 0.9951 - val_loss: 0.1987 - val_acc: 0.8893\n",
      "Epoch 235/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0038 - acc: 0.9959 - val_loss: 0.1982 - val_acc: 0.8893\n",
      "Epoch 236/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0037 - acc: 0.9960 - val_loss: 0.1987 - val_acc: 0.8897\n",
      "Epoch 237/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0039 - acc: 0.9953 - val_loss: 0.2000 - val_acc: 0.8894\n",
      "Epoch 238/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0038 - acc: 0.9956 - val_loss: 0.2017 - val_acc: 0.8865\n",
      "Epoch 239/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0037 - acc: 0.9958 - val_loss: 0.2009 - val_acc: 0.8864\n",
      "Epoch 240/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0039 - acc: 0.9958 - val_loss: 0.2024 - val_acc: 0.8851\n",
      "Epoch 241/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0036 - acc: 0.9961 - val_loss: 0.2011 - val_acc: 0.8872\n",
      "Epoch 242/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0035 - acc: 0.9966 - val_loss: 0.2006 - val_acc: 0.8872\n",
      "Epoch 243/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0037 - acc: 0.9963 - val_loss: 0.2016 - val_acc: 0.8864\n",
      "Epoch 244/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0037 - acc: 0.9960 - val_loss: 0.1993 - val_acc: 0.8899\n",
      "Epoch 245/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0035 - acc: 0.9965 - val_loss: 0.2006 - val_acc: 0.8889\n",
      "Epoch 246/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0037 - acc: 0.9962 - val_loss: 0.2031 - val_acc: 0.8849\n",
      "Epoch 247/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0033 - acc: 0.9967 - val_loss: 0.2010 - val_acc: 0.8883\n",
      "Epoch 248/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0034 - acc: 0.9963 - val_loss: 0.2016 - val_acc: 0.8885\n",
      "Epoch 249/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0034 - acc: 0.9964 - val_loss: 0.2009 - val_acc: 0.8880\n",
      "Epoch 250/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0034 - acc: 0.9965 - val_loss: 0.2029 - val_acc: 0.8867\n"
     ]
    }
   ],
   "source": [
    "history3 = model.fit([X_word_tr,X_char_tr],y_tr,validation_data = ([X_word_te,X_char_te],y_te),batch_size=256, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "6RFg0_ywunrI",
    "outputId": "f68cffb3-c8fe-4943-e56d-93e518255350",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P4uT-gUeunrL"
   },
   "outputs": [],
   "source": [
    "pred3 = model.predict([X_word_te,X_char_te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-F2ZX7_tunrO"
   },
   "outputs": [],
   "source": [
    "pred_tags = get_tags(pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXlLTBSRunrQ"
   },
   "outputs": [],
   "source": [
    "hits ,count_pad ,count_o = get_hits(y_te,pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "w1WgduxdunrX",
    "outputId": "d9b427b5-209e-40be-97e5-bbc92def2940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tags : 26175\n",
      "# of 'P' : 19946\n",
      "# of 'O' : 5403\n",
      "Total tags left without O,P : 826\n",
      "# of hits without 'PAD' and 'O' : 397\n",
      "# of predicted - 'O' : 5366\n",
      "# of predicted - 'PAD' : 0\n",
      "Accuracy rate :  0.48062953995157387\n"
     ]
    }
   ],
   "source": [
    "print_scores(hits,count_pad,count_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEZh5eB1unrZ"
   },
   "source": [
    "## Model 4: GRU network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EU19qgeTLfQN"
   },
   "source": [
    "In this model, i've changed all the LSTM to GRU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgNfHj3-js69"
   },
   "source": [
    "### Layers Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wA1b7W1LH_A"
   },
   "source": [
    "#### Gated Recurrent Unit - GRU\n",
    "\n",
    "The GRU is the newer generation of Recurrent Neural networks and is pretty similar to an LSTM.<br> GRU’s got rid of the cell state and used the hidden state to transfer information. It also only has two gates, a reset gate and update gate.<br>\n",
    "The update gate acts similar to the forget and input gate of an LSTM.<br> It decides what information to throw away and what new information to add\n",
    "The reset gate is another gate is used to decide how much past information to forget.<br>\n",
    "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GCiAhdQSOjo3",
    "outputId": "2c26c677-010d-4a11-e4c5-b9c83a70c3d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "word_input = Input(shape = (X_word_tr.shape[1],))\n",
    "emb_word = Embedding(input_dim = n_words + 1,output_dim=16,mask_zero = True,input_length = max_len)(word_input)\n",
    "\n",
    "char_input = Input(shape = (X_char_tr.shape[1],X_char_tr.shape[2],))\n",
    "emb_char = Embedding(input_dim = n_chars + 1,output_dim = 16,mask_zero = True,input_length = (X_char_tr.shape[1],X_char_tr.shape[2],))(char_input)\n",
    "\n",
    "#flatten = Flatten(emb_word)\n",
    "\n",
    "lstm_word = GRU(units=8, return_sequences=True)(emb_word)\n",
    "\n",
    "char_enc = TimeDistributed(GRU(units=20, return_sequences=False,\n",
    "                                recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "\n",
    "lstm_char = GRU(units=8, return_sequences=True)(char_enc)\n",
    "\n",
    "lstm_word = SpatialDropout1D(0.3)(lstm_word)\n",
    "lstm_char = SpatialDropout1D(0.3)(lstm_char)\n",
    "\n",
    "x = concatenate([lstm_word, lstm_char])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "main_lstm = Bidirectional(GRU(units=50, return_sequences=True))(x)\n",
    "\n",
    "out = Dense(n_tags+1,input_dim = (max_len,),activation = \"softmax\")(main_lstm)\n",
    "\n",
    "model = Model([word_input, char_input], out)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "RygjGZMCRaw3",
    "outputId": "20b44347-d541-4649-b2e1-9df51290c411",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 75, 10)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 75, 10, 16)   1632        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 75, 16)       300048      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 75, 20)       2280        embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 75, 8)        624         embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 75, 8)        720         time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 75, 8)        0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 75, 8)        0           gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 75, 16)       0           spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 75, 16)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 75, 100)      20400       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 75, 20)       2020        bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 327,724\n",
      "Trainable params: 327,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tV73BVBqO69e",
    "outputId": "b0b78e98-018b-4c11-938b-fda635d9e45d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "13/13 [==============================] - 6s 446ms/step - loss: 0.6501 - acc: 0.7845 - val_loss: 0.6033 - val_acc: 0.8671\n",
      "Epoch 2/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.4480 - acc: 0.8589 - val_loss: 0.2166 - val_acc: 0.8671\n",
      "Epoch 3/250\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.2261 - acc: 0.8589 - val_loss: 0.2086 - val_acc: 0.8671\n",
      "Epoch 4/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.1952 - acc: 0.8589 - val_loss: 0.1780 - val_acc: 0.8671\n",
      "Epoch 5/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.1822 - acc: 0.8589 - val_loss: 0.1698 - val_acc: 0.8671\n",
      "Epoch 6/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.1737 - acc: 0.8589 - val_loss: 0.1659 - val_acc: 0.8671\n",
      "Epoch 7/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.1682 - acc: 0.8589 - val_loss: 0.1629 - val_acc: 0.8671\n",
      "Epoch 8/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.1642 - acc: 0.8589 - val_loss: 0.1602 - val_acc: 0.8671\n",
      "Epoch 9/250\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.1603 - acc: 0.8589 - val_loss: 0.1570 - val_acc: 0.8671\n",
      "Epoch 10/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.1550 - acc: 0.8589 - val_loss: 0.1530 - val_acc: 0.8671\n",
      "Epoch 11/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.1493 - acc: 0.8589 - val_loss: 0.1481 - val_acc: 0.8671\n",
      "Epoch 12/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.1422 - acc: 0.8588 - val_loss: 0.1422 - val_acc: 0.8671\n",
      "Epoch 13/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.1345 - acc: 0.8589 - val_loss: 0.1365 - val_acc: 0.8671\n",
      "Epoch 14/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.1270 - acc: 0.8588 - val_loss: 0.1312 - val_acc: 0.8671\n",
      "Epoch 15/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.1199 - acc: 0.8598 - val_loss: 0.1266 - val_acc: 0.8674\n",
      "Epoch 16/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.1127 - acc: 0.8612 - val_loss: 0.1220 - val_acc: 0.8679\n",
      "Epoch 17/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.1070 - acc: 0.8635 - val_loss: 0.1182 - val_acc: 0.8692\n",
      "Epoch 18/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.1003 - acc: 0.8665 - val_loss: 0.1150 - val_acc: 0.8723\n",
      "Epoch 19/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0954 - acc: 0.8700 - val_loss: 0.1120 - val_acc: 0.8767\n",
      "Epoch 20/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0904 - acc: 0.8736 - val_loss: 0.1106 - val_acc: 0.8779\n",
      "Epoch 21/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0868 - acc: 0.8769 - val_loss: 0.1095 - val_acc: 0.8792\n",
      "Epoch 22/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0827 - acc: 0.8814 - val_loss: 0.1084 - val_acc: 0.8811\n",
      "Epoch 23/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0807 - acc: 0.8830 - val_loss: 0.1085 - val_acc: 0.8822\n",
      "Epoch 24/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0775 - acc: 0.8869 - val_loss: 0.1082 - val_acc: 0.8833\n",
      "Epoch 25/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0758 - acc: 0.8890 - val_loss: 0.1087 - val_acc: 0.8846\n",
      "Epoch 26/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0737 - acc: 0.8918 - val_loss: 0.1090 - val_acc: 0.8854\n",
      "Epoch 27/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0719 - acc: 0.8946 - val_loss: 0.1097 - val_acc: 0.8869\n",
      "Epoch 28/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0705 - acc: 0.8964 - val_loss: 0.1097 - val_acc: 0.8872\n",
      "Epoch 29/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0688 - acc: 0.8990 - val_loss: 0.1104 - val_acc: 0.8910\n",
      "Epoch 30/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0662 - acc: 0.9029 - val_loss: 0.1100 - val_acc: 0.8923\n",
      "Epoch 31/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0650 - acc: 0.9056 - val_loss: 0.1104 - val_acc: 0.8941\n",
      "Epoch 32/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0631 - acc: 0.9090 - val_loss: 0.1098 - val_acc: 0.8942\n",
      "Epoch 33/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0613 - acc: 0.9111 - val_loss: 0.1107 - val_acc: 0.8962\n",
      "Epoch 34/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0604 - acc: 0.9138 - val_loss: 0.1113 - val_acc: 0.8971\n",
      "Epoch 35/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0592 - acc: 0.9154 - val_loss: 0.1117 - val_acc: 0.8974\n",
      "Epoch 36/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0569 - acc: 0.9205 - val_loss: 0.1117 - val_acc: 0.8983\n",
      "Epoch 37/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0563 - acc: 0.9213 - val_loss: 0.1131 - val_acc: 0.8991\n",
      "Epoch 38/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0545 - acc: 0.9245 - val_loss: 0.1132 - val_acc: 0.9005\n",
      "Epoch 39/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0535 - acc: 0.9269 - val_loss: 0.1140 - val_acc: 0.9010\n",
      "Epoch 40/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0520 - acc: 0.9296 - val_loss: 0.1144 - val_acc: 0.9008\n",
      "Epoch 41/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0513 - acc: 0.9310 - val_loss: 0.1157 - val_acc: 0.8997\n",
      "Epoch 42/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0499 - acc: 0.9344 - val_loss: 0.1167 - val_acc: 0.8994\n",
      "Epoch 43/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0495 - acc: 0.9354 - val_loss: 0.1182 - val_acc: 0.9015\n",
      "Epoch 44/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0477 - acc: 0.9370 - val_loss: 0.1180 - val_acc: 0.9011\n",
      "Epoch 45/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0473 - acc: 0.9369 - val_loss: 0.1184 - val_acc: 0.9015\n",
      "Epoch 46/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0467 - acc: 0.9396 - val_loss: 0.1199 - val_acc: 0.9023\n",
      "Epoch 47/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0460 - acc: 0.9416 - val_loss: 0.1216 - val_acc: 0.9026\n",
      "Epoch 48/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0462 - acc: 0.9402 - val_loss: 0.1212 - val_acc: 0.9035\n",
      "Epoch 49/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0446 - acc: 0.9441 - val_loss: 0.1213 - val_acc: 0.9034\n",
      "Epoch 50/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0437 - acc: 0.9436 - val_loss: 0.1224 - val_acc: 0.9047\n",
      "Epoch 51/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0430 - acc: 0.9463 - val_loss: 0.1236 - val_acc: 0.9043\n",
      "Epoch 52/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0420 - acc: 0.9467 - val_loss: 0.1236 - val_acc: 0.9048\n",
      "Epoch 53/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0415 - acc: 0.9478 - val_loss: 0.1239 - val_acc: 0.9069\n",
      "Epoch 54/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0406 - acc: 0.9492 - val_loss: 0.1243 - val_acc: 0.9063\n",
      "Epoch 55/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0401 - acc: 0.9495 - val_loss: 0.1254 - val_acc: 0.9063\n",
      "Epoch 56/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0389 - acc: 0.9511 - val_loss: 0.1261 - val_acc: 0.9069\n",
      "Epoch 57/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0384 - acc: 0.9519 - val_loss: 0.1271 - val_acc: 0.9074\n",
      "Epoch 58/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0378 - acc: 0.9526 - val_loss: 0.1271 - val_acc: 0.9087\n",
      "Epoch 59/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0366 - acc: 0.9540 - val_loss: 0.1274 - val_acc: 0.9088\n",
      "Epoch 60/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0368 - acc: 0.9543 - val_loss: 0.1286 - val_acc: 0.9088\n",
      "Epoch 61/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0355 - acc: 0.9559 - val_loss: 0.1285 - val_acc: 0.9084\n",
      "Epoch 62/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0347 - acc: 0.9576 - val_loss: 0.1301 - val_acc: 0.9092\n",
      "Epoch 63/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0344 - acc: 0.9574 - val_loss: 0.1315 - val_acc: 0.9093\n",
      "Epoch 64/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0337 - acc: 0.9595 - val_loss: 0.1319 - val_acc: 0.9085\n",
      "Epoch 65/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0326 - acc: 0.9614 - val_loss: 0.1329 - val_acc: 0.9103\n",
      "Epoch 66/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0325 - acc: 0.9597 - val_loss: 0.1342 - val_acc: 0.9092\n",
      "Epoch 67/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0309 - acc: 0.9624 - val_loss: 0.1342 - val_acc: 0.9079\n",
      "Epoch 68/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0297 - acc: 0.9640 - val_loss: 0.1358 - val_acc: 0.9096\n",
      "Epoch 69/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0302 - acc: 0.9630 - val_loss: 0.1367 - val_acc: 0.9093\n",
      "Epoch 70/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0296 - acc: 0.9642 - val_loss: 0.1379 - val_acc: 0.9090\n",
      "Epoch 71/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0287 - acc: 0.9662 - val_loss: 0.1394 - val_acc: 0.9092\n",
      "Epoch 72/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0284 - acc: 0.9665 - val_loss: 0.1394 - val_acc: 0.9092\n",
      "Epoch 73/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0270 - acc: 0.9673 - val_loss: 0.1413 - val_acc: 0.9082\n",
      "Epoch 74/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0268 - acc: 0.9671 - val_loss: 0.1415 - val_acc: 0.9087\n",
      "Epoch 75/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0266 - acc: 0.9679 - val_loss: 0.1432 - val_acc: 0.9082\n",
      "Epoch 76/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0252 - acc: 0.9700 - val_loss: 0.1439 - val_acc: 0.9080\n",
      "Epoch 77/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0243 - acc: 0.9705 - val_loss: 0.1452 - val_acc: 0.9082\n",
      "Epoch 78/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0248 - acc: 0.9699 - val_loss: 0.1448 - val_acc: 0.9069\n",
      "Epoch 79/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0238 - acc: 0.9719 - val_loss: 0.1471 - val_acc: 0.9066\n",
      "Epoch 80/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0231 - acc: 0.9723 - val_loss: 0.1476 - val_acc: 0.9048\n",
      "Epoch 81/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0226 - acc: 0.9729 - val_loss: 0.1476 - val_acc: 0.9074\n",
      "Epoch 82/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0219 - acc: 0.9737 - val_loss: 0.1485 - val_acc: 0.9061\n",
      "Epoch 83/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0219 - acc: 0.9728 - val_loss: 0.1502 - val_acc: 0.9060\n",
      "Epoch 84/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0205 - acc: 0.9757 - val_loss: 0.1519 - val_acc: 0.9045\n",
      "Epoch 85/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0207 - acc: 0.9746 - val_loss: 0.1514 - val_acc: 0.9058\n",
      "Epoch 86/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0204 - acc: 0.9754 - val_loss: 0.1515 - val_acc: 0.9040\n",
      "Epoch 87/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0198 - acc: 0.9762 - val_loss: 0.1548 - val_acc: 0.9053\n",
      "Epoch 88/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0197 - acc: 0.9768 - val_loss: 0.1550 - val_acc: 0.9042\n",
      "Epoch 89/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0187 - acc: 0.9775 - val_loss: 0.1552 - val_acc: 0.9045\n",
      "Epoch 90/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0188 - acc: 0.9775 - val_loss: 0.1558 - val_acc: 0.9042\n",
      "Epoch 91/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0181 - acc: 0.9780 - val_loss: 0.1562 - val_acc: 0.9039\n",
      "Epoch 92/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0178 - acc: 0.9786 - val_loss: 0.1565 - val_acc: 0.9037\n",
      "Epoch 93/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0172 - acc: 0.9797 - val_loss: 0.1576 - val_acc: 0.9023\n",
      "Epoch 94/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0170 - acc: 0.9788 - val_loss: 0.1593 - val_acc: 0.9013\n",
      "Epoch 95/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0175 - acc: 0.9787 - val_loss: 0.1610 - val_acc: 0.9023\n",
      "Epoch 96/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0168 - acc: 0.9792 - val_loss: 0.1630 - val_acc: 0.9016\n",
      "Epoch 97/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0165 - acc: 0.9803 - val_loss: 0.1621 - val_acc: 0.8983\n",
      "Epoch 98/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0159 - acc: 0.9802 - val_loss: 0.1636 - val_acc: 0.8971\n",
      "Epoch 99/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0160 - acc: 0.9811 - val_loss: 0.1657 - val_acc: 0.9002\n",
      "Epoch 100/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0158 - acc: 0.9807 - val_loss: 0.1676 - val_acc: 0.8978\n",
      "Epoch 101/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0150 - acc: 0.9822 - val_loss: 0.1679 - val_acc: 0.8983\n",
      "Epoch 102/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0144 - acc: 0.9825 - val_loss: 0.1685 - val_acc: 0.8971\n",
      "Epoch 103/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0149 - acc: 0.9822 - val_loss: 0.1682 - val_acc: 0.8974\n",
      "Epoch 104/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0153 - acc: 0.9816 - val_loss: 0.1688 - val_acc: 0.8981\n",
      "Epoch 105/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0140 - acc: 0.9828 - val_loss: 0.1701 - val_acc: 0.8955\n",
      "Epoch 106/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0137 - acc: 0.9836 - val_loss: 0.1706 - val_acc: 0.8981\n",
      "Epoch 107/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0138 - acc: 0.9839 - val_loss: 0.1710 - val_acc: 0.8973\n",
      "Epoch 108/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0138 - acc: 0.9838 - val_loss: 0.1716 - val_acc: 0.8976\n",
      "Epoch 109/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0138 - acc: 0.9834 - val_loss: 0.1735 - val_acc: 0.8981\n",
      "Epoch 110/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0134 - acc: 0.9839 - val_loss: 0.1733 - val_acc: 0.8966\n",
      "Epoch 111/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0131 - acc: 0.9839 - val_loss: 0.1753 - val_acc: 0.8952\n",
      "Epoch 112/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0130 - acc: 0.9846 - val_loss: 0.1755 - val_acc: 0.8970\n",
      "Epoch 113/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0126 - acc: 0.9850 - val_loss: 0.1764 - val_acc: 0.8966\n",
      "Epoch 114/250\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 0.0116 - acc: 0.9861 - val_loss: 0.1775 - val_acc: 0.8950\n",
      "Epoch 115/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0118 - acc: 0.9854 - val_loss: 0.1780 - val_acc: 0.8955\n",
      "Epoch 116/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0118 - acc: 0.9863 - val_loss: 0.1798 - val_acc: 0.8947\n",
      "Epoch 117/250\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 0.0118 - acc: 0.9850 - val_loss: 0.1798 - val_acc: 0.8949\n",
      "Epoch 118/250\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.0116 - acc: 0.9860 - val_loss: 0.1814 - val_acc: 0.8944\n",
      "Epoch 119/250\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 0.0113 - acc: 0.9862 - val_loss: 0.1824 - val_acc: 0.8942\n",
      "Epoch 120/250\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 0.0111 - acc: 0.9866 - val_loss: 0.1824 - val_acc: 0.8938\n",
      "Epoch 121/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0110 - acc: 0.9870 - val_loss: 0.1827 - val_acc: 0.8952\n",
      "Epoch 122/250\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 0.0107 - acc: 0.9873 - val_loss: 0.1848 - val_acc: 0.8946\n",
      "Epoch 123/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0103 - acc: 0.9876 - val_loss: 0.1846 - val_acc: 0.8957\n",
      "Epoch 124/250\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.0099 - acc: 0.9882 - val_loss: 0.1839 - val_acc: 0.8941\n",
      "Epoch 125/250\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.0100 - acc: 0.9877 - val_loss: 0.1858 - val_acc: 0.8923\n",
      "Epoch 126/250\n",
      "13/13 [==============================] - 1s 78ms/step - loss: 0.0105 - acc: 0.9878 - val_loss: 0.1852 - val_acc: 0.8920\n",
      "Epoch 127/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0101 - acc: 0.9880 - val_loss: 0.1870 - val_acc: 0.8933\n",
      "Epoch 128/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0102 - acc: 0.9875 - val_loss: 0.1882 - val_acc: 0.8931\n",
      "Epoch 129/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0097 - acc: 0.9884 - val_loss: 0.1891 - val_acc: 0.8928\n",
      "Epoch 130/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0093 - acc: 0.9887 - val_loss: 0.1901 - val_acc: 0.8893\n",
      "Epoch 131/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0096 - acc: 0.9884 - val_loss: 0.1887 - val_acc: 0.8915\n",
      "Epoch 132/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0099 - acc: 0.9886 - val_loss: 0.1901 - val_acc: 0.8909\n",
      "Epoch 133/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0096 - acc: 0.9881 - val_loss: 0.1910 - val_acc: 0.8913\n",
      "Epoch 134/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0087 - acc: 0.9897 - val_loss: 0.1921 - val_acc: 0.8909\n",
      "Epoch 135/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0092 - acc: 0.9893 - val_loss: 0.1929 - val_acc: 0.8905\n",
      "Epoch 136/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0085 - acc: 0.9897 - val_loss: 0.1927 - val_acc: 0.8934\n",
      "Epoch 137/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0088 - acc: 0.9893 - val_loss: 0.1945 - val_acc: 0.8896\n",
      "Epoch 138/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0090 - acc: 0.9891 - val_loss: 0.1936 - val_acc: 0.8913\n",
      "Epoch 139/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0088 - acc: 0.9893 - val_loss: 0.1936 - val_acc: 0.8939\n",
      "Epoch 140/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0082 - acc: 0.9904 - val_loss: 0.1938 - val_acc: 0.8926\n",
      "Epoch 141/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0085 - acc: 0.9903 - val_loss: 0.1946 - val_acc: 0.8918\n",
      "Epoch 142/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0085 - acc: 0.9893 - val_loss: 0.1932 - val_acc: 0.8938\n",
      "Epoch 143/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0084 - acc: 0.9900 - val_loss: 0.1946 - val_acc: 0.8896\n",
      "Epoch 144/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0080 - acc: 0.9904 - val_loss: 0.1960 - val_acc: 0.8918\n",
      "Epoch 145/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0080 - acc: 0.9903 - val_loss: 0.1977 - val_acc: 0.8899\n",
      "Epoch 146/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0080 - acc: 0.9901 - val_loss: 0.2002 - val_acc: 0.8875\n",
      "Epoch 147/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0081 - acc: 0.9903 - val_loss: 0.1972 - val_acc: 0.8899\n",
      "Epoch 148/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0080 - acc: 0.9903 - val_loss: 0.1961 - val_acc: 0.8917\n",
      "Epoch 149/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0075 - acc: 0.9911 - val_loss: 0.1958 - val_acc: 0.8883\n",
      "Epoch 150/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0078 - acc: 0.9905 - val_loss: 0.1983 - val_acc: 0.8867\n",
      "Epoch 151/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0077 - acc: 0.9911 - val_loss: 0.1992 - val_acc: 0.8870\n",
      "Epoch 152/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0080 - acc: 0.9903 - val_loss: 0.1997 - val_acc: 0.8886\n",
      "Epoch 153/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0072 - acc: 0.9914 - val_loss: 0.1993 - val_acc: 0.8888\n",
      "Epoch 154/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0071 - acc: 0.9912 - val_loss: 0.2017 - val_acc: 0.8854\n",
      "Epoch 155/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0068 - acc: 0.9919 - val_loss: 0.2022 - val_acc: 0.8859\n",
      "Epoch 156/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0075 - acc: 0.9907 - val_loss: 0.2001 - val_acc: 0.8913\n",
      "Epoch 157/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0066 - acc: 0.9920 - val_loss: 0.2010 - val_acc: 0.8904\n",
      "Epoch 158/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0070 - acc: 0.9917 - val_loss: 0.2008 - val_acc: 0.8905\n",
      "Epoch 159/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0068 - acc: 0.9925 - val_loss: 0.2018 - val_acc: 0.8893\n",
      "Epoch 160/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0066 - acc: 0.9921 - val_loss: 0.2007 - val_acc: 0.8891\n",
      "Epoch 161/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0064 - acc: 0.9926 - val_loss: 0.2024 - val_acc: 0.8883\n",
      "Epoch 162/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0065 - acc: 0.9923 - val_loss: 0.2037 - val_acc: 0.8864\n",
      "Epoch 163/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0064 - acc: 0.9928 - val_loss: 0.2054 - val_acc: 0.8861\n",
      "Epoch 164/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0059 - acc: 0.9932 - val_loss: 0.2069 - val_acc: 0.8875\n",
      "Epoch 165/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0067 - acc: 0.9921 - val_loss: 0.2075 - val_acc: 0.8857\n",
      "Epoch 166/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0065 - acc: 0.9924 - val_loss: 0.2070 - val_acc: 0.8865\n",
      "Epoch 167/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0061 - acc: 0.9935 - val_loss: 0.2063 - val_acc: 0.8872\n",
      "Epoch 168/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0055 - acc: 0.9937 - val_loss: 0.2078 - val_acc: 0.8870\n",
      "Epoch 169/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0057 - acc: 0.9933 - val_loss: 0.2082 - val_acc: 0.8861\n",
      "Epoch 170/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0068 - acc: 0.9923 - val_loss: 0.2106 - val_acc: 0.8844\n",
      "Epoch 171/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0060 - acc: 0.9929 - val_loss: 0.2068 - val_acc: 0.8873\n",
      "Epoch 172/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0064 - acc: 0.9927 - val_loss: 0.2085 - val_acc: 0.8846\n",
      "Epoch 173/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0054 - acc: 0.9942 - val_loss: 0.2091 - val_acc: 0.8859\n",
      "Epoch 174/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0054 - acc: 0.9939 - val_loss: 0.2092 - val_acc: 0.8864\n",
      "Epoch 175/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0061 - acc: 0.9931 - val_loss: 0.2119 - val_acc: 0.8832\n",
      "Epoch 176/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0059 - acc: 0.9935 - val_loss: 0.2112 - val_acc: 0.8854\n",
      "Epoch 177/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0057 - acc: 0.9937 - val_loss: 0.2114 - val_acc: 0.8856\n",
      "Epoch 178/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0050 - acc: 0.9941 - val_loss: 0.2108 - val_acc: 0.8885\n",
      "Epoch 179/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0053 - acc: 0.9941 - val_loss: 0.2112 - val_acc: 0.8862\n",
      "Epoch 180/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0052 - acc: 0.9942 - val_loss: 0.2130 - val_acc: 0.8836\n",
      "Epoch 181/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0055 - acc: 0.9937 - val_loss: 0.2136 - val_acc: 0.8844\n",
      "Epoch 182/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0051 - acc: 0.9941 - val_loss: 0.2150 - val_acc: 0.8846\n",
      "Epoch 183/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0055 - acc: 0.9936 - val_loss: 0.2114 - val_acc: 0.8867\n",
      "Epoch 184/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0054 - acc: 0.9940 - val_loss: 0.2134 - val_acc: 0.8854\n",
      "Epoch 185/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0051 - acc: 0.9939 - val_loss: 0.2113 - val_acc: 0.8867\n",
      "Epoch 186/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0052 - acc: 0.9942 - val_loss: 0.2126 - val_acc: 0.8853\n",
      "Epoch 187/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0052 - acc: 0.9942 - val_loss: 0.2144 - val_acc: 0.8853\n",
      "Epoch 188/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0046 - acc: 0.9953 - val_loss: 0.2146 - val_acc: 0.8856\n",
      "Epoch 189/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0049 - acc: 0.9944 - val_loss: 0.2159 - val_acc: 0.8862\n",
      "Epoch 190/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0046 - acc: 0.9951 - val_loss: 0.2185 - val_acc: 0.8819\n",
      "Epoch 191/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0049 - acc: 0.9949 - val_loss: 0.2175 - val_acc: 0.8846\n",
      "Epoch 192/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0051 - acc: 0.9944 - val_loss: 0.2182 - val_acc: 0.8846\n",
      "Epoch 193/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0045 - acc: 0.9951 - val_loss: 0.2155 - val_acc: 0.8865\n",
      "Epoch 194/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0044 - acc: 0.9951 - val_loss: 0.2170 - val_acc: 0.8867\n",
      "Epoch 195/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0044 - acc: 0.9952 - val_loss: 0.2180 - val_acc: 0.8851\n",
      "Epoch 196/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0047 - acc: 0.9950 - val_loss: 0.2202 - val_acc: 0.8835\n",
      "Epoch 197/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0048 - acc: 0.9946 - val_loss: 0.2228 - val_acc: 0.8819\n",
      "Epoch 198/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0048 - acc: 0.9947 - val_loss: 0.2186 - val_acc: 0.8861\n",
      "Epoch 199/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0047 - acc: 0.9949 - val_loss: 0.2179 - val_acc: 0.8861\n",
      "Epoch 200/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0042 - acc: 0.9954 - val_loss: 0.2189 - val_acc: 0.8851\n",
      "Epoch 201/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0043 - acc: 0.9952 - val_loss: 0.2189 - val_acc: 0.8857\n",
      "Epoch 202/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0045 - acc: 0.9949 - val_loss: 0.2197 - val_acc: 0.8846\n",
      "Epoch 203/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0047 - acc: 0.9948 - val_loss: 0.2189 - val_acc: 0.8869\n",
      "Epoch 204/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0042 - acc: 0.9955 - val_loss: 0.2228 - val_acc: 0.8816\n",
      "Epoch 205/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0041 - acc: 0.9957 - val_loss: 0.2211 - val_acc: 0.8836\n",
      "Epoch 206/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0047 - acc: 0.9949 - val_loss: 0.2209 - val_acc: 0.8841\n",
      "Epoch 207/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0047 - acc: 0.9946 - val_loss: 0.2200 - val_acc: 0.8864\n",
      "Epoch 208/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0044 - acc: 0.9950 - val_loss: 0.2211 - val_acc: 0.8853\n",
      "Epoch 209/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0039 - acc: 0.9958 - val_loss: 0.2191 - val_acc: 0.8875\n",
      "Epoch 210/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0042 - acc: 0.9951 - val_loss: 0.2206 - val_acc: 0.8848\n",
      "Epoch 211/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0040 - acc: 0.9954 - val_loss: 0.2223 - val_acc: 0.8838\n",
      "Epoch 212/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0044 - acc: 0.9953 - val_loss: 0.2219 - val_acc: 0.8853\n",
      "Epoch 213/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0041 - acc: 0.9954 - val_loss: 0.2202 - val_acc: 0.8853\n",
      "Epoch 214/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0034 - acc: 0.9965 - val_loss: 0.2202 - val_acc: 0.8872\n",
      "Epoch 215/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0037 - acc: 0.9960 - val_loss: 0.2213 - val_acc: 0.8851\n",
      "Epoch 216/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0038 - acc: 0.9957 - val_loss: 0.2248 - val_acc: 0.8835\n",
      "Epoch 217/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0038 - acc: 0.9957 - val_loss: 0.2259 - val_acc: 0.8849\n",
      "Epoch 218/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0036 - acc: 0.9957 - val_loss: 0.2286 - val_acc: 0.8816\n",
      "Epoch 219/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0037 - acc: 0.9954 - val_loss: 0.2254 - val_acc: 0.8832\n",
      "Epoch 220/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0039 - acc: 0.9958 - val_loss: 0.2240 - val_acc: 0.8843\n",
      "Epoch 221/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0039 - acc: 0.9960 - val_loss: 0.2251 - val_acc: 0.8825\n",
      "Epoch 222/250\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0041 - acc: 0.9955 - val_loss: 0.2255 - val_acc: 0.8827\n",
      "Epoch 223/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0036 - acc: 0.9962 - val_loss: 0.2246 - val_acc: 0.8856\n",
      "Epoch 224/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0035 - acc: 0.9961 - val_loss: 0.2272 - val_acc: 0.8827\n",
      "Epoch 225/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0036 - acc: 0.9963 - val_loss: 0.2291 - val_acc: 0.8812\n",
      "Epoch 226/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0035 - acc: 0.9963 - val_loss: 0.2249 - val_acc: 0.8862\n",
      "Epoch 227/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0040 - acc: 0.9956 - val_loss: 0.2275 - val_acc: 0.8838\n",
      "Epoch 228/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0036 - acc: 0.9960 - val_loss: 0.2276 - val_acc: 0.8849\n",
      "Epoch 229/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0035 - acc: 0.9962 - val_loss: 0.2262 - val_acc: 0.8844\n",
      "Epoch 230/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0040 - acc: 0.9958 - val_loss: 0.2340 - val_acc: 0.8798\n",
      "Epoch 231/250\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0035 - acc: 0.9963 - val_loss: 0.2285 - val_acc: 0.8830\n",
      "Epoch 232/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0035 - acc: 0.9965 - val_loss: 0.2281 - val_acc: 0.8844\n",
      "Epoch 233/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0029 - acc: 0.9968 - val_loss: 0.2273 - val_acc: 0.8849\n",
      "Epoch 234/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0037 - acc: 0.9958 - val_loss: 0.2313 - val_acc: 0.8819\n",
      "Epoch 235/250\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 0.0036 - acc: 0.9961 - val_loss: 0.2289 - val_acc: 0.8843\n",
      "Epoch 236/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0038 - acc: 0.9956 - val_loss: 0.2289 - val_acc: 0.8841\n",
      "Epoch 237/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0034 - acc: 0.9960 - val_loss: 0.2285 - val_acc: 0.8851\n",
      "Epoch 238/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0036 - acc: 0.9962 - val_loss: 0.2321 - val_acc: 0.8827\n",
      "Epoch 239/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0032 - acc: 0.9966 - val_loss: 0.2296 - val_acc: 0.8857\n",
      "Epoch 240/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0035 - acc: 0.9964 - val_loss: 0.2320 - val_acc: 0.8819\n",
      "Epoch 241/250\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.0035 - acc: 0.9958 - val_loss: 0.2328 - val_acc: 0.8816\n",
      "Epoch 242/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0036 - acc: 0.9965 - val_loss: 0.2328 - val_acc: 0.8835\n",
      "Epoch 243/250\n",
      "13/13 [==============================] - 1s 80ms/step - loss: 0.0037 - acc: 0.9958 - val_loss: 0.2316 - val_acc: 0.8832\n",
      "Epoch 244/250\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.0030 - acc: 0.9966 - val_loss: 0.2302 - val_acc: 0.8833\n",
      "Epoch 245/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0034 - acc: 0.9963 - val_loss: 0.2366 - val_acc: 0.8792\n",
      "Epoch 246/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0034 - acc: 0.9963 - val_loss: 0.2340 - val_acc: 0.8822\n",
      "Epoch 247/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0033 - acc: 0.9963 - val_loss: 0.2309 - val_acc: 0.8836\n",
      "Epoch 248/250\n",
      "13/13 [==============================] - 1s 82ms/step - loss: 0.0039 - acc: 0.9959 - val_loss: 0.2330 - val_acc: 0.8812\n",
      "Epoch 249/250\n",
      "13/13 [==============================] - 1s 81ms/step - loss: 0.0037 - acc: 0.9960 - val_loss: 0.2332 - val_acc: 0.8825\n",
      "Epoch 250/250\n",
      "13/13 [==============================] - 1s 84ms/step - loss: 0.0035 - acc: 0.9958 - val_loss: 0.2287 - val_acc: 0.8875\n"
     ]
    }
   ],
   "source": [
    "history4 = model.fit([X_word_tr,X_char_tr],y_tr,validation_data = ([X_word_te,X_char_te],y_te),batch_size=256, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "hRQQDfYerBpI",
    "outputId": "2e7028c0-775a-4934-dbb1-ad7f9725f1f9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9rNTj8xPij9"
   },
   "outputs": [],
   "source": [
    "pred4 = model.predict([X_word_te,np.array(X_char_te).reshape((len(X_char_te), max_len, max_len_char))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIF7mtitPcPu"
   },
   "outputs": [],
   "source": [
    "pred_tags = get_tags(pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "koG4VJ0EPgAM"
   },
   "outputs": [],
   "source": [
    "hits , count_pad , count_o = get_hits(y_te,pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "s2wQQ-t7Podb",
    "outputId": "79ae78df-255e-4dfa-c248-e938a0f6a952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tags : 26175\n",
      "# of 'P' : 19946\n",
      "# of 'O' : 5403\n",
      "Total tags left without O,P : 826\n",
      "# of hits without 'PAD' and 'O' : 343\n",
      "# of predicted - 'O' : 5467\n",
      "# of predicted - 'PAD' : 0\n",
      "Accuracy rate :  0.4152542372881356\n"
     ]
    }
   ],
   "source": [
    "print_scores(hits , count_pad , count_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUNVAYGVjs7T"
   },
   "source": [
    "## Model 5: LSTM - CRF word based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NEL4UuNjs7T"
   },
   "source": [
    "#### CRF - Condinital Random Field\n",
    "Conditional random fields (CRFs) are a class of statistical modeling method often applied in pattern recognition and machine learning and used for structured prediction.<br>\n",
    " Whereas a classifier predicts a label for a single sample without considering \"neighboring\" samples, a CRF can take context into account.<br> To do so, the prediction is modeled as a graphical model, which implements dependencies between the predictions.<br>\n",
    "https://en.wikipedia.org/wiki/Conditional_random_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMgCdQK03rlm"
   },
   "outputs": [],
   "source": [
    "#!pip install keras --upgrade\n",
    "import tensorflow.keras.backend as K\n",
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVoaMEevjs7V"
   },
   "outputs": [],
   "source": [
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWSdNUxLjs7a"
   },
   "outputs": [],
   "source": [
    "X_word_tr, X_word_te, y_tr, y_te = train_test_split(X_word_padded, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QG55Q7QNnvRN",
    "outputId": "aa2b6b63-9cd7-4cd1-eed0-10f51b729086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras_contrib-2.0.8-py3.7.egg\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "C:\\Anaconda\\lib\\site-packages\\keras_contrib-2.0.8-py3.7.egg\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n"
     ]
    }
   ],
   "source": [
    "word_input = Input(shape = (X_word_tr.shape[1],))\n",
    "emb_word = Embedding(input_dim = n_words + 1,output_dim=16,mask_zero = True,input_length = max_len)(word_input)\n",
    "\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(emb_word)  # variational biLSTM\n",
    "\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model(word_input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTLbKALmjs7f",
    "outputId": "84dd2848-a79e-454d-d41a-dbb5f09240fd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 75, 16)            300048    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 75, 100)           26800     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 75, 19)            1368      \n",
      "=================================================================\n",
      "Total params: 333,266\n",
      "Trainable params: 333,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oeyIQBz2hAv",
    "outputId": "334801b7-82b3-40ef-8212-02bf43f625c6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 3133 samples, validate on 349 samples\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 28.0295 - crf_viterbi_accuracy: 0.6948 - val_loss: 26.1638 - val_crf_viterbi_accuracy: 0.8628\n",
      "Epoch 2/150\n",
      "3133/3133 [==============================] - 5s 2ms/step - loss: 27.1819 - crf_viterbi_accuracy: 0.8582 - val_loss: 25.8954 - val_crf_viterbi_accuracy: 0.8662\n",
      "Epoch 3/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.9731 - crf_viterbi_accuracy: 0.8593 - val_loss: 25.7632 - val_crf_viterbi_accuracy: 0.8662\n",
      "Epoch 4/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.8564 - crf_viterbi_accuracy: 0.8590 - val_loss: 25.6800 - val_crf_viterbi_accuracy: 0.8664\n",
      "Epoch 5/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.7627 - crf_viterbi_accuracy: 0.8644 - val_loss: 25.6291 - val_crf_viterbi_accuracy: 0.8759\n",
      "Epoch 6/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.6952 - crf_viterbi_accuracy: 0.8755 - val_loss: 25.6044 - val_crf_viterbi_accuracy: 0.8831\n",
      "Epoch 7/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.6534 - crf_viterbi_accuracy: 0.8847 - val_loss: 25.5961 - val_crf_viterbi_accuracy: 0.8885\n",
      "Epoch 8/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.6234 - crf_viterbi_accuracy: 0.8958 - val_loss: 25.6019 - val_crf_viterbi_accuracy: 0.8867\n",
      "Epoch 9/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.5987 - crf_viterbi_accuracy: 0.9047 - val_loss: 25.5994 - val_crf_viterbi_accuracy: 0.8859\n",
      "Epoch 10/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.5775 - crf_viterbi_accuracy: 0.9140 - val_loss: 25.5858 - val_crf_viterbi_accuracy: 0.8906\n",
      "Epoch 11/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.5585 - crf_viterbi_accuracy: 0.9208 - val_loss: 25.5951 - val_crf_viterbi_accuracy: 0.8800\n",
      "Epoch 12/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.5407 - crf_viterbi_accuracy: 0.9265 - val_loss: 25.5994 - val_crf_viterbi_accuracy: 0.8809\n",
      "Epoch 13/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.5256 - crf_viterbi_accuracy: 0.9314 - val_loss: 25.6482 - val_crf_viterbi_accuracy: 0.8381\n",
      "Epoch 14/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.5121 - crf_viterbi_accuracy: 0.9367 - val_loss: 25.6133 - val_crf_viterbi_accuracy: 0.8758\n",
      "Epoch 15/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.4998 - crf_viterbi_accuracy: 0.9403 - val_loss: 25.6472 - val_crf_viterbi_accuracy: 0.8504\n",
      "Epoch 16/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.4891 - crf_viterbi_accuracy: 0.9443 - val_loss: 25.7070 - val_crf_viterbi_accuracy: 0.8198\n",
      "Epoch 17/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.4790 - crf_viterbi_accuracy: 0.9472 - val_loss: 25.6865 - val_crf_viterbi_accuracy: 0.8379\n",
      "Epoch 18/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.4707 - crf_viterbi_accuracy: 0.9499 - val_loss: 25.7314 - val_crf_viterbi_accuracy: 0.8218\n",
      "Epoch 19/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.4622 - crf_viterbi_accuracy: 0.9524 - val_loss: 25.7221 - val_crf_viterbi_accuracy: 0.8283\n",
      "Epoch 20/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.4550 - crf_viterbi_accuracy: 0.9534 - val_loss: 25.7006 - val_crf_viterbi_accuracy: 0.8496\n",
      "Epoch 21/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.4475 - crf_viterbi_accuracy: 0.9567 - val_loss: 25.7311 - val_crf_viterbi_accuracy: 0.8293\n",
      "Epoch 22/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.4394 - crf_viterbi_accuracy: 0.9601 - val_loss: 25.7152 - val_crf_viterbi_accuracy: 0.8661\n",
      "Epoch 23/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.4319 - crf_viterbi_accuracy: 0.9625 - val_loss: 25.7628 - val_crf_viterbi_accuracy: 0.8312\n",
      "Epoch 24/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.4243 - crf_viterbi_accuracy: 0.9667 - val_loss: 25.7519 - val_crf_viterbi_accuracy: 0.8402\n",
      "Epoch 25/150\n",
      "3133/3133 [==============================] - 8s 2ms/step - loss: 26.4171 - crf_viterbi_accuracy: 0.9690 - val_loss: 25.7899 - val_crf_viterbi_accuracy: 0.8261\n",
      "Epoch 26/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.4098 - crf_viterbi_accuracy: 0.9721 - val_loss: 25.7442 - val_crf_viterbi_accuracy: 0.8598\n",
      "Epoch 27/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.4026 - crf_viterbi_accuracy: 0.9738 - val_loss: 25.7701 - val_crf_viterbi_accuracy: 0.8520\n",
      "Epoch 28/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3969 - crf_viterbi_accuracy: 0.9765 - val_loss: 25.7796 - val_crf_viterbi_accuracy: 0.8411\n",
      "Epoch 29/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3896 - crf_viterbi_accuracy: 0.9792 - val_loss: 25.8363 - val_crf_viterbi_accuracy: 0.8209\n",
      "Epoch 30/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3835 - crf_viterbi_accuracy: 0.9814 - val_loss: 25.8626 - val_crf_viterbi_accuracy: 0.8195\n",
      "Epoch 31/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3777 - crf_viterbi_accuracy: 0.9823 - val_loss: 25.8118 - val_crf_viterbi_accuracy: 0.8528\n",
      "Epoch 32/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3731 - crf_viterbi_accuracy: 0.9844 - val_loss: 25.8498 - val_crf_viterbi_accuracy: 0.8388\n",
      "Epoch 33/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3682 - crf_viterbi_accuracy: 0.9858 - val_loss: 25.8768 - val_crf_viterbi_accuracy: 0.8350\n",
      "Epoch 34/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3639 - crf_viterbi_accuracy: 0.9876 - val_loss: 25.8882 - val_crf_viterbi_accuracy: 0.8363\n",
      "Epoch 35/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3602 - crf_viterbi_accuracy: 0.9884 - val_loss: 25.9103 - val_crf_viterbi_accuracy: 0.8308\n",
      "Epoch 36/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3561 - crf_viterbi_accuracy: 0.9899 - val_loss: 25.9229 - val_crf_viterbi_accuracy: 0.8440\n",
      "Epoch 37/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3530 - crf_viterbi_accuracy: 0.9907 - val_loss: 25.9165 - val_crf_viterbi_accuracy: 0.8658\n",
      "Epoch 38/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3505 - crf_viterbi_accuracy: 0.9920 - val_loss: 26.0137 - val_crf_viterbi_accuracy: 0.8302\n",
      "Epoch 39/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3475 - crf_viterbi_accuracy: 0.9930 - val_loss: 25.9408 - val_crf_viterbi_accuracy: 0.8634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3450 - crf_viterbi_accuracy: 0.9940 - val_loss: 25.9849 - val_crf_viterbi_accuracy: 0.8496\n",
      "Epoch 41/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3431 - crf_viterbi_accuracy: 0.9947 - val_loss: 26.0379 - val_crf_viterbi_accuracy: 0.8357\n",
      "Epoch 42/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3424 - crf_viterbi_accuracy: 0.9951 - val_loss: 26.0211 - val_crf_viterbi_accuracy: 0.8424\n",
      "Epoch 43/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3399 - crf_viterbi_accuracy: 0.9965 - val_loss: 26.1215 - val_crf_viterbi_accuracy: 0.8216\n",
      "Epoch 44/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3384 - crf_viterbi_accuracy: 0.9964 - val_loss: 26.0479 - val_crf_viterbi_accuracy: 0.8433\n",
      "Epoch 45/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3372 - crf_viterbi_accuracy: 0.9974 - val_loss: 26.1225 - val_crf_viterbi_accuracy: 0.8328\n",
      "Epoch 46/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3357 - crf_viterbi_accuracy: 0.9975 - val_loss: 26.1317 - val_crf_viterbi_accuracy: 0.8343\n",
      "Epoch 47/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3352 - crf_viterbi_accuracy: 0.9978 - val_loss: 26.1433 - val_crf_viterbi_accuracy: 0.8390\n",
      "Epoch 48/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3346 - crf_viterbi_accuracy: 0.9981 - val_loss: 26.1677 - val_crf_viterbi_accuracy: 0.8369\n",
      "Epoch 49/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3337 - crf_viterbi_accuracy: 0.9983 - val_loss: 26.1430 - val_crf_viterbi_accuracy: 0.8422\n",
      "Epoch 50/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3326 - crf_viterbi_accuracy: 0.9988 - val_loss: 26.2222 - val_crf_viterbi_accuracy: 0.8324\n",
      "Epoch 51/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3325 - crf_viterbi_accuracy: 0.9987 - val_loss: 26.2052 - val_crf_viterbi_accuracy: 0.8450\n",
      "Epoch 52/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3323 - crf_viterbi_accuracy: 0.9988 - val_loss: 26.2813 - val_crf_viterbi_accuracy: 0.8215\n",
      "Epoch 53/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3319 - crf_viterbi_accuracy: 0.9988 - val_loss: 26.2758 - val_crf_viterbi_accuracy: 0.8314\n",
      "Epoch 54/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3313 - crf_viterbi_accuracy: 0.9990 - val_loss: 26.2659 - val_crf_viterbi_accuracy: 0.8330\n",
      "Epoch 55/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3306 - crf_viterbi_accuracy: 0.9994 - val_loss: 26.2442 - val_crf_viterbi_accuracy: 0.8485\n",
      "Epoch 56/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3304 - crf_viterbi_accuracy: 0.9993 - val_loss: 26.2215 - val_crf_viterbi_accuracy: 0.8423\n",
      "Epoch 57/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3304 - crf_viterbi_accuracy: 0.9993 - val_loss: 26.2596 - val_crf_viterbi_accuracy: 0.8377\n",
      "Epoch 58/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3302 - crf_viterbi_accuracy: 0.9994 - val_loss: 26.2762 - val_crf_viterbi_accuracy: 0.8456\n",
      "Epoch 59/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3300 - crf_viterbi_accuracy: 0.9994 - val_loss: 26.2793 - val_crf_viterbi_accuracy: 0.8415\n",
      "Epoch 60/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3296 - crf_viterbi_accuracy: 0.9996 - val_loss: 26.3671 - val_crf_viterbi_accuracy: 0.8311\n",
      "Epoch 61/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3294 - crf_viterbi_accuracy: 0.9996 - val_loss: 26.4559 - val_crf_viterbi_accuracy: 0.8288\n",
      "Epoch 62/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3294 - crf_viterbi_accuracy: 0.9995 - val_loss: 26.3845 - val_crf_viterbi_accuracy: 0.8371\n",
      "Epoch 63/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3292 - crf_viterbi_accuracy: 0.9998 - val_loss: 26.3537 - val_crf_viterbi_accuracy: 0.8390\n",
      "Epoch 64/150\n",
      "3133/3133 [==============================] - 8s 2ms/step - loss: 26.3293 - crf_viterbi_accuracy: 0.9997 - val_loss: 26.4736 - val_crf_viterbi_accuracy: 0.8220\n",
      "Epoch 65/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3290 - crf_viterbi_accuracy: 0.9998 - val_loss: 26.4038 - val_crf_viterbi_accuracy: 0.8364\n",
      "Epoch 66/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3286 - crf_viterbi_accuracy: 0.9998 - val_loss: 26.4613 - val_crf_viterbi_accuracy: 0.8203\n",
      "Epoch 67/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3288 - crf_viterbi_accuracy: 0.9998 - val_loss: 26.4863 - val_crf_viterbi_accuracy: 0.8308\n",
      "Epoch 68/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3288 - crf_viterbi_accuracy: 0.9997 - val_loss: 26.3864 - val_crf_viterbi_accuracy: 0.8415\n",
      "Epoch 69/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3288 - crf_viterbi_accuracy: 0.9997 - val_loss: 26.4198 - val_crf_viterbi_accuracy: 0.8428\n",
      "Epoch 70/150\n",
      "3133/3133 [==============================] - 8s 3ms/step - loss: 26.3285 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.4495 - val_crf_viterbi_accuracy: 0.8331\n",
      "Epoch 71/150\n",
      "3133/3133 [==============================] - 8s 3ms/step - loss: 26.3284 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.4247 - val_crf_viterbi_accuracy: 0.8436\n",
      "Epoch 72/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3284 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.4480 - val_crf_viterbi_accuracy: 0.8447\n",
      "Epoch 73/150\n",
      "3133/3133 [==============================] - 8s 2ms/step - loss: 26.3284 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.4729 - val_crf_viterbi_accuracy: 0.8302\n",
      "Epoch 74/150\n",
      "3133/3133 [==============================] - 8s 2ms/step - loss: 26.3285 - crf_viterbi_accuracy: 0.9997 - val_loss: 26.4328 - val_crf_viterbi_accuracy: 0.8374\n",
      "Epoch 75/150\n",
      "3133/3133 [==============================] - 9s 3ms/step - loss: 26.3284 - crf_viterbi_accuracy: 0.9998 - val_loss: 26.6296 - val_crf_viterbi_accuracy: 0.8071\n",
      "Epoch 76/150\n",
      "3133/3133 [==============================] - 8s 2ms/step - loss: 26.3283 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.4581 - val_crf_viterbi_accuracy: 0.8380\n",
      "Epoch 77/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3281 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.5203 - val_crf_viterbi_accuracy: 0.8322\n",
      "Epoch 78/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3282 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.4584 - val_crf_viterbi_accuracy: 0.8342\n",
      "Epoch 79/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3282 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.4003 - val_crf_viterbi_accuracy: 0.8561\n",
      "Epoch 80/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.4636 - val_crf_viterbi_accuracy: 0.8438\n",
      "Epoch 81/150\n",
      "3133/3133 [==============================] - 7s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.5282 - val_crf_viterbi_accuracy: 0.8391\n",
      "Epoch 82/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3284 - crf_viterbi_accuracy: 0.9997 - val_loss: 26.4482 - val_crf_viterbi_accuracy: 0.8450\n",
      "Epoch 83/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.5624 - val_crf_viterbi_accuracy: 0.8288\n",
      "Epoch 84/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.5534 - val_crf_viterbi_accuracy: 0.8349\n",
      "Epoch 85/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3281 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.5385 - val_crf_viterbi_accuracy: 0.8342\n",
      "Epoch 86/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3281 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.5779 - val_crf_viterbi_accuracy: 0.8307\n",
      "Epoch 87/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.5808 - val_crf_viterbi_accuracy: 0.8305\n",
      "Epoch 88/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.5351 - val_crf_viterbi_accuracy: 0.8497\n",
      "Epoch 89/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.5805 - val_crf_viterbi_accuracy: 0.8485\n",
      "Epoch 90/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6228 - val_crf_viterbi_accuracy: 0.8365\n",
      "Epoch 91/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7331 - val_crf_viterbi_accuracy: 0.8258\n",
      "Epoch 92/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6678 - val_crf_viterbi_accuracy: 0.8306\n",
      "Epoch 93/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6519 - val_crf_viterbi_accuracy: 0.8350\n",
      "Epoch 94/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7059 - val_crf_viterbi_accuracy: 0.8302\n",
      "Epoch 95/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6610 - val_crf_viterbi_accuracy: 0.8341\n",
      "Epoch 96/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.6678 - val_crf_viterbi_accuracy: 0.8361\n",
      "Epoch 97/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6981 - val_crf_viterbi_accuracy: 0.8353\n",
      "Epoch 98/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6890 - val_crf_viterbi_accuracy: 0.8412\n",
      "Epoch 99/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6427 - val_crf_viterbi_accuracy: 0.8469\n",
      "Epoch 100/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6447 - val_crf_viterbi_accuracy: 0.8436\n",
      "Epoch 101/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6848 - val_crf_viterbi_accuracy: 0.8406\n",
      "Epoch 102/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3281 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.7617 - val_crf_viterbi_accuracy: 0.8243\n",
      "Epoch 103/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6739 - val_crf_viterbi_accuracy: 0.8339\n",
      "Epoch 104/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8403 - val_crf_viterbi_accuracy: 0.8195\n",
      "Epoch 105/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6590 - val_crf_viterbi_accuracy: 0.8479\n",
      "Epoch 106/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7062 - val_crf_viterbi_accuracy: 0.8375\n",
      "Epoch 107/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6729 - val_crf_viterbi_accuracy: 0.8478\n",
      "Epoch 108/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7598 - val_crf_viterbi_accuracy: 0.8355\n",
      "Epoch 109/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.6965 - val_crf_viterbi_accuracy: 0.8489\n",
      "Epoch 110/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7277 - val_crf_viterbi_accuracy: 0.8429\n",
      "Epoch 111/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7400 - val_crf_viterbi_accuracy: 0.8474\n",
      "Epoch 112/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7662 - val_crf_viterbi_accuracy: 0.8460\n",
      "Epoch 113/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8479 - val_crf_viterbi_accuracy: 0.8237\n",
      "Epoch 114/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.7996 - val_crf_viterbi_accuracy: 0.8332\n",
      "Epoch 115/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7726 - val_crf_viterbi_accuracy: 0.8364\n",
      "Epoch 116/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8192 - val_crf_viterbi_accuracy: 0.8342\n",
      "Epoch 117/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8029 - val_crf_viterbi_accuracy: 0.8450\n",
      "Epoch 118/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8190 - val_crf_viterbi_accuracy: 0.8382\n",
      "Epoch 119/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7667 - val_crf_viterbi_accuracy: 0.8394\n",
      "Epoch 120/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8327 - val_crf_viterbi_accuracy: 0.8368\n",
      "Epoch 121/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8808 - val_crf_viterbi_accuracy: 0.8322\n",
      "Epoch 122/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3281 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.9635 - val_crf_viterbi_accuracy: 0.8267\n",
      "Epoch 123/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8785 - val_crf_viterbi_accuracy: 0.8374\n",
      "Epoch 124/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 27.0328 - val_crf_viterbi_accuracy: 0.8071\n",
      "Epoch 125/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7960 - val_crf_viterbi_accuracy: 0.8503\n",
      "Epoch 126/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7759 - val_crf_viterbi_accuracy: 0.8465\n",
      "Epoch 127/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.9261 - val_crf_viterbi_accuracy: 0.8335\n",
      "Epoch 128/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8494 - val_crf_viterbi_accuracy: 0.8405\n",
      "Epoch 129/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8686 - val_crf_viterbi_accuracy: 0.8431\n",
      "Epoch 130/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7575 - val_crf_viterbi_accuracy: 0.8556\n",
      "Epoch 131/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7628 - val_crf_viterbi_accuracy: 0.8527\n",
      "Epoch 132/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8561 - val_crf_viterbi_accuracy: 0.8444\n",
      "Epoch 133/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8367 - val_crf_viterbi_accuracy: 0.8498\n",
      "Epoch 134/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.9412 - val_crf_viterbi_accuracy: 0.8413\n",
      "Epoch 135/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8484 - val_crf_viterbi_accuracy: 0.8512\n",
      "Epoch 136/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.9169 - val_crf_viterbi_accuracy: 0.8459\n",
      "Epoch 137/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8977 - val_crf_viterbi_accuracy: 0.8399\n",
      "Epoch 138/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8283 - val_crf_viterbi_accuracy: 0.8499\n",
      "Epoch 139/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8097 - val_crf_viterbi_accuracy: 0.8552\n",
      "Epoch 140/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7948 - val_crf_viterbi_accuracy: 0.8534\n",
      "Epoch 141/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8129 - val_crf_viterbi_accuracy: 0.8650\n",
      "Epoch 142/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8810 - val_crf_viterbi_accuracy: 0.8489\n",
      "Epoch 143/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7919 - val_crf_viterbi_accuracy: 0.8565\n",
      "Epoch 144/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8026 - val_crf_viterbi_accuracy: 0.8564\n",
      "Epoch 145/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8018 - val_crf_viterbi_accuracy: 0.8583\n",
      "Epoch 146/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8347 - val_crf_viterbi_accuracy: 0.8555\n",
      "Epoch 147/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.7840 - val_crf_viterbi_accuracy: 0.8612\n",
      "Epoch 148/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8423 - val_crf_viterbi_accuracy: 0.8513\n",
      "Epoch 149/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3280 - crf_viterbi_accuracy: 0.9999 - val_loss: 26.9290 - val_crf_viterbi_accuracy: 0.8435\n",
      "Epoch 150/150\n",
      "3133/3133 [==============================] - 6s 2ms/step - loss: 26.3279 - crf_viterbi_accuracy: 1.0000 - val_loss: 26.8680 - val_crf_viterbi_accuracy: 0.8493\n"
     ]
    }
   ],
   "source": [
    "history5 = model.fit(X_word_tr, np.array(y_tr),validation_data = (X_word_te, np.array(y_te)), batch_size=64, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJQD2DoqzWvD",
    "outputId": "1015fb25-0da4-42bd-8904-f19d85c0dcad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23cec1feb08>]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history5.history['crf_viterbi_accuracy'])\n",
    "plt.plot(history5.history['val_crf_viterbi_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6Y4wr7Anv3g"
   },
   "outputs": [],
   "source": [
    "pred5 = model.predict(X_word_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2RBoOG1rBpr"
   },
   "outputs": [],
   "source": [
    "pred_tags = get_tags(pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyKlLm1Xjs7l"
   },
   "outputs": [],
   "source": [
    "new_y_te = from_catagorical(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDe8zFkKjs7n"
   },
   "outputs": [],
   "source": [
    "hits , count_pad , count_o = get_hits(new_y_te,pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixCyD5gzjs7q",
    "outputId": "1de34b80-a3b0-4d71-e066-02497bb0c88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tags : 26175\n",
      "# of 'P' : 19946\n",
      "# of 'O' : 5403\n",
      "Total tags left without O,P : 826\n",
      "# of hits without 'PAD' and 'O' : 483\n",
      "# of predicted - 'O' : 4725\n",
      "# of predicted - 'PAD' : 20229\n",
      "Accuracy rate :  0.5847457627118644\n"
     ]
    }
   ],
   "source": [
    "print_scores(hits , count_pad , count_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iqFCVQtajs7t"
   },
   "source": [
    "## Model 6 : LSTM-CRF word and char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQ95A1IIjs7t",
    "outputId": "c1ced6c0-552d-4165-c33d-c7abfe590291",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras_contrib-2.0.8-py3.7.egg\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "C:\\Anaconda\\lib\\site-packages\\keras_contrib-2.0.8-py3.7.egg\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n"
     ]
    }
   ],
   "source": [
    "char_input = Input(shape = (X_char.shape[1],X_char.shape[2],))\n",
    "\n",
    "emb_char = Embedding(input_dim = n_chars + 1,output_dim = 16,mask_zero = True,\n",
    "                     input_length = (X_char_tr.shape[1],X_char_tr.shape[2],))(char_input)\n",
    "\n",
    "char_enc = TimeDistributed(GRU(units=20, return_sequences=False,\n",
    "                                recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "#lstm_char = LSTM(units=8, return_sequences=True)(char_enc)\n",
    "\n",
    "word_input = Input(shape = (X_word_tr.shape[1],))\n",
    "emb_word = Embedding(input_dim = n_words + 1,output_dim=16,mask_zero = True,input_length = max_len)(word_input)\n",
    "\n",
    "lstm_word = LSTM(units=8, return_sequences=True)(emb_word)\n",
    "\n",
    "x = concatenate([lstm_word, char_enc])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,recurrent_dropout=0.1))(x)  # variational biLSTM\n",
    "\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model([char_input,word_input], out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHpRV5TUrBp1",
    "outputId": "8d28f3be-1bf7-4847-971a-7c1671b75d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 75, 10)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 75, 16)       300048      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 75, 10, 16)   1632        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 75, 8)        800         embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 75, 20)       2220        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 75, 28)       0           lstm_2[0][0]                     \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 75, 28)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 75, 100)      31600       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 75, 50)       5050        bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "crf_2 (CRF)                     (None, 75, 19)       1368        time_distributed_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 342,718\n",
      "Trainable params: 342,718\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_w0E4gx_js7w",
    "outputId": "251004ba-3396-4fc0-90cb-e1bc13f066f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3133 samples, validate on 349 samples\n",
      "Epoch 1/200\n",
      "3133/3133 [==============================] - 11s 3ms/step - loss: 43.0142 - crf_viterbi_accuracy: 0.9910 - val_loss: 38.9728 - val_crf_viterbi_accuracy: 0.8415\n",
      "Epoch 2/200\n",
      "3133/3133 [==============================] - 12s 4ms/step - loss: 43.0149 - crf_viterbi_accuracy: 0.9900 - val_loss: 39.0133 - val_crf_viterbi_accuracy: 0.8218\n",
      "Epoch 3/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0147 - crf_viterbi_accuracy: 0.9903 - val_loss: 39.0215 - val_crf_viterbi_accuracy: 0.8315\n",
      "Epoch 4/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0113 - crf_viterbi_accuracy: 0.9927 - val_loss: 38.9873 - val_crf_viterbi_accuracy: 0.8500\n",
      "Epoch 5/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0145 - crf_viterbi_accuracy: 0.9907 - val_loss: 39.0283 - val_crf_viterbi_accuracy: 0.8349\n",
      "Epoch 6/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0122 - crf_viterbi_accuracy: 0.9924 - val_loss: 39.0194 - val_crf_viterbi_accuracy: 0.8330\n",
      "Epoch 7/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0120 - crf_viterbi_accuracy: 0.9927 - val_loss: 39.0430 - val_crf_viterbi_accuracy: 0.8343\n",
      "Epoch 8/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0130 - crf_viterbi_accuracy: 0.9918 - val_loss: 39.0541 - val_crf_viterbi_accuracy: 0.8356\n",
      "Epoch 9/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0131 - crf_viterbi_accuracy: 0.9913 - val_loss: 39.0096 - val_crf_viterbi_accuracy: 0.8390\n",
      "Epoch 10/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0133 - crf_viterbi_accuracy: 0.9916 - val_loss: 39.1030 - val_crf_viterbi_accuracy: 0.8280\n",
      "Epoch 11/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0141 - crf_viterbi_accuracy: 0.9917 - val_loss: 39.0783 - val_crf_viterbi_accuracy: 0.8256\n",
      "Epoch 12/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0144 - crf_viterbi_accuracy: 0.9921 - val_loss: 39.0533 - val_crf_viterbi_accuracy: 0.8439\n",
      "Epoch 13/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0117 - crf_viterbi_accuracy: 0.9929 - val_loss: 39.0891 - val_crf_viterbi_accuracy: 0.8292\n",
      "Epoch 14/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0134 - crf_viterbi_accuracy: 0.9919 - val_loss: 39.0727 - val_crf_viterbi_accuracy: 0.8364\n",
      "Epoch 15/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0150 - crf_viterbi_accuracy: 0.9922 - val_loss: 39.0513 - val_crf_viterbi_accuracy: 0.8415\n",
      "Epoch 16/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0118 - crf_viterbi_accuracy: 0.9922 - val_loss: 39.0623 - val_crf_viterbi_accuracy: 0.8483\n",
      "Epoch 17/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0121 - crf_viterbi_accuracy: 0.9922 - val_loss: 39.1157 - val_crf_viterbi_accuracy: 0.8353\n",
      "Epoch 18/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0129 - crf_viterbi_accuracy: 0.9911 - val_loss: 39.0661 - val_crf_viterbi_accuracy: 0.8439\n",
      "Epoch 19/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0119 - crf_viterbi_accuracy: 0.9925 - val_loss: 39.0889 - val_crf_viterbi_accuracy: 0.8371\n",
      "Epoch 20/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0091 - crf_viterbi_accuracy: 0.9945 - val_loss: 39.0928 - val_crf_viterbi_accuracy: 0.8329\n",
      "Epoch 21/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0105 - crf_viterbi_accuracy: 0.9926 - val_loss: 39.1098 - val_crf_viterbi_accuracy: 0.8454\n",
      "Epoch 22/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0110 - crf_viterbi_accuracy: 0.9927 - val_loss: 39.1389 - val_crf_viterbi_accuracy: 0.8349\n",
      "Epoch 23/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0129 - crf_viterbi_accuracy: 0.9919 - val_loss: 39.1279 - val_crf_viterbi_accuracy: 0.8430\n",
      "Epoch 24/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0102 - crf_viterbi_accuracy: 0.9925 - val_loss: 39.1173 - val_crf_viterbi_accuracy: 0.8425\n",
      "Epoch 25/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0116 - crf_viterbi_accuracy: 0.9929 - val_loss: 39.1710 - val_crf_viterbi_accuracy: 0.8252\n",
      "Epoch 26/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0114 - crf_viterbi_accuracy: 0.9941 - val_loss: 39.1552 - val_crf_viterbi_accuracy: 0.8338\n",
      "Epoch 27/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0111 - crf_viterbi_accuracy: 0.9930 - val_loss: 39.1855 - val_crf_viterbi_accuracy: 0.8217\n",
      "Epoch 28/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0105 - crf_viterbi_accuracy: 0.9925 - val_loss: 39.1358 - val_crf_viterbi_accuracy: 0.8336\n",
      "Epoch 29/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0127 - crf_viterbi_accuracy: 0.9943 - val_loss: 39.1511 - val_crf_viterbi_accuracy: 0.8245\n",
      "Epoch 30/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0112 - crf_viterbi_accuracy: 0.9930 - val_loss: 39.1161 - val_crf_viterbi_accuracy: 0.8338\n",
      "Epoch 31/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0099 - crf_viterbi_accuracy: 0.9929 - val_loss: 39.1348 - val_crf_viterbi_accuracy: 0.8441\n",
      "Epoch 32/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0104 - crf_viterbi_accuracy: 0.9926 - val_loss: 39.1368 - val_crf_viterbi_accuracy: 0.8350\n",
      "Epoch 33/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0104 - crf_viterbi_accuracy: 0.9932 - val_loss: 39.1386 - val_crf_viterbi_accuracy: 0.8429\n",
      "Epoch 34/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0112 - crf_viterbi_accuracy: 0.9941 - val_loss: 39.2111 - val_crf_viterbi_accuracy: 0.8214\n",
      "Epoch 35/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0079 - crf_viterbi_accuracy: 0.9938 - val_loss: 39.1570 - val_crf_viterbi_accuracy: 0.8335\n",
      "Epoch 36/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0102 - crf_viterbi_accuracy: 0.9936 - val_loss: 39.1610 - val_crf_viterbi_accuracy: 0.8389\n",
      "Epoch 37/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0116 - crf_viterbi_accuracy: 0.9931 - val_loss: 39.1887 - val_crf_viterbi_accuracy: 0.8280\n",
      "Epoch 38/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0097 - crf_viterbi_accuracy: 0.9938 - val_loss: 39.1723 - val_crf_viterbi_accuracy: 0.8406\n",
      "Epoch 39/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0088 - crf_viterbi_accuracy: 0.9941 - val_loss: 39.1631 - val_crf_viterbi_accuracy: 0.8422\n",
      "Epoch 40/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0089 - crf_viterbi_accuracy: 0.9937 - val_loss: 39.1980 - val_crf_viterbi_accuracy: 0.8467\n",
      "Epoch 41/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0084 - crf_viterbi_accuracy: 0.9943 - val_loss: 39.1694 - val_crf_viterbi_accuracy: 0.8416\n",
      "Epoch 42/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0108 - crf_viterbi_accuracy: 0.9941 - val_loss: 39.1449 - val_crf_viterbi_accuracy: 0.8439\n",
      "Epoch 43/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0080 - crf_viterbi_accuracy: 0.9947 - val_loss: 39.1965 - val_crf_viterbi_accuracy: 0.8554\n",
      "Epoch 44/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0094 - crf_viterbi_accuracy: 0.9931 - val_loss: 39.2200 - val_crf_viterbi_accuracy: 0.8317\n",
      "Epoch 45/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0074 - crf_viterbi_accuracy: 0.9951 - val_loss: 39.1887 - val_crf_viterbi_accuracy: 0.8342\n",
      "Epoch 46/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0090 - crf_viterbi_accuracy: 0.9947 - val_loss: 39.2438 - val_crf_viterbi_accuracy: 0.8216\n",
      "Epoch 47/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0067 - crf_viterbi_accuracy: 0.9945 - val_loss: 39.2266 - val_crf_viterbi_accuracy: 0.8444\n",
      "Epoch 48/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0122 - crf_viterbi_accuracy: 0.9937 - val_loss: 39.1996 - val_crf_viterbi_accuracy: 0.8373\n",
      "Epoch 49/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0096 - crf_viterbi_accuracy: 0.9947 - val_loss: 39.3041 - val_crf_viterbi_accuracy: 0.8293\n",
      "Epoch 50/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0063 - crf_viterbi_accuracy: 0.9952 - val_loss: 39.2294 - val_crf_viterbi_accuracy: 0.8455\n",
      "Epoch 51/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0055 - crf_viterbi_accuracy: 0.9955 - val_loss: 39.2462 - val_crf_viterbi_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0073 - crf_viterbi_accuracy: 0.9950 - val_loss: 39.2507 - val_crf_viterbi_accuracy: 0.8390\n",
      "Epoch 53/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0078 - crf_viterbi_accuracy: 0.9941 - val_loss: 39.2472 - val_crf_viterbi_accuracy: 0.8321\n",
      "Epoch 54/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0105 - crf_viterbi_accuracy: 0.9931 - val_loss: 39.2164 - val_crf_viterbi_accuracy: 0.8345\n",
      "Epoch 55/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0057 - crf_viterbi_accuracy: 0.9953 - val_loss: 39.2104 - val_crf_viterbi_accuracy: 0.8484\n",
      "Epoch 56/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0067 - crf_viterbi_accuracy: 0.9957 - val_loss: 39.2473 - val_crf_viterbi_accuracy: 0.8418\n",
      "Epoch 57/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0057 - crf_viterbi_accuracy: 0.9948 - val_loss: 39.2524 - val_crf_viterbi_accuracy: 0.8468\n",
      "Epoch 58/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0078 - crf_viterbi_accuracy: 0.9947 - val_loss: 39.2970 - val_crf_viterbi_accuracy: 0.8336\n",
      "Epoch 59/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0090 - crf_viterbi_accuracy: 0.9961 - val_loss: 39.3054 - val_crf_viterbi_accuracy: 0.8385\n",
      "Epoch 60/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0064 - crf_viterbi_accuracy: 0.9953 - val_loss: 39.2556 - val_crf_viterbi_accuracy: 0.8374\n",
      "Epoch 61/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0065 - crf_viterbi_accuracy: 0.9946 - val_loss: 39.2622 - val_crf_viterbi_accuracy: 0.8413\n",
      "Epoch 62/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0047 - crf_viterbi_accuracy: 0.9955 - val_loss: 39.2812 - val_crf_viterbi_accuracy: 0.8368\n",
      "Epoch 63/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0072 - crf_viterbi_accuracy: 0.9950 - val_loss: 39.2820 - val_crf_viterbi_accuracy: 0.8432\n",
      "Epoch 64/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0067 - crf_viterbi_accuracy: 0.9945 - val_loss: 39.2638 - val_crf_viterbi_accuracy: 0.8400\n",
      "Epoch 65/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0075 - crf_viterbi_accuracy: 0.9947 - val_loss: 39.3037 - val_crf_viterbi_accuracy: 0.8272\n",
      "Epoch 66/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0089 - crf_viterbi_accuracy: 0.9958 - val_loss: 39.2860 - val_crf_viterbi_accuracy: 0.8425\n",
      "Epoch 67/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0076 - crf_viterbi_accuracy: 0.9951 - val_loss: 39.2634 - val_crf_viterbi_accuracy: 0.8379\n",
      "Epoch 68/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0054 - crf_viterbi_accuracy: 0.9951 - val_loss: 39.2671 - val_crf_viterbi_accuracy: 0.8447\n",
      "Epoch 69/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0043 - crf_viterbi_accuracy: 0.9966 - val_loss: 39.3432 - val_crf_viterbi_accuracy: 0.8412\n",
      "Epoch 70/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0076 - crf_viterbi_accuracy: 0.9959 - val_loss: 39.2950 - val_crf_viterbi_accuracy: 0.8325\n",
      "Epoch 71/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0051 - crf_viterbi_accuracy: 0.9956 - val_loss: 39.2750 - val_crf_viterbi_accuracy: 0.8439\n",
      "Epoch 72/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0046 - crf_viterbi_accuracy: 0.9955 - val_loss: 39.3326 - val_crf_viterbi_accuracy: 0.8562\n",
      "Epoch 73/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0083 - crf_viterbi_accuracy: 0.9945 - val_loss: 39.2869 - val_crf_viterbi_accuracy: 0.8361\n",
      "Epoch 74/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0049 - crf_viterbi_accuracy: 0.9962 - val_loss: 39.3402 - val_crf_viterbi_accuracy: 0.8240\n",
      "Epoch 75/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0057 - crf_viterbi_accuracy: 0.9954 - val_loss: 39.3156 - val_crf_viterbi_accuracy: 0.8331\n",
      "Epoch 76/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0047 - crf_viterbi_accuracy: 0.9961 - val_loss: 39.2887 - val_crf_viterbi_accuracy: 0.8407\n",
      "Epoch 77/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0048 - crf_viterbi_accuracy: 0.9953 - val_loss: 39.2954 - val_crf_viterbi_accuracy: 0.8369\n",
      "Epoch 78/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0062 - crf_viterbi_accuracy: 0.9956 - val_loss: 39.3058 - val_crf_viterbi_accuracy: 0.8422\n",
      "Epoch 79/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0045 - crf_viterbi_accuracy: 0.9965 - val_loss: 39.3435 - val_crf_viterbi_accuracy: 0.8467\n",
      "Epoch 80/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0046 - crf_viterbi_accuracy: 0.9954 - val_loss: 39.3401 - val_crf_viterbi_accuracy: 0.8404\n",
      "Epoch 81/200\n",
      "3133/3133 [==============================] - 13s 4ms/step - loss: 43.0048 - crf_viterbi_accuracy: 0.9959 - val_loss: 39.3386 - val_crf_viterbi_accuracy: 0.8394\n",
      "Epoch 82/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0038 - crf_viterbi_accuracy: 0.9963 - val_loss: 39.3574 - val_crf_viterbi_accuracy: 0.8502\n",
      "Epoch 83/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0055 - crf_viterbi_accuracy: 0.9964 - val_loss: 39.3203 - val_crf_viterbi_accuracy: 0.8445\n",
      "Epoch 84/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0034 - crf_viterbi_accuracy: 0.9972 - val_loss: 39.3186 - val_crf_viterbi_accuracy: 0.8443\n",
      "Epoch 85/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0054 - crf_viterbi_accuracy: 0.9965 - val_loss: 39.3769 - val_crf_viterbi_accuracy: 0.8329\n",
      "Epoch 86/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0064 - crf_viterbi_accuracy: 0.9950 - val_loss: 39.3753 - val_crf_viterbi_accuracy: 0.8289\n",
      "Epoch 87/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0037 - crf_viterbi_accuracy: 0.9954 - val_loss: 39.3943 - val_crf_viterbi_accuracy: 0.8225\n",
      "Epoch 88/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0054 - crf_viterbi_accuracy: 0.9956 - val_loss: 39.3557 - val_crf_viterbi_accuracy: 0.8372\n",
      "Epoch 89/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0028 - crf_viterbi_accuracy: 0.9967 - val_loss: 39.3674 - val_crf_viterbi_accuracy: 0.8383\n",
      "Epoch 90/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0050 - crf_viterbi_accuracy: 0.9962 - val_loss: 39.3823 - val_crf_viterbi_accuracy: 0.8362\n",
      "Epoch 91/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0033 - crf_viterbi_accuracy: 0.9960 - val_loss: 39.4464 - val_crf_viterbi_accuracy: 0.8196\n",
      "Epoch 92/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0051 - crf_viterbi_accuracy: 0.9960 - val_loss: 39.4349 - val_crf_viterbi_accuracy: 0.8252\n",
      "Epoch 93/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0042 - crf_viterbi_accuracy: 0.9969 - val_loss: 39.3942 - val_crf_viterbi_accuracy: 0.8363\n",
      "Epoch 94/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0031 - crf_viterbi_accuracy: 0.9968 - val_loss: 39.4122 - val_crf_viterbi_accuracy: 0.8345\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0037 - crf_viterbi_accuracy: 0.9961 - val_loss: 39.3943 - val_crf_viterbi_accuracy: 0.8371\n",
      "Epoch 96/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0023 - crf_viterbi_accuracy: 0.9966 - val_loss: 39.4056 - val_crf_viterbi_accuracy: 0.8349\n",
      "Epoch 97/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0036 - crf_viterbi_accuracy: 0.9967 - val_loss: 39.4282 - val_crf_viterbi_accuracy: 0.8359\n",
      "Epoch 98/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0047 - crf_viterbi_accuracy: 0.9955 - val_loss: 39.4101 - val_crf_viterbi_accuracy: 0.8380\n",
      "Epoch 99/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0036 - crf_viterbi_accuracy: 0.9971 - val_loss: 39.4376 - val_crf_viterbi_accuracy: 0.8420\n",
      "Epoch 100/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0056 - crf_viterbi_accuracy: 0.9968 - val_loss: 39.4536 - val_crf_viterbi_accuracy: 0.8383\n",
      "Epoch 101/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0049 - crf_viterbi_accuracy: 0.9964 - val_loss: 39.4720 - val_crf_viterbi_accuracy: 0.8385\n",
      "Epoch 102/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0027 - crf_viterbi_accuracy: 0.9963 - val_loss: 39.4628 - val_crf_viterbi_accuracy: 0.8373\n",
      "Epoch 103/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0036 - crf_viterbi_accuracy: 0.9957 - val_loss: 39.4381 - val_crf_viterbi_accuracy: 0.8455\n",
      "Epoch 104/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0025 - crf_viterbi_accuracy: 0.9962 - val_loss: 39.4677 - val_crf_viterbi_accuracy: 0.8371\n",
      "Epoch 105/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0032 - crf_viterbi_accuracy: 0.9968 - val_loss: 39.4524 - val_crf_viterbi_accuracy: 0.8352\n",
      "Epoch 106/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0026 - crf_viterbi_accuracy: 0.9969 - val_loss: 39.4593 - val_crf_viterbi_accuracy: 0.8349\n",
      "Epoch 107/200\n",
      "3133/3133 [==============================] - 18s 6ms/step - loss: 43.0017 - crf_viterbi_accuracy: 0.9972 - val_loss: 39.4517 - val_crf_viterbi_accuracy: 0.8385\n",
      "Epoch 108/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0032 - crf_viterbi_accuracy: 0.9967 - val_loss: 39.4689 - val_crf_viterbi_accuracy: 0.8353\n",
      "Epoch 109/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0034 - crf_viterbi_accuracy: 0.9961 - val_loss: 39.4191 - val_crf_viterbi_accuracy: 0.8390\n",
      "Epoch 110/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0026 - crf_viterbi_accuracy: 0.9964 - val_loss: 39.4456 - val_crf_viterbi_accuracy: 0.8345\n",
      "Epoch 111/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0056 - crf_viterbi_accuracy: 0.9958 - val_loss: 39.4658 - val_crf_viterbi_accuracy: 0.8384\n",
      "Epoch 112/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0047 - crf_viterbi_accuracy: 0.9965 - val_loss: 39.4788 - val_crf_viterbi_accuracy: 0.8416\n",
      "Epoch 113/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0047 - crf_viterbi_accuracy: 0.9968 - val_loss: 39.4446 - val_crf_viterbi_accuracy: 0.8476\n",
      "Epoch 114/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0023 - crf_viterbi_accuracy: 0.9964 - val_loss: 39.4117 - val_crf_viterbi_accuracy: 0.8393\n",
      "Epoch 115/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0027 - crf_viterbi_accuracy: 0.9960 - val_loss: 39.5269 - val_crf_viterbi_accuracy: 0.8491\n",
      "Epoch 116/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0032 - crf_viterbi_accuracy: 0.9965 - val_loss: 39.4829 - val_crf_viterbi_accuracy: 0.8461\n",
      "Epoch 117/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0031 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.4942 - val_crf_viterbi_accuracy: 0.8409\n",
      "Epoch 118/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0025 - crf_viterbi_accuracy: 0.9968 - val_loss: 39.4952 - val_crf_viterbi_accuracy: 0.8329\n",
      "Epoch 119/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0022 - crf_viterbi_accuracy: 0.9963 - val_loss: 39.5064 - val_crf_viterbi_accuracy: 0.8383\n",
      "Epoch 120/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0037 - crf_viterbi_accuracy: 0.9971 - val_loss: 39.5283 - val_crf_viterbi_accuracy: 0.8298\n",
      "Epoch 121/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0014 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.5003 - val_crf_viterbi_accuracy: 0.8362\n",
      "Epoch 122/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0039 - crf_viterbi_accuracy: 0.9972 - val_loss: 39.5176 - val_crf_viterbi_accuracy: 0.8348\n",
      "Epoch 123/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0015 - crf_viterbi_accuracy: 0.9970 - val_loss: 39.5418 - val_crf_viterbi_accuracy: 0.8272\n",
      "Epoch 124/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0032 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.5468 - val_crf_viterbi_accuracy: 0.8317\n",
      "Epoch 125/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0032 - crf_viterbi_accuracy: 0.9966 - val_loss: 39.5194 - val_crf_viterbi_accuracy: 0.8376\n",
      "Epoch 126/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0018 - crf_viterbi_accuracy: 0.9972 - val_loss: 39.5059 - val_crf_viterbi_accuracy: 0.8366\n",
      "Epoch 127/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0019 - crf_viterbi_accuracy: 0.9968 - val_loss: 39.5647 - val_crf_viterbi_accuracy: 0.8259\n",
      "Epoch 128/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0010 - crf_viterbi_accuracy: 0.9975 - val_loss: 39.5397 - val_crf_viterbi_accuracy: 0.8430\n",
      "Epoch 129/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0006 - crf_viterbi_accuracy: 0.9975 - val_loss: 39.5739 - val_crf_viterbi_accuracy: 0.8312\n",
      "Epoch 130/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0032 - crf_viterbi_accuracy: 0.9971 - val_loss: 39.5308 - val_crf_viterbi_accuracy: 0.8331\n",
      "Epoch 131/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0005 - crf_viterbi_accuracy: 0.9977 - val_loss: 39.6284 - val_crf_viterbi_accuracy: 0.8282\n",
      "Epoch 132/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0018 - crf_viterbi_accuracy: 0.9971 - val_loss: 39.5621 - val_crf_viterbi_accuracy: 0.8312\n",
      "Epoch 133/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0024 - crf_viterbi_accuracy: 0.9971 - val_loss: 39.5480 - val_crf_viterbi_accuracy: 0.8427\n",
      "Epoch 134/200\n",
      "3133/3133 [==============================] - 17s 5ms/step - loss: 43.0035 - crf_viterbi_accuracy: 0.9973 - val_loss: 39.5472 - val_crf_viterbi_accuracy: 0.8474\n",
      "Epoch 135/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0009 - crf_viterbi_accuracy: 0.9971 - val_loss: 39.5792 - val_crf_viterbi_accuracy: 0.8336\n",
      "Epoch 136/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0035 - crf_viterbi_accuracy: 0.9955 - val_loss: 39.5406 - val_crf_viterbi_accuracy: 0.8439\n",
      "Epoch 137/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0027 - crf_viterbi_accuracy: 0.9972 - val_loss: 39.5844 - val_crf_viterbi_accuracy: 0.8510\n",
      "Epoch 138/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0014 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.6026 - val_crf_viterbi_accuracy: 0.8212\n",
      "Epoch 139/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0006 - crf_viterbi_accuracy: 0.9978 - val_loss: 39.5773 - val_crf_viterbi_accuracy: 0.8359\n",
      "Epoch 140/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0017 - crf_viterbi_accuracy: 0.9975 - val_loss: 39.5829 - val_crf_viterbi_accuracy: 0.8376\n",
      "Epoch 141/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0041 - crf_viterbi_accuracy: 0.9975 - val_loss: 39.5765 - val_crf_viterbi_accuracy: 0.8392\n",
      "Epoch 142/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0010 - crf_viterbi_accuracy: 0.9977 - val_loss: 39.5693 - val_crf_viterbi_accuracy: 0.8340\n",
      "Epoch 143/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0015 - crf_viterbi_accuracy: 0.9983 - val_loss: 39.5799 - val_crf_viterbi_accuracy: 0.8451\n",
      "Epoch 144/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0023 - crf_viterbi_accuracy: 0.9970 - val_loss: 39.5673 - val_crf_viterbi_accuracy: 0.8432\n",
      "Epoch 145/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0003 - crf_viterbi_accuracy: 0.9980 - val_loss: 39.5925 - val_crf_viterbi_accuracy: 0.8399\n",
      "Epoch 146/200\n",
      "3133/3133 [==============================] - 14s 4ms/step - loss: 43.0014 - crf_viterbi_accuracy: 0.9976 - val_loss: 39.5814 - val_crf_viterbi_accuracy: 0.8328\n",
      "Epoch 147/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0013 - crf_viterbi_accuracy: 0.9977 - val_loss: 39.6144 - val_crf_viterbi_accuracy: 0.8373\n",
      "Epoch 148/200\n",
      "3133/3133 [==============================] - 17s 5ms/step - loss: 43.0005 - crf_viterbi_accuracy: 0.9980 - val_loss: 39.6017 - val_crf_viterbi_accuracy: 0.8392\n",
      "Epoch 149/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0017 - crf_viterbi_accuracy: 0.9975 - val_loss: 39.6054 - val_crf_viterbi_accuracy: 0.8334\n",
      "Epoch 150/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0015 - crf_viterbi_accuracy: 0.9977 - val_loss: 39.6456 - val_crf_viterbi_accuracy: 0.8383\n",
      "Epoch 151/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0015 - crf_viterbi_accuracy: 0.9971 - val_loss: 39.6259 - val_crf_viterbi_accuracy: 0.8397\n",
      "Epoch 152/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0013 - crf_viterbi_accuracy: 0.9980 - val_loss: 39.6523 - val_crf_viterbi_accuracy: 0.8432\n",
      "Epoch 153/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0004 - crf_viterbi_accuracy: 0.9980 - val_loss: 39.6331 - val_crf_viterbi_accuracy: 0.8420\n",
      "Epoch 154/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0007 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.6025 - val_crf_viterbi_accuracy: 0.8432\n",
      "Epoch 155/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0002 - crf_viterbi_accuracy: 0.9970 - val_loss: 39.6437 - val_crf_viterbi_accuracy: 0.8476\n",
      "Epoch 156/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0018 - crf_viterbi_accuracy: 0.9972 - val_loss: 39.6385 - val_crf_viterbi_accuracy: 0.8334\n",
      "Epoch 157/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0022 - crf_viterbi_accuracy: 0.9969 - val_loss: 39.6534 - val_crf_viterbi_accuracy: 0.8294\n",
      "Epoch 158/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0012 - crf_viterbi_accuracy: 0.9976 - val_loss: 39.6278 - val_crf_viterbi_accuracy: 0.8409\n",
      "Epoch 159/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0011 - crf_viterbi_accuracy: 0.9968 - val_loss: 39.6125 - val_crf_viterbi_accuracy: 0.8355\n",
      "Epoch 160/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9998 - crf_viterbi_accuracy: 0.9981 - val_loss: 39.6696 - val_crf_viterbi_accuracy: 0.8358\n",
      "Epoch 161/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0017 - crf_viterbi_accuracy: 0.9977 - val_loss: 39.6306 - val_crf_viterbi_accuracy: 0.8397\n",
      "Epoch 162/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0008 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.6738 - val_crf_viterbi_accuracy: 0.8394\n",
      "Epoch 163/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0007 - crf_viterbi_accuracy: 0.9971 - val_loss: 39.6770 - val_crf_viterbi_accuracy: 0.8361\n",
      "Epoch 164/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0004 - crf_viterbi_accuracy: 0.9980 - val_loss: 39.7088 - val_crf_viterbi_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0006 - crf_viterbi_accuracy: 0.9977 - val_loss: 39.7016 - val_crf_viterbi_accuracy: 0.8474\n",
      "Epoch 166/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0022 - crf_viterbi_accuracy: 0.9967 - val_loss: 39.7125 - val_crf_viterbi_accuracy: 0.8340\n",
      "Epoch 167/200\n",
      "3133/3133 [==============================] - 17s 5ms/step - loss: 43.0003 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.7031 - val_crf_viterbi_accuracy: 0.8359\n",
      "Epoch 168/200\n",
      "3133/3133 [==============================] - 17s 5ms/step - loss: 43.0003 - crf_viterbi_accuracy: 0.9978 - val_loss: 39.6890 - val_crf_viterbi_accuracy: 0.8373\n",
      "Epoch 169/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0019 - crf_viterbi_accuracy: 0.9973 - val_loss: 39.6732 - val_crf_viterbi_accuracy: 0.8314\n",
      "Epoch 170/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0000 - crf_viterbi_accuracy: 0.9978 - val_loss: 39.7301 - val_crf_viterbi_accuracy: 0.8251\n",
      "Epoch 171/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 42.9997 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.7083 - val_crf_viterbi_accuracy: 0.8326\n",
      "Epoch 172/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9990 - crf_viterbi_accuracy: 0.9983 - val_loss: 39.7452 - val_crf_viterbi_accuracy: 0.8268\n",
      "Epoch 173/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0017 - crf_viterbi_accuracy: 0.9971 - val_loss: 39.7822 - val_crf_viterbi_accuracy: 0.8118\n",
      "Epoch 174/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0007 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.7050 - val_crf_viterbi_accuracy: 0.8331\n",
      "Epoch 175/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9993 - crf_viterbi_accuracy: 0.9980 - val_loss: 39.7004 - val_crf_viterbi_accuracy: 0.8273\n",
      "Epoch 176/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0016 - crf_viterbi_accuracy: 0.9981 - val_loss: 39.7193 - val_crf_viterbi_accuracy: 0.8324\n",
      "Epoch 177/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0001 - crf_viterbi_accuracy: 0.9981 - val_loss: 39.7353 - val_crf_viterbi_accuracy: 0.8315\n",
      "Epoch 178/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9995 - crf_viterbi_accuracy: 0.9980 - val_loss: 39.7607 - val_crf_viterbi_accuracy: 0.8252\n",
      "Epoch 179/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0004 - crf_viterbi_accuracy: 0.9977 - val_loss: 39.7107 - val_crf_viterbi_accuracy: 0.8343\n",
      "Epoch 180/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0004 - crf_viterbi_accuracy: 0.9974 - val_loss: 39.7394 - val_crf_viterbi_accuracy: 0.8345\n",
      "Epoch 181/200\n",
      "3133/3133 [==============================] - 16s 5ms/step - loss: 43.0006 - crf_viterbi_accuracy: 0.9978 - val_loss: 39.7565 - val_crf_viterbi_accuracy: 0.8277\n",
      "Epoch 182/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9991 - crf_viterbi_accuracy: 0.9980 - val_loss: 39.7288 - val_crf_viterbi_accuracy: 0.8380\n",
      "Epoch 183/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0010 - crf_viterbi_accuracy: 0.9978 - val_loss: 39.7236 - val_crf_viterbi_accuracy: 0.8298\n",
      "Epoch 184/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0043 - crf_viterbi_accuracy: 0.9973 - val_loss: 39.7161 - val_crf_viterbi_accuracy: 0.8356\n",
      "Epoch 185/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9994 - crf_viterbi_accuracy: 0.9979 - val_loss: 39.7593 - val_crf_viterbi_accuracy: 0.8242\n",
      "Epoch 186/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9997 - crf_viterbi_accuracy: 0.9981 - val_loss: 39.7418 - val_crf_viterbi_accuracy: 0.8394\n",
      "Epoch 187/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0037 - crf_viterbi_accuracy: 0.9973 - val_loss: 39.7519 - val_crf_viterbi_accuracy: 0.8359\n",
      "Epoch 188/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0009 - crf_viterbi_accuracy: 0.9980 - val_loss: 39.7345 - val_crf_viterbi_accuracy: 0.8349\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9999 - crf_viterbi_accuracy: 0.9987 - val_loss: 39.7570 - val_crf_viterbi_accuracy: 0.8391\n",
      "Epoch 190/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9987 - crf_viterbi_accuracy: 0.9985 - val_loss: 39.7539 - val_crf_viterbi_accuracy: 0.8311\n",
      "Epoch 191/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9996 - crf_viterbi_accuracy: 0.9979 - val_loss: 39.7541 - val_crf_viterbi_accuracy: 0.8420\n",
      "Epoch 192/200\n",
      "3133/3133 [==============================] - 14s 5ms/step - loss: 43.0022 - crf_viterbi_accuracy: 0.9976 - val_loss: 39.7640 - val_crf_viterbi_accuracy: 0.8398\n",
      "Epoch 193/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9991 - crf_viterbi_accuracy: 0.9983 - val_loss: 39.7954 - val_crf_viterbi_accuracy: 0.8373\n",
      "Epoch 194/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0002 - crf_viterbi_accuracy: 0.9973 - val_loss: 39.8231 - val_crf_viterbi_accuracy: 0.8383\n",
      "Epoch 195/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9992 - crf_viterbi_accuracy: 0.9981 - val_loss: 39.7754 - val_crf_viterbi_accuracy: 0.8375\n",
      "Epoch 196/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0002 - crf_viterbi_accuracy: 0.9973 - val_loss: 39.8250 - val_crf_viterbi_accuracy: 0.8308\n",
      "Epoch 197/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9990 - crf_viterbi_accuracy: 0.9982 - val_loss: 39.8134 - val_crf_viterbi_accuracy: 0.8335\n",
      "Epoch 198/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0017 - crf_viterbi_accuracy: 0.9981 - val_loss: 39.8100 - val_crf_viterbi_accuracy: 0.8347\n",
      "Epoch 199/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 42.9997 - crf_viterbi_accuracy: 0.9979 - val_loss: 39.8021 - val_crf_viterbi_accuracy: 0.8322\n",
      "Epoch 200/200\n",
      "3133/3133 [==============================] - 15s 5ms/step - loss: 43.0016 - crf_viterbi_accuracy: 0.9981 - val_loss: 39.8139 - val_crf_viterbi_accuracy: 0.8244\n"
     ]
    }
   ],
   "source": [
    "history6 = model.fit([X_char_tr,X_word_tr], y_tr,validation_data = ([X_char_te,X_word_te], y_te), batch_size=256, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbR98ac9rBp4",
    "outputId": "a56c06d5-e591-49ce-9724-c1ac38e80a8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c81915508>]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history6.history['crf_viterbi_accuracy'])\n",
    "plt.plot(history6.history['val_crf_viterbi_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wr1I50D2js7x"
   },
   "outputs": [],
   "source": [
    "pred6 = model.predict([X_char_te,X_word_te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7HooU1Igjs7y"
   },
   "outputs": [],
   "source": [
    "pred_tags = get_tags(pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyveLPEQrBp7"
   },
   "outputs": [],
   "source": [
    "hits,count_pad,count_o = get_hits(new_y_te,pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUGwzE4zrBp8",
    "outputId": "ab0c68f4-ac31-423f-a4c4-69dc6a595fb5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tags : 26175\n",
      "# of 'P' : 19946\n",
      "# of 'O' : 5403\n",
      "Total tags left without O,P : 826\n",
      "# of hits without 'PAD' and 'O' : 13\n",
      "# of predicted - 'O' : 3491\n",
      "# of predicted - 'PAD' : 21910\n",
      "Accuracy rate :  0.015738498789346248\n"
     ]
    }
   ],
   "source": [
    "print_scores(hits,count_pad,count_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31f3W_KEzWvg"
   },
   "source": [
    "# cuDNN \n",
    "The NVIDIA CUDA Deep Neural Network library (cuDNN) is a GPU-accelerated library of primitives for deep neural networks.<br> \n",
    "cuDNN provides highly tuned implementations for standard routines such as forward and backward convolution, pooling, normalization, and activation layers, cuDNN is used to accelerate the learning time.<br><br>\n",
    "The requirements to use the cuDNN implementation are:<br>\n",
    "1.activation == tanh<br>\n",
    "2.recurrent_activation == sigmoid<br>\n",
    "3.recurrent_dropout == 0<br>\n",
    "4.unroll is False<br>\n",
    "5.use_bias is True<br>\n",
    "6.Inputs, if use masking, are strictly right-padded.<br>\n",
    "7.Eager execution is enabled in the outermost context.<br>\n",
    "\n",
    "https://developer.nvidia.com/cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmynzbjArBp9"
   },
   "source": [
    "# Comparing to a bigger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TA-viHa9rBp-"
   },
   "source": [
    "Getting a large,good tagged dataset for a specific langauge is a hard task.<br>\n",
    "In order to valuate my hit rates, we will try a bigger dataset, on several models, and compare the accuracy rate.<br>\n",
    "I am going to use a English dataset.<br>\n",
    "In this dataset, there are - 47,958 sentences, with 35,178 unique words, and 98 unique chars.<br>\n",
    "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltxUW4v4rBp-"
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRd6jDqhrBqA",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ner_dataset.csv\",encoding= 'unicode_escape')\n",
    "df[\"Sentence #\"] = df[\"Sentence #\"].fillna(\"\")\n",
    "df = df.fillna(0)\n",
    "starting_idxs = list(df[df[\"Sentence #\"] != \"\"].index)\n",
    "sentences = []\n",
    "poses = []\n",
    "tags = []\n",
    "for idx in range(len(starting_idxs)-1):\n",
    "    sent = df['Word'][starting_idxs[idx]:starting_idxs[idx+1]]\n",
    "    sentences.append(sent)\n",
    "    pos = df['POS'][starting_idxs[idx]:starting_idxs[idx+1]]\n",
    "    poses.append(pos)\n",
    "    tag = list(df['Tag'][starting_idxs[idx]:starting_idxs[idx+1]])\n",
    "    tags.append(tag)\n",
    "words = []\n",
    "for sent in sentences:\n",
    "    for word in sent:\n",
    "        if(word not in words):\n",
    "            words.append(word)\n",
    "n_words = len(words)\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "word2idx[\"PAD\"] = 0\n",
    "distinct_tags = list(set(df[\"Tag\"].values))\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(distinct_tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "n_tags = len(distinct_tags) + 1\n",
    "chars = set([w_i for w in words for w_i in w])\n",
    "n_chars = len(chars)\n",
    "char2idx = {c: i + 1 for i, c in enumerate(chars)}\n",
    "char2idx[\"PAD\"] = 0\n",
    "X_word = [[word2idx[w] for w in s] for s in sentences]\n",
    "X_word = pad_sequences(maxlen=75, sequences=X_word, value=word2idx[\"PAD\"], padding='post', truncating='post')\n",
    "\n",
    "y = [[tag2idx[w] for w in s] for s in tags]\n",
    "y = np.array(y)\n",
    "    # Padding the labels with zeros, so it will match the length of the new padded sentences\n",
    "max_len = 75\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, value=tag2idx[\"PAD\"], padding='post', truncating='post')\n",
    "y = y.reshape(y.shape[0],y.shape[1],1)\n",
    "#\n",
    "max_len = 75\n",
    "max_len_char = 10\n",
    "X_char = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))\n",
    "X_char = np.array(X_char)\n",
    "\n",
    "\n",
    "X_word_tr, X_word_te, y_tr, y_te = train_test_split(X_word, y, test_size=0.1, random_state=2018)\n",
    "X_char_tr, X_char_te, asf, asd = train_test_split(X_char, y, test_size=0.1)\n",
    "\n",
    "temp = y.reshape(y.shape[0],y.shape[1]) \n",
    "y2 = [to_categorical(i, num_classes=n_tags+1) for i in temp] # this is for the crf\n",
    "y2 = np.array(y2)\n",
    "X_word_tr2, X_word_te2, y_tr2, y_te2 = train_test_split(X_word, y2, test_size=0.1, random_state=2018)\n",
    "new_y_te = from_catagorical(y_te2)\n",
    "new_y_te= np.array(new_y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCDYMcZHRaaA"
   },
   "outputs": [],
   "source": [
    "total_tags = 0\n",
    "count_padding = 0\n",
    "count_other = 0\n",
    "for sent in y_te:\n",
    "    for tag in sent:\n",
    "        total_tags+=1\n",
    "        if(tag == 0):\n",
    "            count_padding +=1\n",
    "        if(tag == tag2idx[\"O\"]):\n",
    "            count_other+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "0EZ1MZuirBqB",
    "outputId": "40e54352-4788-4161-8bad-89800d4c6b06",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td></td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td></td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td></td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td></td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td></td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentence #           Word  POS Tag\n",
       "0        Sentence: 1      Thousands  NNS   O\n",
       "1                                of   IN   O\n",
       "2                     demonstrators  NNS   O\n",
       "3                              have  VBP   O\n",
       "4                           marched  VBN   O\n",
       "...              ...            ...  ...  ..\n",
       "1048570                        they  PRP   O\n",
       "1048571                   responded  VBD   O\n",
       "1048572                          to   TO   O\n",
       "1048573                         the   DT   O\n",
       "1048574                      attack   NN   O\n",
       "\n",
       "[1048575 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "A9BPV4JbrBqC",
    "outputId": "17647a4b-4b8e-4527-ca2f-9072be60621d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 17 artists>"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flat_list2 = []\n",
    "for sublist in tags:\n",
    "    for item in sublist:\n",
    "        flat_list2.append(item)\n",
    "\n",
    "plt.figure(figsize = (20,5))\n",
    "w = Counter(flat_list2)\n",
    "plt.bar(w.keys(), w.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NF6OLfknrBqD"
   },
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEXu4AJXrBqD"
   },
   "source": [
    "### Model 2: Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWDNCFCFrBqD"
   },
   "outputs": [],
   "source": [
    "word_input = Input(shape = (X_word_tr.shape[1],))\n",
    "emb_word = Embedding(input_dim = n_words + 1,output_dim=16,mask_zero = True,input_length = max_len)(word_input)\n",
    "\n",
    "lstm1 = LSTM(units=8, return_sequences=True)(emb_word)\n",
    "\n",
    "out = Dense(n_tags+1,activation = \"softmax\")(lstm1)\n",
    "\n",
    "model = Model(word_input,out)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "xeGB3YnprBqE",
    "outputId": "2196ee9d-e695-4962-90fd-1907a078e60f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 75)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 75, 16)            562864    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 75, 8)             800       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75, 19)            171       \n",
      "=================================================================\n",
      "Total params: 563,835\n",
      "Trainable params: 563,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WuK-_pburBqG",
    "outputId": "d68ea8eb-4c5d-408b-d547-591c5c141a1d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "43/43 [==============================] - 4s 101ms/step - loss: 0.8207 - acc: 0.7925 - val_loss: 0.7517 - val_acc: 0.8467\n",
      "Epoch 2/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.5854 - acc: 0.8468 - val_loss: 0.4240 - val_acc: 0.8467\n",
      "Epoch 3/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.3460 - acc: 0.8468 - val_loss: 0.2953 - val_acc: 0.8467\n",
      "Epoch 4/120\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.2731 - acc: 0.8468 - val_loss: 0.2594 - val_acc: 0.8467\n",
      "Epoch 5/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.2489 - acc: 0.8468 - val_loss: 0.2429 - val_acc: 0.8467\n",
      "Epoch 6/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.2354 - acc: 0.8468 - val_loss: 0.2317 - val_acc: 0.8467\n",
      "Epoch 7/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.2252 - acc: 0.8469 - val_loss: 0.2222 - val_acc: 0.8469\n",
      "Epoch 8/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2157 - acc: 0.8468 - val_loss: 0.2125 - val_acc: 0.8469\n",
      "Epoch 9/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2054 - acc: 0.8469 - val_loss: 0.2017 - val_acc: 0.8469\n",
      "Epoch 10/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.1940 - acc: 0.8472 - val_loss: 0.1901 - val_acc: 0.8473\n",
      "Epoch 11/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.1825 - acc: 0.8473 - val_loss: 0.1793 - val_acc: 0.8475\n",
      "Epoch 12/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1722 - acc: 0.8477 - val_loss: 0.1702 - val_acc: 0.8483\n",
      "Epoch 13/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.1637 - acc: 0.8487 - val_loss: 0.1628 - val_acc: 0.8490\n",
      "Epoch 14/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1569 - acc: 0.8490 - val_loss: 0.1571 - val_acc: 0.8488\n",
      "Epoch 15/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.1515 - acc: 0.8491 - val_loss: 0.1524 - val_acc: 0.8487\n",
      "Epoch 16/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1470 - acc: 0.8492 - val_loss: 0.1484 - val_acc: 0.8486\n",
      "Epoch 17/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.1431 - acc: 0.8494 - val_loss: 0.1449 - val_acc: 0.8489\n",
      "Epoch 18/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1396 - acc: 0.8499 - val_loss: 0.1417 - val_acc: 0.8500\n",
      "Epoch 19/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1364 - acc: 0.8515 - val_loss: 0.1387 - val_acc: 0.8519\n",
      "Epoch 20/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1334 - acc: 0.8554 - val_loss: 0.1359 - val_acc: 0.8584\n",
      "Epoch 21/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1305 - acc: 0.8653 - val_loss: 0.1332 - val_acc: 0.8699\n",
      "Epoch 22/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1277 - acc: 0.8735 - val_loss: 0.1305 - val_acc: 0.8735\n",
      "Epoch 23/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1249 - acc: 0.8756 - val_loss: 0.1278 - val_acc: 0.8745\n",
      "Epoch 24/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.1221 - acc: 0.8766 - val_loss: 0.1250 - val_acc: 0.8753\n",
      "Epoch 25/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.1193 - acc: 0.8775 - val_loss: 0.1222 - val_acc: 0.8760\n",
      "Epoch 26/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1163 - acc: 0.8787 - val_loss: 0.1191 - val_acc: 0.8776\n",
      "Epoch 27/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.1131 - acc: 0.8840 - val_loss: 0.1160 - val_acc: 0.8871\n",
      "Epoch 28/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1099 - acc: 0.8937 - val_loss: 0.1128 - val_acc: 0.8926\n",
      "Epoch 29/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1067 - acc: 0.8974 - val_loss: 0.1098 - val_acc: 0.8948\n",
      "Epoch 30/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1036 - acc: 0.8997 - val_loss: 0.1068 - val_acc: 0.8963\n",
      "Epoch 31/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1007 - acc: 0.9011 - val_loss: 0.1041 - val_acc: 0.8974\n",
      "Epoch 32/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0979 - acc: 0.9024 - val_loss: 0.1014 - val_acc: 0.8995\n",
      "Epoch 33/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0953 - acc: 0.9043 - val_loss: 0.0989 - val_acc: 0.9004\n",
      "Epoch 34/120\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0928 - acc: 0.9055 - val_loss: 0.0966 - val_acc: 0.9015\n",
      "Epoch 35/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0904 - acc: 0.9073 - val_loss: 0.0943 - val_acc: 0.9040\n",
      "Epoch 36/120\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0881 - acc: 0.9103 - val_loss: 0.0921 - val_acc: 0.9068\n",
      "Epoch 37/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0859 - acc: 0.9135 - val_loss: 0.0900 - val_acc: 0.9098\n",
      "Epoch 38/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0837 - acc: 0.9171 - val_loss: 0.0880 - val_acc: 0.9145\n",
      "Epoch 39/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0816 - acc: 0.9220 - val_loss: 0.0860 - val_acc: 0.9179\n",
      "Epoch 40/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0795 - acc: 0.9259 - val_loss: 0.0840 - val_acc: 0.9219\n",
      "Epoch 41/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0774 - acc: 0.9303 - val_loss: 0.0820 - val_acc: 0.9254\n",
      "Epoch 42/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0753 - acc: 0.9337 - val_loss: 0.0801 - val_acc: 0.9278\n",
      "Epoch 43/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0733 - acc: 0.9360 - val_loss: 0.0783 - val_acc: 0.9294\n",
      "Epoch 44/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0713 - acc: 0.9373 - val_loss: 0.0764 - val_acc: 0.9305\n",
      "Epoch 45/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0694 - acc: 0.9385 - val_loss: 0.0746 - val_acc: 0.9320\n",
      "Epoch 46/120\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0674 - acc: 0.9409 - val_loss: 0.0728 - val_acc: 0.9355\n",
      "Epoch 47/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0655 - acc: 0.9455 - val_loss: 0.0711 - val_acc: 0.9405\n",
      "Epoch 48/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0637 - acc: 0.9498 - val_loss: 0.0694 - val_acc: 0.9423\n",
      "Epoch 49/120\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0619 - acc: 0.9512 - val_loss: 0.0678 - val_acc: 0.9433\n",
      "Epoch 50/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0602 - acc: 0.9521 - val_loss: 0.0662 - val_acc: 0.9443\n",
      "Epoch 51/120\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0585 - acc: 0.9536 - val_loss: 0.0647 - val_acc: 0.9464\n",
      "Epoch 52/120\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0569 - acc: 0.9556 - val_loss: 0.0633 - val_acc: 0.9477\n",
      "Epoch 53/120\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0555 - acc: 0.9566 - val_loss: 0.0620 - val_acc: 0.9484\n",
      "Epoch 54/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0541 - acc: 0.9573 - val_loss: 0.0608 - val_acc: 0.9490\n",
      "Epoch 55/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0528 - acc: 0.9580 - val_loss: 0.0597 - val_acc: 0.9493\n",
      "Epoch 56/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0515 - acc: 0.9585 - val_loss: 0.0587 - val_acc: 0.9498\n",
      "Epoch 57/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0504 - acc: 0.9589 - val_loss: 0.0577 - val_acc: 0.9504\n",
      "Epoch 58/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0493 - acc: 0.9596 - val_loss: 0.0569 - val_acc: 0.9512\n",
      "Epoch 59/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0483 - acc: 0.9614 - val_loss: 0.0560 - val_acc: 0.9526\n",
      "Epoch 60/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0473 - acc: 0.9623 - val_loss: 0.0552 - val_acc: 0.9530\n",
      "Epoch 61/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0464 - acc: 0.9628 - val_loss: 0.0545 - val_acc: 0.9533\n",
      "Epoch 62/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0456 - acc: 0.9631 - val_loss: 0.0539 - val_acc: 0.9535\n",
      "Epoch 63/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0448 - acc: 0.9635 - val_loss: 0.0533 - val_acc: 0.9536\n",
      "Epoch 64/120\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0441 - acc: 0.9638 - val_loss: 0.0527 - val_acc: 0.9540\n",
      "Epoch 65/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0434 - acc: 0.9641 - val_loss: 0.0522 - val_acc: 0.9541\n",
      "Epoch 66/120\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0427 - acc: 0.9645 - val_loss: 0.0517 - val_acc: 0.9543\n",
      "Epoch 67/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0421 - acc: 0.9648 - val_loss: 0.0513 - val_acc: 0.9545\n",
      "Epoch 68/120\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0415 - acc: 0.9651 - val_loss: 0.0508 - val_acc: 0.9546\n",
      "Epoch 69/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0410 - acc: 0.9653 - val_loss: 0.0504 - val_acc: 0.9546\n",
      "Epoch 70/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0404 - acc: 0.9655 - val_loss: 0.0500 - val_acc: 0.9547\n",
      "Epoch 71/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0399 - acc: 0.9658 - val_loss: 0.0497 - val_acc: 0.9550\n",
      "Epoch 72/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0394 - acc: 0.9661 - val_loss: 0.0494 - val_acc: 0.9552\n",
      "Epoch 73/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0390 - acc: 0.9662 - val_loss: 0.0491 - val_acc: 0.9552\n",
      "Epoch 74/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0385 - acc: 0.9664 - val_loss: 0.0488 - val_acc: 0.9553\n",
      "Epoch 75/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0381 - acc: 0.9666 - val_loss: 0.0485 - val_acc: 0.9552\n",
      "Epoch 76/120\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0377 - acc: 0.9669 - val_loss: 0.0483 - val_acc: 0.9554\n",
      "Epoch 77/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0373 - acc: 0.9671 - val_loss: 0.0481 - val_acc: 0.9554\n",
      "Epoch 78/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0370 - acc: 0.9673 - val_loss: 0.0478 - val_acc: 0.9556\n",
      "Epoch 79/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0366 - acc: 0.9675 - val_loss: 0.0477 - val_acc: 0.9556\n",
      "Epoch 80/120\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0362 - acc: 0.9677 - val_loss: 0.0474 - val_acc: 0.9558\n",
      "Epoch 81/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0359 - acc: 0.9679 - val_loss: 0.0473 - val_acc: 0.9558\n",
      "Epoch 82/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0356 - acc: 0.9682 - val_loss: 0.0471 - val_acc: 0.9559\n",
      "Epoch 83/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0353 - acc: 0.9683 - val_loss: 0.0469 - val_acc: 0.9559\n",
      "Epoch 84/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0349 - acc: 0.9685 - val_loss: 0.0467 - val_acc: 0.9560\n",
      "Epoch 85/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0346 - acc: 0.9687 - val_loss: 0.0466 - val_acc: 0.9560\n",
      "Epoch 86/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0343 - acc: 0.9689 - val_loss: 0.0464 - val_acc: 0.9561\n",
      "Epoch 87/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0340 - acc: 0.9691 - val_loss: 0.0463 - val_acc: 0.9560\n",
      "Epoch 88/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0337 - acc: 0.9693 - val_loss: 0.0461 - val_acc: 0.9560\n",
      "Epoch 89/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0334 - acc: 0.9694 - val_loss: 0.0460 - val_acc: 0.9561\n",
      "Epoch 90/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0331 - acc: 0.9697 - val_loss: 0.0458 - val_acc: 0.9562\n",
      "Epoch 91/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0328 - acc: 0.9699 - val_loss: 0.0458 - val_acc: 0.9560\n",
      "Epoch 92/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0325 - acc: 0.9700 - val_loss: 0.0457 - val_acc: 0.9561\n",
      "Epoch 93/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0323 - acc: 0.9703 - val_loss: 0.0456 - val_acc: 0.9563\n",
      "Epoch 94/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0320 - acc: 0.9705 - val_loss: 0.0456 - val_acc: 0.9561\n",
      "Epoch 95/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0318 - acc: 0.9706 - val_loss: 0.0455 - val_acc: 0.9561\n",
      "Epoch 96/120\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0315 - acc: 0.9708 - val_loss: 0.0454 - val_acc: 0.9562\n",
      "Epoch 97/120\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0312 - acc: 0.9710 - val_loss: 0.0453 - val_acc: 0.9563\n",
      "Epoch 98/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0310 - acc: 0.9713 - val_loss: 0.0453 - val_acc: 0.9562\n",
      "Epoch 99/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0307 - acc: 0.9714 - val_loss: 0.0451 - val_acc: 0.9565\n",
      "Epoch 100/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0305 - acc: 0.9717 - val_loss: 0.0451 - val_acc: 0.9563\n",
      "Epoch 101/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0303 - acc: 0.9718 - val_loss: 0.0450 - val_acc: 0.9564\n",
      "Epoch 102/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0300 - acc: 0.9720 - val_loss: 0.0451 - val_acc: 0.9563\n",
      "Epoch 103/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0298 - acc: 0.9721 - val_loss: 0.0451 - val_acc: 0.9562\n",
      "Epoch 104/120\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0296 - acc: 0.9724 - val_loss: 0.0451 - val_acc: 0.9561\n",
      "Epoch 105/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0294 - acc: 0.9725 - val_loss: 0.0450 - val_acc: 0.9562\n",
      "Epoch 106/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0291 - acc: 0.9727 - val_loss: 0.0451 - val_acc: 0.9562\n",
      "Epoch 107/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0289 - acc: 0.9729 - val_loss: 0.0451 - val_acc: 0.9562\n",
      "Epoch 108/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0287 - acc: 0.9730 - val_loss: 0.0451 - val_acc: 0.9562\n",
      "Epoch 109/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0285 - acc: 0.9732 - val_loss: 0.0452 - val_acc: 0.9560\n",
      "Epoch 110/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0283 - acc: 0.9733 - val_loss: 0.0451 - val_acc: 0.9563\n",
      "Epoch 111/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0281 - acc: 0.9735 - val_loss: 0.0454 - val_acc: 0.9558\n",
      "Epoch 112/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0279 - acc: 0.9736 - val_loss: 0.0452 - val_acc: 0.9559\n",
      "Epoch 113/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0277 - acc: 0.9737 - val_loss: 0.0452 - val_acc: 0.9562\n",
      "Epoch 114/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0275 - acc: 0.9739 - val_loss: 0.0453 - val_acc: 0.9559\n",
      "Epoch 115/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0273 - acc: 0.9741 - val_loss: 0.0454 - val_acc: 0.9559\n",
      "Epoch 116/120\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0271 - acc: 0.9742 - val_loss: 0.0453 - val_acc: 0.9561\n",
      "Epoch 117/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0268 - acc: 0.9743 - val_loss: 0.0454 - val_acc: 0.9559\n",
      "Epoch 118/120\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0266 - acc: 0.9745 - val_loss: 0.0452 - val_acc: 0.9561\n",
      "Epoch 119/120\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0263 - acc: 0.9747 - val_loss: 0.0453 - val_acc: 0.9560\n",
      "Epoch 120/120\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0261 - acc: 0.9749 - val_loss: 0.0453 - val_acc: 0.9560\n"
     ]
    }
   ],
   "source": [
    "history8 = model.fit(X_word_tr,y_tr2,validation_data = (X_word_te,y_te2),epochs = 120,batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "7VKzhO6qrBqH",
    "outputId": "6f84cdcf-ff71-4850-cff5-a0a166874e22"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oDqXuQ4rBqI"
   },
   "outputs": [],
   "source": [
    "pred8 = model.predict(X_word_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpY_KRxJrBqJ"
   },
   "outputs": [],
   "source": [
    "pred_tags = get_tags(pred8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKtpRgrzRH7S"
   },
   "outputs": [],
   "source": [
    "total_tags = 0\n",
    "count_padding = 0\n",
    "count_other = 0\n",
    "\n",
    "for sent in new_y_te:\n",
    "    for tag in sent:\n",
    "        total_tags+=1\n",
    "        if(tag == 0):\n",
    "            count_padding +=1\n",
    "        if(tag == tag2idx[\"O\"]):\n",
    "            count_other+=1\n",
    "            \n",
    "hits = 0\n",
    "count_pad = 0\n",
    "count_o = 0\n",
    "\n",
    "for real_tag,pred_tag in zip(y_te,pred_tags):\n",
    "    for y,yhat in zip(real_tag,pred_tag):\n",
    "           if(y == yhat and yhat != 0 and y != tag2idx[\"O\"]):\n",
    "               hits +=1\n",
    "           if(yhat == tag2idx[\"PAD\"] == y):\n",
    "               count_pad +=1\n",
    "           if(yhat == tag2idx[\"O\"] == y):\n",
    "               count_o +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "1OMW9no3rBqN",
    "outputId": "eda4cfaa-99ed-463c-b21f-cb33bc3c0564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tags : 359700\n",
      "# of 'P' : 254383\n",
      "# of 'O' : 89177\n",
      "Total tags left without O,P : 16140\n",
      "# of hits without 'PAD' and 'O' : 12534\n",
      "# of predicted - 'O' : 88150\n",
      "# of predicted - 'PAD' : 0\n",
      "Accuracy rate :  0.7765799256505577\n"
     ]
    }
   ],
   "source": [
    "print_scores(hits,count_pad,count_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nitSmlTjrBqa"
   },
   "source": [
    "### Model 5 : LSTM-CRF word based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrsPNsADzWwA",
    "outputId": "cae84f79-9ffb-4701-8b0c-0da1f8777b39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras_contrib-2.0.8-py3.7.egg\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "C:\\Anaconda\\lib\\site-packages\\keras_contrib-2.0.8-py3.7.egg\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n"
     ]
    }
   ],
   "source": [
    "word_input = Input(shape = (X_word_tr.shape[1],))\n",
    "emb_word = Embedding(input_dim = n_words + 1,output_dim=16,mask_zero = True,input_length = max_len)(word_input)\n",
    "\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(emb_word)  # variational biLSTM\n",
    "\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags+1,activation = \"sigmoid\")  # CRF layer\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model(word_input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wkW1BtErBqb",
    "outputId": "05a6bd1c-8b5a-4dd6-9e07-71a88991635d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_28 (Embedding)     (None, 75, 16)            562864    \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 75, 100)           26800     \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf_16 (CRF)                 (None, 75, 19)            1368      \n",
      "=================================================================\n",
      "Total params: 596,082\n",
      "Trainable params: 596,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_hUnjFZzWwC",
    "outputId": "919b871e-3e77-4e46-efe5-9f700855c5b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43162 samples, validate on 4796 samples\n",
      "Epoch 1/10\n",
      "43162/43162 [==============================] - 240s 6ms/step - loss: 11.0862 - crf_viterbi_accuracy: 0.8435 - val_loss: 10.9841 - val_crf_viterbi_accuracy: 0.8444\n",
      "Epoch 2/10\n",
      "43162/43162 [==============================] - 247s 6ms/step - loss: 11.0765 - crf_viterbi_accuracy: 0.8447 - val_loss: 10.9754 - val_crf_viterbi_accuracy: 0.8451\n",
      "Epoch 3/10\n",
      "43162/43162 [==============================] - 238s 6ms/step - loss: 11.0681 - crf_viterbi_accuracy: 0.8455 - val_loss: 10.9677 - val_crf_viterbi_accuracy: 0.8456\n",
      "Epoch 4/10\n",
      "43162/43162 [==============================] - 244s 6ms/step - loss: 11.0605 - crf_viterbi_accuracy: 0.8460 - val_loss: 10.9606 - val_crf_viterbi_accuracy: 0.8459\n",
      "Epoch 5/10\n",
      "43162/43162 [==============================] - 238s 6ms/step - loss: 11.0536 - crf_viterbi_accuracy: 0.8463 - val_loss: 10.9540 - val_crf_viterbi_accuracy: 0.8462\n",
      "Epoch 6/10\n",
      "43162/43162 [==============================] - 241s 6ms/step - loss: 11.0471 - crf_viterbi_accuracy: 0.8465 - val_loss: 10.9477 - val_crf_viterbi_accuracy: 0.8464\n",
      "Epoch 7/10\n",
      "43162/43162 [==============================] - 239s 6ms/step - loss: 11.0409 - crf_viterbi_accuracy: 0.8466 - val_loss: 10.9417 - val_crf_viterbi_accuracy: 0.8466\n",
      "Epoch 8/10\n",
      "43162/43162 [==============================] - 238s 6ms/step - loss: 11.0350 - crf_viterbi_accuracy: 0.8467 - val_loss: 10.9359 - val_crf_viterbi_accuracy: 0.8467\n",
      "Epoch 9/10\n",
      "43162/43162 [==============================] - 236s 5ms/step - loss: 11.0292 - crf_viterbi_accuracy: 0.8467 - val_loss: 10.9303 - val_crf_viterbi_accuracy: 0.8467\n",
      "Epoch 10/10\n",
      "43162/43162 [==============================] - 236s 5ms/step - loss: 11.0236 - crf_viterbi_accuracy: 0.8467 - val_loss: 10.9247 - val_crf_viterbi_accuracy: 0.8467\n"
     ]
    }
   ],
   "source": [
    "history10 = model.fit(X_word_tr,y_tr2,validation_data = (X_word_te,y_te2),epochs = 10,batch_size=round(X_word_tr.shape[0]/3)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4xwAeVgrBqf",
    "outputId": "2aa51ec8-8a3f-4b57-83fd-a839490ad504",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c8592c848>]"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXzV1Z3/8dfJcrMvhCQEkrDvOxhwoShuFbVqqzNuU1tprdNprZ1WO2Nn6fTn9NFprbbT/mp/M1artlCXWrW24FoX3CXKkgUCkTUkISGQjWx3Ob8/vgECBAnk++UueT8fjzxu7r3fnHO43rw9+dzzPV9jrUVERKJfXLgHICIi7lCgi4jECAW6iEiMUKCLiMQIBbqISIxICFfHubm5duzYseHqXkQkKn344Yd7rbV5/T0XtkAfO3YspaWl4epeRCQqGWN2HO85lVxERGKEAl1EJEYo0EVEYoQCXUQkRijQRURihAJdRCRGKNBFRGJE2Nahi4hEpVAQAt0Q6Or/Ntjdz+NHHTP5Eig8w/WhKdBFJDYEeqC7DXranNvu9t7bVujp/d7fdWzABnuOH859bm3AOc6E/IMeakVrCjMU6CISU4L+3tDt/ToYvMe7f8Rj7UeGdbBnQF1a4gjEJxEwSQTifPhNIn7jowcf3TaRLhLptgl02hQ6Qwl09H4dCCb0PpdIN4l046OHhN77vt7HDj/vNz5MYjJxickk+JKJ86WQ4EvG50tm2ZRxzPDg5VSgi4g7/F3QXg9te6CtDtp7b9vqoWNf/7PnYPfA2k5Mg6R0bFIGwcR0euJS6fIV0OEbRzsptIaSaA4msy/gY6/fR2O3j9quBBq6fbSTQrtN4QDJdJJEkPhDzRoDKYnxpPriSfUlkOqLJ8V35P1UXzwpib3fJ8UzPNF5LsUXT1pSn+d88aQmJZCa6LSRlBCHMcajF7t/CnQR+WSBbieU2+p7A7u+N6j7BHZ7PXTuP/Zn4xIhfQSk5kByFmQWQVIGJKVDUgbWl05PfBptNpmWUIoTyv5EGv1J7OlOoK4zkdrOOPYeCLK3vYf9+3oIho69bKYxkJPqY3i6j+FpSQwf4WNUmo9Z6UmHH0v3kZmceCi003wJJCee/tD1kgJdZKgKdPfOoo8T0Acf7zeoEyC9ADIKYPgEGLvI+T69ADJGQkYBNn0ENd0plNe2UbO/k70Humlq76GptZumAz00tfewt72b7kCon8H5yUiyDE83DE9PYnROKvNGDyM33cfwNB856UnkpvkY3hvYw1J9xMfFTjCfKgW6SCyyFvZthT0Vh4P5UAmk97Zz37E/F5fgzKgzCiBnPIw++1BAH/4aCSk5EHd41XMwZNm2t52K2lbKN7dQvruVitrdtHYFDh3jS4g7IoQn5Wc4Ad1nBp2bnkROmo+cNB/JifHHjk8+kQJdJBaEQtC4EXa8Azvedm7b9xx+3sT3zqBHwLCxMPqsIwM6fYRzmzr8iKDuT08gxJb6Nip2t1Je20JFbSuVta10+oOAE9zTCjL4zJxRzByVxYxRmYzPSyM9KSGmyhuRSIEuEo2Cfqhb3xve78LOd6Gr2XkuYxSMO9eZXRfOh8xCSM09YVD3p7MnyMb6VipqW6nY3UJ5bQub69vpCTplkjRfPDNGZXHdgmJmFmYxszCTCXnpJMbrnMVwUKCLRAN/J9SUOjPvne/Arg/A3+E8lzMBpl0BYxbBmLMhe4zzKeFJau3yU1nbSvluZ9ZdUdtCdUM7Bz+DzE5NZOaoLJZ9aiwzRmUxc1QmY4enEafadcRQoItEoq4WJ7QPlk92fwQhP2BgxEyY93kYcw6MPgcyRpx0803t3ZT3hvbB0smOpo5Dz4/ITGLGqCyWzihgRqFTNinMTlHJJMIp0EUiQXujM/Pe8a4T4nvKwYacDylHzYOz/sGZgY8+E1KGDbhZay31rV2U7z5y5l3X0nXomOKcFGaOyuLakmKmj8pkxqhM8jOSvfhXiscU6CLh0Lzr8AeYO9+FvZudxxOSoWgBnPtPTvmkaAH40k6pixXv7+CnL22m6YBzBqUxMCEvnYXjcpwPKwszmTEyi6zURLf+VRJmCnQRr1kLTdWHyyc73oGWXc5zSVnOrHvujc4MfORcSPANusvny+r4t2fLWTA2h9tnjWRmYSZTCzJJS9KvfCzTf10RL9SXw/a3Ds/ADzQ6j6flOatPzr7NqYGPmAFx7q63Lt2+j28+sY75o4fx2y8t1HruIUSBLuK2dY/Bs191vs8aDRMudMonYxbB8ImntAJloD5ubOeW35ZSmJ3Cr79QojAfYgYU6MaYpcDPgXjgQWvtj456fjTwKJDde8xd1tpVLo9VJPIF/fD6D50PMq/9HWQXn7auG9u6ufnhD4g3hkeWLSAnbfClG4kuJ1z9b4yJB+4HLgWmAzcYY6Yfddi/AU9aa+cB1wO/cnugIlFhw5PQvBPOu+u0hnlHT4BbHl1DY1s3D928gDHDT+2DVIluAzmdayFQba3daq3tAR4HrjrqGAtk9n6fBdS6N0SRKBEMwJv3QsFs54o0p0kgGOL2x9ZStruF/3vDfOYWZ5+2viWyDKTkUgjs6nO/BjjzqGO+D7xkjPkGkAZc1F9DxphbgVsBRo8efbJjFYlsFU87G2Jdt9zTOnlf1lq+/+cKXtnYwH9eNYOLp5/8SUYSOwYyQ+/vnXn0hsQ3AI9Ya4uAy4DfGWOOadta+4C1tsRaW5KXl3fyoxWJVKEgrL4X8qfDlMtPW7f/88ZWlr+3k78/bzw3nT32tPUrkWkggV4D9C0GFnFsSeXLwJMA1tp3gWQg140BikSFyj/B3io49zuntAnWqfjTut38+IVNXDFnFP98ydTT0qdEtoG889YAk4wx44wxPpwPPZ876pidwIUAxphpOIHe6OZARSJWKOTMznMnw/SjP17yxrsfN3HnH9Zz5rgc7v3b2dogS4ABBLq1NgDcBrwIbMRZzVJhjLnbGHNl72F3AF8xxqwHHgNuttYee50okVhUtQoaKmDxna6fJNSfzXvauPV3pYwZnsYDN5WQlKC15uIY0Dr03jXlq4567Ht9vq8EFrk7NJEoYC288WPn6j4zr/G8uz2tXSx7eA3JifE8smyB9mGRI2gXepHB2PIS1G+AxXdAvLcnXrd3B1j28Br2d/Tw8M0LKBqW6ml/En106r/IqbIW3rgHskfD7Os87cofDPG1FR9RtaeNh75YwszCLE/7k+ikGbrIqfr4VdhdCp/6NsR7V/qw1vKvz5SxenMjP/zcTJZMyfesL4luCnSRU2EtrP6Jc73OuTd62tUv/lrNk6U13H7BRK5boBPy5PgU6CKnYvtbzra4i/4REpI86+apD2v42SubuWZ+Ed+6eLJn/UhsUKCLnIo3fgzpBTD/C5518eaWRu764wY+NTGX/7p6lq7nKSekQBc5WTvfg+1vwqLbIdGba29W1rbyD8s/YmJ+Or/6/Hx8CfpVlRPTu0TkZL1xD6TmwhnLPGm+trmTZY98QHpSAg8vW0Bmstaay8Ao0EVORs2H8PFf4ZxvgM/9deAtnX6WPbyGju4gj3xpASOzUlzvQ2KX1qGLnIzV90DKMFjwZdeb7gmE+OrvPmTr3nYeWbaQqQWZJ/4hkT40QxcZqLr1sPkFOOvrkJThatPWWv75jxt4d2sTP75mNosmarNSOXkKdJGBeuMeSMqCM291ven7XtrMM2t3c+enJ3P1/CLX25ehQYEuMhB7KmDTX+Csr0Kyu6fd//79nfzytWquX1DM18+f6GrbMrQo0EUGYvW94EuHM7/qarOvbWrg3/9UzpIpefzgszO11lwGRYEuciKNVVDxDCz8CqTmuNZsWU0LX//9R0wbmcH9N84nIV6/jjI4egeJnMib90FiCpx9m2tN7trXwbJH1jAs1cdvbl5AWpIWnMngKdBFPknTx1D2Byj5EqS5s/KkuaOHLz78Af5giEe/tID8DG/ONpWhR4Eu8kne/CnE++Cc211prssf5Cu/LaVmXye//kIJE/PdXf4oQ5sCXeR49u+ADY/DGTdDxohBNxcKWe74w3rWbN/PfdfOYeE49+rxIqBAFzm+t34GJg4WfdOV5n70wiZWbqjju5dO5Yo5o1xpU6QvBbpIf1pqYO1ymPd5yBx8+D76znYeWL2VL5w9hlvPHe/CAEWOpUAX6c/bPwcsfOpbg27qxYp6vv/nCi6ePoL/uGKG1pqLZxToIkdrq4cPH4U5NzgXgB6Ej3bu5/bH1jKnKJtfXD+P+DiFuXhHgS5ytLd/AaEALP72oJrZvvcAtzxaSkFWMg99sYQUX7xLAxTpnwJdpK/2Rij9Dcy+FnJOvdbd1N7NzQ9/gLWWR5YtZHi6d9cdFTlIp6eJ9PXuLyHQBYvvOOUmuvxBbvltKXUtXfz+K2cxLjfNxQGKHJ8CXeSgjn3wwa9h5tWQO+mUm/n9+ztZu7OZ//n8fM4YM8zFAYp8MpVcRA5671fgPwDnfmdQzawsq2PayEyWzhzp0sBEBkaBLgLQ2Qzv/y9MuxLyp51yM/UtXXy4Yz+XzSxwcXAiA6NAFwEnzLtbBz07f768DoDLZmt2LqefAl2kq9Upt0y5DEbOHlRTq8rqmFqQwYS8dJcGJzJwCnSRNQ9CV/OgZ+d7Wrso3bGfy2Zpdi7hoUCXoa3ngLNUceJFUDh/UE29UF6PtXDZLNXPJTwGFOjGmKXGmCpjTLUx5q5+nv+ZMWZd79dmY0yz+0MV8UDpb6CjCc7750E3tbKsjskj0rXHuYTNCdehG2PigfuBi4EaYI0x5jlrbeXBY6y13+pz/DeAeR6MVcRd/k7nNP9x50HxwkE11dDaxZrt+/jmhae+fl1ksAYyQ18IVFtrt1pre4DHgas+4fgbgMfcGJyIpz58FA40wHn/NOimXqg4WG5R/VzCZyCBXgjs6nO/pvexYxhjxgDjgFcHPzQRDwW6nS1yxyyCsZ8adHOryuqYmJ/O5BEqt0j4DCTQ+9vv0x7n2OuBp6y1wX4bMuZWY0ypMaa0sbFxoGMUcd/a5dBWO+iVLQCNbd18sG2fZucSdgMJ9BqguM/9IqD2OMdezyeUW6y1D1hrS6y1JXl5eQMfpYibAj3O5eWKFsD4JYNu7oWKekIWLlegS5gNJNDXAJOMMeOMMT6c0H7u6IOMMVOAYcC77g5RxGUbHoeWXc7KFheuHvR8WR3j89KYPEInE0l4nTDQrbUB4DbgRWAj8KS1tsIYc7cx5so+h94APG6tPV45RiT8ggF48z4YNc9Zez5Ie9u7eW9rE5fPGqlLy0nYDWj7XGvtKmDVUY9976j733dvWCIeKfsD7N8Ol/zQldn5i73lFtXPJRLoTFEZOkJBePNeGDHT2bfFBavK6hifm8bUAq1ukfBToMvQUfEMNFU7K1tcmJ03tXfz3tZ9XDqrQOUWiQgKdBkaQiFYfS/kTXX2PHfBS5V7CIasyi0SMRToMjRs+jM0boTFd0KcO2/7VWV1jB2eyvSRma60JzJYCnSJfdbCGz+B4ROd64W6YN+BHt75uIlLtbpFIogCXWJf1fOwpwwW3wFx8a40+XJlPcGQ1clEElEU6BLbrIXV90D2GJj1t641u7KsntE5qcwYpXKLRA4FusS26r9C7Vpndh6f6EqTzR09vFO9l8tUbpEIo0CX2GUtvPFjyCqGOTe41uxLlXsIhKyuTCQRR4EusWvbG1DzASz6JiT4XGt2VVkdRcNSmFWY5VqbIm5QoEvseuMnkDES5t3kWpMtHX7ert6rvVskIinQJTZtfxt2vOXMzhOTXWv2pcp6/EHLpVrdIhFIgS6xafU9kJYH87/oarPPl9dTmJ3CnCKVWyTyKNAl9uxaA1tfh3NuB1+qa822dPp5c0sjl2nvFolQCnSJPavvgZQcKPmSq82+UrkHf1B7t0jkUqBLbNn9EWx5Cc7+OiS5ewWh58vrGJWVzNzibFfbFXGLAl1iy+p7ITkLFt7qarOtXX5Wb96rvVskoinQJXY0bIKqlXDW1yDZ3VPy/7pxDz3BkMotEtEU6BI71v4O4hJgwS2uN71yQz0js5KZp3KLRDAFusSGoB82PAGTl0JarqtNt3X5Wb2lkaUzC4iLU7lFIpcCXWLDlpfhQCPM+7zrTb+6qYGeQEhb5UrEU6BLbFi7HNLyYeLFrje9ckMdIzKTmD96mOtti7hJgS7Rr70RtrwIc66D+AR3m+4O8PrmRi6dOVLlFol4CnSJfhuegFAA5npXbtHqFokGCnSJbtY65ZbCMyB/quvNr9pQR35GEiVjVG6RyKdAl+hW+xE0bvTkw9AD3QFeq2rgUq1ukSihQJfotnYFJCTDzGtcb/q1qga6AyFtlStRQ4Eu0cvfBeVPwbQrnNP9XbaqrI7c9CQWjM1xvW0RLyjQJXpt+gt0tcDcv3O96Y6eAK9ucsot8Sq3SJRQoEv0WrfCuQD0uPNcb/q1TY10+UNcqgtBSxRRoEt0at4FH78Gc2+EOPffxqvK68hN93HmuOGuty3iFQW6RKf1jwPWCXSXdfYEeXVjA5fMULlFoosCXaKPtU65ZexiGDbW9eZfr2qg0x/U3i0SdRToEn12vAP7t3nyYSjAyrI6ctJ8LByn1S0SXQYU6MaYpcaYKmNMtTHmruMcc60xptIYU2GM+b27wxTpY+1y8GXA9Ctdb7rLH+TVTU65JSFe8x2JLifcycgYEw/cD1wM1ABrjDHPWWsr+xwzCfgusMhau98Yk+/VgGWI626Dymdh1t+AL8315l+vaqSjR+UWiU4DmYIsBKqttVuttT3A48BVRx3zFeB+a+1+AGttg7vDFOlV8Sz4OzzZiAuck4mGpSZy1niVWyT6DCTQC4Fdfe7X9D7W12RgsjHmbWPMe8aYpf01ZIy51RhTaowpbWxsPLURy9C2bgUMnwTFC11vussf5K8b96jcIlFrIO/a/tZt2aPuJwCTgCXADcCDxphjLr5orX3AWltirS3Jy8s72bHKULe3Gna+C/P+Doz7ywlXb27kQE9QW+VK1BpIoNcAxX3uFwG1/RzzJ2ut31q7DajCCXgR96xbASYOZl/vSfOryurITk3k7Ak6mUii00ACfQ0wyRgzzhjjA64HnjvqmGeB8wGMMbk4JZitbg5UhrhQ0DmZaOJFkOn+DLrLH+SVjQ18evoIElVukSh1wneutTYA3Aa8CGwEnrTWVhhj7jbGHFw39iLQZIypBF4DvmOtbfJq0DIEffwatNV6tvb8rS17ae8OqNwiUW1AF2C01q4CVh312Pf6fG+Bb/d+ibhv3XJIGQZTLvWk+VVldWSlJLJoYq4n7YucDvrbUiJfxz7YtBJmXwcJSa433x0I8nLlHpVbJOrp3SuRr+wpCPZ4Wm5pU7lFYoACXSLfuuVQMAtGzvak+VVl9WQmJ6jcIlFPgS6Rrb4c6tZ7dmZoTyDEy5X1XDy9AF+Cfh0kuukdLJFt3QqI98Hsaz1p/u3qvbR2Bbh8tq5MJNFPgS6RK9ADG55wVrakerO3yqqyOjKSVG6R2KBAl8i1+QXoaPKs3OIPhnipcg8XTx9BUkK8J32InE4KdIlc61ZAegFMuMCT5t+u3ktLp1+rWyRmKNAlMrXVw5aXYc71ED+g899O2qqyOtKTEvjUJJVbJDYo0CUyrX8cbBDmeVtuuWhaPsmJKrdIbFCgS+Q5eBHo4jMh15tNO9/9uInmDpVbJLYo0CXy1JTC3s2enRkKTrklzRfPuZO1L7/EDgW6RJ51yyEhBWZ8zpPmA8EQL1bUc+G0ESq3SExRoEtk6emA8qdhxmchOdOTLt7buo/9KrdIDFKgS2TZ+GfobvW03LKyrI5UXzxLpqjcIrFFgS6RZd1yyB4DYxZ50vzBcssFU7W6RWKPAl0ix/4dsG21MzuP8+at+cG2few70MPlKrdIDFKgS+RY/xhgYO4NnnWxsqyOlMR4lkzJ96wPkXBRoEtkCIVg7QoYfx5kj/aki2DIOuWWafmk+FRukdijQJfIsP1NaNnp2UZcAO9va2Jvew+XzVS5RWKTAl0iw7oVkJQF0z7jWRfPl9WTnBjH+VO1ukVikwJdwq+rBSqfg5lXQ2KKJ10EQ5bny53VLak+bzb7Egk3BbqEX/nTEOiEeTd51sWa7fvY296tk4kkpinQJfzWrYC8qVA437Muni+rIykhjvO1ukVimAJdwquxCmrWOGvPjfGki1BvueX8KfmkJancIrFLgS7htW4FmHiYfZ1nXZTu2E9DWzeXzVa5RWKbAl3CJxhwLmQx6dOQMcKzblaV1eFLiOOCqSq3SGxToEv4VL8C7Xs8uyoRHCy31LFkch7pKrdIjFOgS/isWw6puTD5Es+6+Gjnfva0dnO5yi0yBCjQJTwONEHVC07tPD7Rs25WqtwiQ4gCXcKj7EkI+WGed/ueh0KW58vqOXdSHhnJ3v1PQyRSKNDl9LMW1i6HUfNgxAzPulm7q5n61i4un13gWR8ikUSBLqdf3XrYU+7pVYmgd3VLfBwXTvNuBY1IJBlQoBtjlhpjqowx1caYu/p5/mZjTKMxZl3v1y3uD1VixroVEJ8Es/7Gsy6ccksdiyflkqlyiwwRJwx0Y0w8cD9wKTAduMEYM72fQ5+w1s7t/XrQ5XFKrAh0Q9kfYOrlkDLMs27W1zRT29KlvVtkSBnIDH0hUG2t3Wqt7QEeB67ydlgSs6pWQed+Tz8MBafckhhvuGi6yi0ydAwk0AuBXX3u1/Q+drRrjDEbjDFPGWOK+2vIGHOrMabUGFPa2Nh4CsOVqLd2OWQWwvjzPevCWsuqsnoWT8ojK0XlFhk6BhLo/e2YZI+6/2dgrLV2NvAK8Gh/DVlrH7DWllhrS/LydJGBIae1Fj5+FebcAHHeXQJufU0Lu5s7uXSmVrfI0DKQQK8B+s64i4DavgdYa5ustd29d38NnOHO8CSmrH8MbAjm3uhpN8/3lls+PV2BLkPLQAJ9DTDJGDPOGOMDrgee63uAMabvJ09XAhvdG6LEBGudi0CPPgeGT/CwG8vKsjoWTcwlK1XlFhlaThjo1toAcBvwIk5QP2mtrTDG3G2MubL3sNuNMRXGmPXA7cDNXg1YotTO92Dfx55uxAVQtruFmv2dWt0iQ9KAtp+z1q4CVh312Pf6fP9d4LvuDk1iyrrlkJgG071dILWyrI6EOMOntbpFhiCdKSre6zkAFc/CjM9BUrpn3Vjr7N1yzsRcslN9nvUjEqkU6OK9yj9BT7una8+bO3r4zlMb2Lmvg8+o3CJDlHb8F++tXQE542H02a43ba3lufW13P3nSpo7/fzDkglcPb+/0yREYp8CXby1byvseAsu+HfXLwK9a18H//6ncl6vamROcTbLr57FtJGZrvYhEk0U6OKtdb8HE+ecTOSSQDDEI+9s576XNmMM/McV0/nC2WOJj3P3fxgi0UaBLt4JBWHdY85p/lnulEHKd7fw3afLKNvdwoVT87n7szMpzE5xpW2RaKdAF+9sewNaa+DTdw+6qc6eID97ZTMPvbWNYak+7r9xPpfNKsC4XMYRiWYKdPHO2uWQnA1TLh9UM6s3N/Kvz5axa18nNyws5q6l03QWqEg/FOjijc79sPEvMP8LkJh8Sk00tXfzg5UbeWbtbsbnpfHErWdx5vjhLg9UJHYo0MUb5X+EYPcprT231vL0R7v5wcpK2rsD3H7hJL62ZALJid7t0CgSCxTo4o21KyB/Boyce1I/tqPpAP/yTBlvVzdxxphh/OjqWUwakeHRIEViiwJd3LenEmo/gkv+a8Brz/3BEA++uY3/fmUzvvg4fvDZmdy4cDRxWoooMmAKdHHfuhUQlwCzrx3Q4et3NXPX02VsrGtl6YwCvn/lDAqyTq3uLjKUKdDFXUE/bHgCJi+FtNxPPLS9O8B9L1Xx6Dvbyc9I5n9vOoNLZuiiFCKnSoEu7tryEhxoPOG+569u2sO/PVNOXWsXN501hu9cMoWMZC1FFBkMBbq4a+0KSMuHiRf3+3RDWxf/58+VrNxQx+QR6Tx149mcMSbnNA9SJDYp0MU97Q2w+QU4++sQf+Rby1rLE2t28cNVG+nyh7jj4sn8/XkT8CVoB2cRtyjQxT0bngAbPKbc8nFjO//ydBnvb9vHmeNy+OHVs5iQ592FLkSGKgW6uOPgRaALSyBvCgA9gRD/88bH/PLVapIT4/jxNbO4tqRY+6+IeESBLu6o/QgaN8JnfgbAhzv2cdcfy9jS0M5nZo/ke1dMJz9DSxFFvKRAF3esXQ4JybROvIqfPFvO8vd3MCorhd/cXMIFU3XBZpHTQYEeq0JB8HdCoKuf2w7wd0GgcwC3AzmmC4Ld1I6+gs/9ai2Nbd0sO2ccd3x6MmlJeouJnC76bYtmuz+Ct/8bGqt6g7dPcIf8p95uQoqzQ2JiKiQkQ2LK4dvUXOe53mM6rY+drSEq9ga4b/MZ5IxM4oGbSphTnO3ev1NEBkSBHo12vgerfwLVrzj7jY871wnfPkF73NvElE8+JiHpE/dfCYUsZbtbeHVTA69XNbBhdwvWQl5GEl9aOo5bFo8jMV5LEUXCQYEeLayFbaudIN/+pjNTvuj7UPJlSPb2wsgtHX5Wb2nktaoG3qhqpOlAD8bAvOJsvn3RZM6fms/0kZnaSEskzBTokc5a2PKyE+Q1H0B6gbOL4RlfBF+aR11aNtW38VpVA69vauTDnfsJhizZqYmcNzmPC6bms3hSHjlpPk/6F5FTo0CPVKEQVK10grxuPWQVw+X3wdzPn/IVgD7Jge4Ab1fv5bWqRl6vaqCupQuAmYWZfG3JBJZMyWducTbxmoWLRCwFeqQJBaHiGXjzPmiohGHj4MpfwuzrIMG9GbG1lm17D/TWwhv5YNs+eoIh0pMSWDwpl29dlM95U/IYkam14yLRQoEeKYJ+KPuDE+RN1ZA7Ba7+Ncy4+ph9UU5Vlz/Ie1ubeL3KqYfvaOoAYFJ+OjcvGsuSKXmUjMnR/ioiUUqBHm6Bblj3e3jrZ9C8AwpmwbW/halXQNzgg7Vmf4dTRtnUwNsf76XLHyI5MY5zJuRyy+LxLJmcR3FOqgv/EBEJNwV6uPg74aPfwts/h9bdUHgGXHoPTL5kwJdt67fZYIjS7T2qMloAAAfYSURBVPt5vaqBVzc1sKWhHYDROalcv2A0S6bkcdb44brgskgMUqCfbt3tUPoQvPNLONAAo8+Bq34J488/5SBvaO06VEZ5a8te2roDJMYbzhw3nOsWFHP+1HzG56ZpUyyRGKdAP126WuD9B+C9+6FzvxPg5z4CYxedVDPdgSCb6trYUNPMhpoWNtS0ULWnDYCCzGQ+M2ckS6bks2hiLuk67V5kSBnQb7wxZinwcyAeeNBa+6PjHPc3wB+ABdbaUtdGGc069sF7v3LCvLvFudbm4juheMEJfzQQDLF5Tztlu5tZX9NCWU0Lm+pb8QctADlpPmYXZXHl3FFcMDWfqQUZmoWLDGEnDHRjTDxwP3AxUAOsMcY8Z62tPOq4DOB24H0vBhp12vbAu7+ENQ+B/wBMuxLOvRNGzun38FDIsnXvgT4z72Yq61rp8ocAyEhOYHZRFl/+1HjmFGUxqyiLwuwUBbiIHDKQGfpCoNpauxXAGPM4cBVQedRx/wncA9zp6gijTctueOcX8OEjEOyBmdfA4jsgf9qhQ6y17NrXyYbdh8O7fHcr7d0BAFIS45lZmMnfnTmG2UVZzC7KZkxOqk6tF5FPNJBALwR29blfA5zZ9wBjzDyg2Fr7F2PMcQPdGHMrcCvA6NGjT360kWz/dmfp4doVgIXZ18Pib2NzxrOntZv1FfWU1bSwvqaZst0tNHc4uyH64uOYNiqTz80rPBTeE/PTdUamiJy0gQR6f8liDz1pTBzwM+DmEzVkrX0AeACgpKTEnuDw6LC32jkZaMMTEBdP16wbWTv6Zj7Yn0HZX/axvmYbjW3dAMTHGSaPyGDpjAJmFWUxpyibySMydCKPiLhiIIFeAxT3uV8E1Pa5nwHMBF7vrecWAM8ZY6705IPRPZVQu9b1Zk+epWfzKyRu+hMB42N15mf5RdelrH8/Fd6vw5g6JuSls3hiLrOLsphVlM2MUZla/y0inhlIoK8BJhljxgG7geuBGw8+aa1tAXIP3jfGvA7c6dkql+qX4eXvedL0yeqxyTwUvJyHApeRmjyS2WOyuLy3bDJjVCYZyYnhHqKIDCEnDHRrbcAYcxvwIs6yxd9YayuMMXcDpdba57we5BHOuBmmf9bTLkLWsqOpg8q6VjbVtbGxvpXqhnYCocPLBaePzGTc6GJmjBnFK0VZZKdqK1kRCS9jbXhK2SUlJba0NPxL1a211Ld2sX5XM+t2tbB+l/Oh5cEVJ+lJznLBOcXZzCnKZk5xFgWZyVouKCJhYYz50Fpb0t9zQ+5UwpZO/6HVJut2NbN+VzMNvR9aJsYbpo10VpzMKc5mbnEW43PTtVxQRKJCTAd6lz/IxrpW1u9yzrRcX9PM1sYDh54fn5vGoom5zOmdgU8bqQ8tRSR6xUygO2dath8qm6yvaWZj3eHT5PMykphbnM0184uYU5TNrKIsslL0oaWIxI6oDfT6li6nZFLjlE021BxZ955V6JwmP7fYmX2r7i0isS7qAv3xD3by05c3H1P3/uy8UcwpymZucTbj83SmpYgMPVEX6PmZSap7i4j0I+oC/YKpI7hg6ohwD0NEJOJoExERkRihQBcRiREKdBGRGKFAFxGJEQp0EZEYoUAXEYkRCnQRkRihQBcRiRFh2w/dGNMI7DjFH88F9ro4nGin1+NIej0O02txpFh4PcZYa/P6eyJsgT4YxpjS423wPhTp9TiSXo/D9FocKdZfD5VcRERihAJdRCRGRGugPxDuAUQYvR5H0utxmF6LI8X06xGVNXQRETlWtM7QRUTkKAp0EZEYEXWBboxZaoypMsZUG2PuCvd4wsUYU2yMec0Ys9EYU2GM+Wa4xxQJjDHxxpi1xpi/hHss4WaMyTbGPGWM2dT7Pjk73GMKF2PMt3p/T8qNMY8ZY5LDPSYvRFWgG2PigfuBS4HpwA3GmOnhHVXYBIA7rLXTgLOArw/h16KvbwIbwz2ICPFz4AVr7VRgDkP0dTHGFAK3AyXW2plAPHB9eEfljagKdGAhUG2t3Wqt7QEeB64K85jCwlpbZ639qPf7Npxf1sLwjiq8jDFFwOXAg+EeS7gZYzKBc4GHAKy1Pdba5vCOKqwSgBRjTAKQCtSGeTyeiLZALwR29blfwxAPMQBjzFhgHvB+eEcSdv8N/BMQCvdAIsB4oBF4uLcE9aAxJi3cgwoHa+1u4F5gJ1AHtFhrXwrvqLwRbYFu+nlsSK+7NMakA38E/tFa2xru8YSLMeYzQIO19sNwjyVCJADzgf9nrZ0HHACG5GdOxphhOH/JjwNGAWnGmM+Hd1TeiLZArwGK+9wvIkb/dBoIY0wiTpivsNY+He7xhNki4EpjzHacUtwFxpjl4R1SWNUANdbag3+1PYUT8EPRRcA2a22jtdYPPA2cE+YxeSLaAn0NMMkYM84Y48P5YOO5MI8pLIwxBqc+utFa+9NwjyfcrLXftdYWWWvH4rwvXrXWxuQsbCCstfXALmPMlN6HLgQqwzikcNoJnGWMSe39vbmQGP2AOCHcAzgZ1tqAMeY24EWcT6p/Y62tCPOwwmURcBNQZoxZ1/vYv1hrV4VxTBJZvgGs6J38bAWWhXk8YWGtfd8Y8xTwEc7qsLXE6BYAOvVfRCRGRFvJRUREjkOBLiISIxToIiIxQoEuIhIjFOgiIjFCgS4iEiMU6CIiMeL/A7rZYIQoIU4bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history10.history['crf_viterbi_accuracy']) # this is the first run of 10 epochs. got 0 accuracy.\n",
    "plt.plot(history10.history['val_crf_viterbi_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPgMJy7FzWwE",
    "outputId": "0defbe3a-62db-484c-8d04-ac63f511938a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c81ceb788>]"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history10.history['crf_viterbi_accuracy']) # after 10 more epochs\n",
    "plt.plot(history10.history['val_crf_viterbi_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWJZ_o2urBqg"
   },
   "outputs": [],
   "source": [
    "pred10 = model.predict(X_word_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHmZpBNerBqh"
   },
   "outputs": [],
   "source": [
    "pred_tags = get_tags(pred10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-ucexg1zWwI"
   },
   "outputs": [],
   "source": [
    "hits,count_pad,count_o = get_hits(new_y_te,pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MAZqS1BUrBqk",
    "outputId": "20bf5cb5-011a-46c6-f370-1ae1287fa3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tags : 359700\n",
      "# of 'P' : 254383\n",
      "# of 'O' : 89177\n",
      "Total tags left without O,P : 16140\n",
      "# of hits without 'PAD' and 'O' : 0\n",
      "# of predicted - 'O' : 105315\n",
      "# of predicted - 'PAD' : 254383\n",
      "Accuracy rate :  0.0\n"
     ]
    }
   ],
   "source": [
    "print_scores(hits,count_pad,count_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dk_-tqP8rBql"
   },
   "source": [
    "# Difficulties and future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPwGdpQFrBql"
   },
   "source": [
    "While working on this project, i have faced some difficulties.<br>\n",
    "My main problam was my small dataset, in order to train a deep neural network model well, planty of data is required, NER is relatively old, while Hebrew tagged data is very hard to manage thesedays.<br>\n",
    "Building a strong model, requires a good parameters and initializers choosing, architecture etc. so in order to find the best \"fit\", alot of practice is needed.<br>\n",
    "Another tricky issue is to keep up with the layers shapes, outputs and vector transforming, it is importent to understand the model's data shape.<br><br>\n",
    "A note about models 5 and 6 - <br>\n",
    "Unfortunatly, models 5 and 6 requiers heavie computing, COLAB keras_contrib version doesnt match the CRF version, so i had to run the model on my on CPU, which is alot weaker, hence, # of epochs is very small and the accuracy rate of this models is very low,specially on the english dataset (because its alot bigger). I'm SURE running more epochs will get better results.<br><br>\n",
    "To implement:<br>\n",
    "Pointer Networks - https://arxiv.org/pdf/1812.09449.pdf<br>\n",
    "ELMo Embedding - https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/ <br>\n",
    "Deep transfer learning with multitask bi-directional LSTM RNN - https://ccsb.pvamu.edu/papers/dong-multitask-bidirectional-lstm-rnn-chinese-emr/ <br>\n",
    "Better char encoding approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnv9P1_9rBqm"
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XDRKO40E3Rrg"
   },
   "source": [
    "<center>Hebrew models:</center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th># Model</th>\n",
    "    <th># Parameters</th>\n",
    "    <th>Accuracy</th>\n",
    "    <th>Description</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>3,099</td>\n",
    "    <td>0</td>\n",
    "    <td>Simple NN</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>301,019</td>\n",
    "    <td>0.5786</td>\n",
    "    <td>Simple LSTM</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>338,959</td>\n",
    "    <td>0.4806</td> \n",
    "    <td>Complex LSTM network</td>\n",
    "      \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>327,724</td>\n",
    "    <td>0.4152</td> \n",
    "    <td>GRU Network</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>333,266</td>\n",
    "    <td>0.5847</td> \n",
    "    <td>LSTM - CRF word based</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td>342,718</td>\n",
    "    <td>0.0157</td>\n",
    "    <td>LSTM - CRF word and char</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<br>\n",
    "<center>English models:</center>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th># Model</th>\n",
    "    <th># Parameters</th>\n",
    "    <th>Accuracy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>563,835</td>\n",
    "    <td>0.7765</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>605,486</td>\n",
    "    <td>0</td> \n",
    "  </tr>\n",
    "  </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdRdZDirzWwM"
   },
   "source": [
    "# Final Conclusions\n",
    "\n",
    "Named entity recognition is a hard task in the field of NLP, there are many langauges that needs to be handled, each langauge has its own pragmatics, semantics and syntax, which makes the solution even harder.<br>\n",
    "many of insights have learned thourghout this project.<br>\n",
    "First, in order to get good results and a strong model, a LARGE dataset is required, as we have seen while comparing the small hebrew dataset to the english dataset.<br>\n",
    "Second, sometimes, when working with a small dataset, going deeper and heavier with the model architecture wont always help, in fact, sometimes it can get worse.<br>\n",
    "Theird, it is importent to understand your dataset, and engineer it right, I'm sure that preforming a good feature engineering and corpus constructing will help the process become better (e.g. word embedding).<br>\n",
    "Fourth, Because time and GPU limitations, parameter choosing is a long and confusing process, while choosing them right, can help tune up the whole model.<br>\n",
    "Fifth, There are many \"addons\" to add a model (e.g. cuDNN) in order the accelerate the model and get better results, it is imported to be familiar with the ones in your niche.<br>\n",
    "Sixth, IDE choosing is very importent, some models requiers their own environment setup with specific packages versions, i found myslef switching between COLAB and jupyter in order to custom environment versions, which made my work twice hard."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "newAndFinal_(2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
